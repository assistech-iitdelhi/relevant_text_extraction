<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Sparse Fourier Transform: Theory and Practice</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet.css"/>
<link rel="stylesheet" type="application/vnd.adobe-page-template+xml" href="../styles/page-template.xpgt"/>
</head>
<body>
<p class="chno"><a id="page_29"/><b>3</b></p>
<p class="chtitle"><b>Simple and Practical Algorithm</b></p>
<p class="h1"><b><a id="ch3_1"/><span class="big">3.1</span>&#160;&#160;&#160;&#160;Introduction</b></p>
<p class="noindent">In this chapter, we propose a new sublinear Sparse Fourier Transform algorithm over the complex field. The key feature of this algorithm is its simplicity: the algorithm has a simple structure, which leads to efficient runtime with low big-Oh constant. This was the first algorithm to outperform FFT in practice for a practical range of sparsity as we will show later in <a href="15_Chapter06.xhtml">Chapter 6</a>.</p>
<p class="h2"><a id="ch3_1_1"/><b><span class="big1">3.1.1</span>&#160;&#160;&#160;&#160;Results</b></p>
<p class="noindent">We present an algorithm which has the runtime of</p>
<p class="image"><img src="../images/pg29_1.png" alt="image"/></p>
<p class="noindent">where <i>n</i> is the size of the signal and <i>k</i> is the number of non-zero frequency coefficients. Thus, the algorithm is faster than FFT for <i>k</i> up to <i>O</i>(<i>n</i>/log <i>n</i>). In contrast, earlier algorithms required asymptotically smaller bounds on <i>k</i>. This asymptotic improvement is also reflected in empirical runtimes. For example, we show in <a href="15_Chapter06.xhtml">Chapter 6</a> that for <i>n</i> = 2<sup>22</sup>, this algorithm outperforms FFT for <i>k</i> up to about 2,200, which is an order of magnitude higher than what was achieved by prior work.</p>
<p class="indent">The estimations provided by our algorithm satisfy the so-called <i>&#8467;<sub>&#8734;</sub></i>/<i>&#8467;</i><sub>2</sub> guarantee. Specifically, let <i>y</i> be the minimizer of ||<i>x&#770;</i> &#8722; <i>y</i>||<sub>2</sub>. For a precision parameter <i>&#948;</i> = 1/<i>n</i><sup><i>O</i>(1)</sup>, and a constant <i>&#8714;</i> &#62; 0, our (randomized) algorithm outputs <i>x&#770;</i>&#8242; such that:</p>
<p class="eqn"><a id="eq3_1"/><img src="../images/eq3_1.png" alt="image"/></p>
<p class="noindent">with probability 1 &#8722; 1/<i>n</i>. The additive term that depends on <i>&#948;</i> appears in all past algorithms [Akavia 2010, Akavia et al. 2003, Gilbert et al. 2002, Gilbert et al. 2005a, Iwen 2010b, Mansour 1992], although typically (with the exception of Iwen <a id="page_30"/>[2010a]) it is eliminated by assuming that all coordinates are integers in the range {&#8722;<i>n</i><sup><i>O</i>(1)</sup> &#8230; <i>n</i><sup><i>O</i>(1)</sup>}. In this chapter, we keep the dependence on <i>&#948;</i> explicit.</p>
<p class="indent">The <i>&#8467;<sub>&#8734;</sub></i>/<i>&#8467;</i><sub>2</sub> guarantee of <a href="#eq3_1">Equation (3.1)</a> is <i>stronger</i> than the <i>&#8467;</i><sub>2</sub>/<i>&#8467;</i><sub>2</sub> guarantee of <a href="09_Chapter01.xhtml#eq1_2">Equation (1.2)</a>. In particular, the <i>&#8467;<sub>&#8734;</sub></i>/<i>&#8467;</i><sub>2</sub> guarantee with a constant approximation factor <i>C</i> implies the <i>&#8467;</i><sub>2</sub>/<i>&#8467;</i><sub>2</sub> guarantee with a constant approximation factor <i>C</i>&#8242;, if one sets all but the <i>k</i> largest entries in <i>x&#770;</i>&#8242; to 0.<sup><a id="fn1" href="#rfn1">1</a></sup> Furthermore, instead of bounding only the collective error, the <i>&#8467;<sub>&#8734;</sub></i>/<i>&#8467;</i><sub>2</sub> guarantee ensures that every Fourier coefficient is well approximated.</p>
<p class="h2"><a id="ch3_1_2"/><b><span class="big1">3.1.2</span>&#160;&#160;&#160;&#160;Techniques</b></p>
<p class="noindent">Recall from <a href="09_Chapter01.xhtml">Chapter 1</a> that the Sparse Fourier Transform algorithms work by binning<sup><a id="fn2" href="#rfn2">2</a></sup> the Fourier coefficients into a small number of buckets. Since the signal is sparse in the frequency domain, each bucket is likely<sup><a id="fn3" href="#rfn3">3</a></sup> to have only one large coefficient, which can then be located (to find its position) and estimated (to find its value). For the algorithm to be sublinear, the binning has to be done in sublinear time. Binning the Fourier coefficient is done using an <i>n</i>-dimensional filter vector <i>G</i> that is concentrated both in time and frequency, i.e., <i>G</i> is zero except at a small <i>number</i> of time coordinates, and its Fourier transform <img src="../images/in25_1.png" alt="image"/> is negligible except at a small <i>fraction</i> (about 1/<i>k</i>) of the frequency coordinates (the &#8220;pass&#8221; region).</p>
<p class="indent">Prior work uses different types of filters. Depending on the choice of the filter <i>G</i>, past algorithms can be classified as iteration-based or interpolation-based.</p>
<p class="indent">Iteration-based algorithms use a filter that has a significant mass outside its pass region [Gilbert et al. 2002, Gilbert et al. 2005a, Mansour 1992]. For example, Gilbert et al. [2002] and Gilbert et al. [2005a] set <i>G</i> to the rectangular filter which was shown in <a href="09_Chapter01.xhtml#fig1_3">Figure 1.3(a)</a>, in which case <img src="../images/in25_1.png" alt="image"/> is the Dirichlet kernel<sup><a id="fn4" href="#rfn4">4</a></sup>, whose tail decays in an inverse linear fashion. Since the tail decays slowly, the Fourier coefficients binned to a particular bucket &#8220;leak&#8221; into other buckets. On the other hand, Mansour [1992] estimates the convolution in time domain via random sampling, which also leads to a large estimation error. To reduce these errors and obtain the <i>&#8467;</i><sub>2</sub>/<i>&#8467;</i><sub>2</sub> guarantee, these algorithms have to perform multiple iterations, where each iteration estimates the largest Fourier coefficient (the one least impacted by leakage) and subtracts its contribution <a id="page_31"/>to the time signal. The iterative update of the time signal causes a large increase in runtime. The algorithms in Gilbert et al. [2002] and Mansour [1992] perform this update by going through <i>O</i>(<i>k</i>) iterations, each of which updates at least <i>O</i>(<i>k</i>) time samples, resulting in an <i>O</i>(<i>k</i><sup>2</sup>) term in the runtime. The algorithm of Gilbert et al. [2005a] introduced a &#8220;bulk sampling&#8221; algorithm that amortizes this process but it requires solving instances of a non-uniform Fourier transform, which is expensive in practice.</p>
<p class="indent">Interpolation-based algorithms are less common and limited to the design in Iwen [2010b]. This approach uses the aliasing filter presented in <a href="09_Chapter01.xhtml">Chapter 1</a>, which is a leakage-free filter that allows [Iwen 2010b] to avoid the need for iteration. Recall that in this case, the filter <i>G</i> has <i>G<sub>i</sub></i> = 1 iff <i>i</i> mod <i>n</i>/<i>p</i> = 0 and <i>G<sub>i</sub></i> = 0 otherwise. The Fourier transform of this filter is a &#8220;spike train&#8221; with period <i>p</i> and hence this filter does not leak; it is equal to 1 on 1/<i>p</i> fraction of coordinates and is zero elsewhere. Unfortunately, however, such a filter requires that <i>p</i> divides <i>n</i> and the algorithm in Iwen [2010b] needs many different values of <i>p</i>. Since in general one cannot assume that <i>n</i> is divisible by all numbers <i>p</i>, the algorithm treats the signal as a continuous function and <i>interpolates</i> it at the required points. Interpolation introduces additional complexity and increases the exponents in the runtime.</p>
<p class="h2"><a id="ch3_1_3"/><b><span class="big1">3.1.3</span>&#160;&#160;&#160;&#160;Our Approach</b></p>
<p class="noindent">The key feature of our algorithm is the use of a different type of filter. In the simplest case, we use a filter obtained by convolving a Gaussian function with a box-car function.<sup><a id="fn5" href="#rfn5">5</a></sup> Because of this new filter, our algorithm does not need to either iterate or interpolate. Specifically, the frequency response of our filter <img src="../images/in25_1.png" alt="image"/> is nearly flat inside the pass region and has an <i>exponential</i> tail outside it. This means that leakage from frequencies in other buckets is negligible, and hence, our algorithm need not iterate. Also, filtering can be performed using the existing input samples <i>x<sub>i</sub></i>, and hence our algorithm need not interpolate the signal at new points. Avoiding both iteration and interpolation is the key feature that makes this algorithm efficient.</p>
<p class="indent">Further, once a large coefficient is isolated in a bucket, one needs to identify its frequency. In contrast to past work which typically uses binary search for this task, we adopt an idea from Porat and Strauss [2010] and tailor it to our problem. Specifically, we simply select the set of &#8220;large&#8221; bins which are likely to contain large coefficients, and directly estimate all frequencies in those bins. To balance the cost of the bin selection and estimation steps, we make the number of bins somewhat <a id="page_32"/>larger than the typical value of <i>O</i>(<i>k</i>). Specifically, we use <img src="../images/in32_1.png" alt="image"/>, which leads to the stated runtime.<sup><a id="fn6" href="#rfn6">6</a></sup></p>
<p class="h1"><b><a id="ch3_2"/><span class="big">3.2</span>&#160;&#160;&#160;&#160;Algorithm</b></p>
<p class="noindent">We refer to our algorithm as SFT 1.0 and it is shown in Algorithm 3.1. A key element of this algorithm is the <i>inner loop</i>, which finds and estimates each &#8220;large&#8221; coefficient with constant probability. In <a href="#ch3_2_1">Section 3.2.1</a> we describe the inner loop, and in <a href="#ch3_2_2">Section 3.2.2</a> we show how to use it to construct the full algorithm.</p>
<p class="h2"><a id="ch3_2_1"/><b><span class="big1">3.2.1</span>&#160;&#160;&#160;&#160;Inner Loop</b></p>
<p class="noindent">Let <i>B</i> be a parameter that divides <i>n</i>, to be determined later. Let <i>G</i> be a (1/<i>B</i>, 1/(2<i>B</i>), <i>&#948;, &#969;</i>) flat window function described in <a href="11_Chapter02.xhtml#ch2_2_1">Section 2.2.1</a> for some <i>&#948;</i> and <img src="../images/in32_2.png" alt="image"/>. We will have <i>&#948;</i> &#8776; 1/<i>n<sup>c</sup></i>, so one can think of it as negligibly small.</p>
<p class="indent">There are two versions of the inner loop: <i>location</i> loops and <i>estimation</i> loops. Location loops, described as the procedure L<small>OCATION</small>I<small>NNER</small>L<small>OOP</small> in Algorithm 3.1, are given a parameter <i>d</i>, and output a set <i>I</i> &#8834; [<i>n</i>] of <i>dkn</i>/<i>B</i> coordinates that contains each large coefficient with &#8220;good&#8221; probability. Estimation loops, described as the procedure E<small>STIMATION</small>I<small>NNER</small>L<small>OOP</small> in Algorithm 3.1, are given a set <i>I</i> &#8834; [<i>n</i>] and estimate <i>x&#770;<sub>I</sub></i> such that each coordinate is estimated well with &#8220;good&#8221; probability.</p>
<p class="indent">By Claim 2.4, we can compute <i>z&#770;</i> in <img src="../images/in32_3.png" alt="image"/> time. Location loops thus take <img src="../images/in32_4.png" alt="image"/> time and estimation loops take <img src="../images/in32_5.png" alt="image"/> time. <a href="#fig3_1">Figure 3.1</a> illustrates the inner loop.</p>
<p class="indent">For estimation loops, we get the following guarantee.</p>
<p class="noindentt"><b>Lemma 3.1</b> Let <i>S</i> be the support of the largest <i>k</i> coefficients of <i>x&#770;</i>, and <i>x&#770;</i><sub>&#8722;<i>S</i></sub> contain the rest. Then for any <i>&#8714;</i> &#8804; 1,</p>
<p class="image"><img src="../images/pg32_1.png" alt="image"/></p>
<p class="noindent"><b>Proof</b> The proof can be found in <a href="23_Appendix01.xhtml#appA_1">Appendix A.1</a>. &#9632;</p>
<p class="indent">Furthermore, since <img src="../images/in32_6.png" alt="image"/> is a good estimate for |<i>x&#770;<sub>i</sub></i>|&#8212;the division is mainly useful for fixing the phase. Therefore in location loops, we get the following guarantee:</p>
<p class="noindentt"><a id="page_33"/><b>Algorithm 3.1 SFT 1.0: Non-iterative Sparse Fourier Transform for</b> <img src="../images/in33_1.png" alt="image"/></p>
<p class="image"><img src="../images/alg3_1.png" alt="image"/></p>
<div class="cap">
<p class="image"><a id="page_34"/><a id="fig3_1"/><img src="../images/fig3_1.png" alt="image"/></p>
<p class="figcaption"><b>Figure 3.1</b> Example inner loop of the algorithm on sparse input. This run has parameters <i>n</i> = 256, <i>k</i> = 4, <i>G</i> being the (0.11, 0.06, 2 &#215; 10<sup>&#8722;9</sup>, 133) flat window function in <a href="11_Chapter02.xhtml#fig2_1">Figure 2.1</a>, and selecting the top 4 of <i>B</i> = 16 samples. In part (a), the algorithm begins with time domain access to <i>P</i><sub><i>&#963;, &#964;, b</i></sub><i>x</i> given by (<i>P</i><sub><i>&#963;, &#964;, b</i></sub><i>x</i>)<i><sub>i</sub></i> = <i>x</i><sub><i>&#963;</i>(<i>i</i>&#8722;<i>&#964;</i>)</sub><i>&#969;</i><sup><i>&#963;bi</i></sup>, which permutes the spectrum of <i>x</i> by permuting the samples in the time domain. In part (b), the algorithm computes the time domain signal <i>y</i> = <i>G</i> &#183; <i>P</i><sub><i>&#963;, &#964;, b</i></sub><i>x</i>. The spectrum of <i>y</i> (pictured) is large around the large coordinates of <i>P</i><sub><i>&#963;, &#964;, b</i></sub><i>x</i>. The algorithm then computes <i>z&#770;</i>, which is the rate <i>B</i> subsampling of <i>y&#770;</i> as pictured in part (c). During estimation loops, the algorithm estimates <i>x&#770;<sub>i</sub></i> based on the value of the nearest coordinate in <i>z&#770;</i>, namely <img src="../images/in34_3.png" alt="image"/>. During location loops (part (d)), the algorithm chooses <i>J</i>, the top <i>dk</i> (here, 4) coordinates of <i>z&#770;</i>, and selects the elements of [<i>n</i>] that are closest to those coordinates (the shaded region of the picture). It outputs the set <i>I</i> of preimages of those elements. In this example, the two coordinates on the left landed too close in the permutation and form a &#8220;hash collision.&#8221; As a result, the algorithm misses the second from the left coordinate in its output. Our guarantee is that each large coordinate has a low probability of being missed if we select the top <i>O</i>(<i>k</i>) samples.</p>
</div>
<p class="noindentt"><b>Lemma 3.2</b> Define <img src="../images/in34_1.png" alt="image"/> to be the error tolerated in Lemma 3.1. Then for any <i>i</i> &#8712; [<i>n</i>] with |<i>x&#770;<sub>i</sub></i>| &#8805; 4<i>E</i></p>
<p class="image"><img src="../images/in34_2.png" alt="image"/></p>
<p class="noindentt"><b>Proof</b> The proof can be found in <a href="23_Appendix01.xhtml#appA_2">Appendix A.2</a> &#9632;</p>
<p class="h2"><a id="page_35"/><a id="ch3_2_2"/><b><span class="big1">3.2.2</span>&#160;&#160;&#160;&#160;Non-Iterative Sparse Fourier Transform</b></p>
<p class="noindent">Our SFT 1.0 algorithm shown in Algorithm 3.1 is parameterized by <i>&#8714;</i> and <i>&#948;</i>. It runs <i>L</i> = <i>O</i>(log <i>n</i>) iterations of the inner loop, with parameters <img src="../images/in35_1.png" alt="image"/> and <i>d</i> = <i>O</i>(1/<i>&#8714;</i>) as well as <i>&#948;</i>.<sup><a id="fn7" href="#rfn7">7</a></sup></p>
<p class="noindentt"><b>Lemma 3.3</b> The algorithm runs in time <img src="../images/in35_2.png" alt="image"/>.</p>
<p class="noindentt"><b>Proof</b> To analyze this algorithm, note that</p>
<p class="image"><img src="../images/in35_3.png" alt="image"/></p>
<p class="noindent">or |<i>I</i>&#8242;| &#8804; 2<i>dkn</i>/<i>B</i>. Therefore, the running time of both the location and estimation inner loops is <img src="../images/in35_4.png" alt="image"/>. Computing <i>I</i>&#8242; and computing the medians both take linear time, namely <i>O</i>(<i>Ldkn</i>/<i>B</i>). Thus, the total running time is <img src="../images/in35_5.png" alt="image"/>. Plugging in <img src="../images/in35_6.png" alt="image"/> and <i>d</i> = <i>O</i>(1/<i>&#8714;</i>), this running time is <img src="../images/in35_2.png" alt="image"/>. We require <i>B</i> = <i>&#937;</i>(<i>k</i>/<i>&#8714;</i>), however; for <i>k</i> &#62; <i>&#8714;n</i>/log(<i>n</i>/<i>&#948;</i>), this would cause the run time to be larger. But in this case, the predicted run time is <i>&#937;</i>(<i>n</i> log <i>n</i>) already, so the standard FFT is faster and we can fall back on it. &#9632;</p>
<p class="noindentt"><b>Theorem 3.1</b> Running the algorithm with parameters <i>&#8714;, &#948;</i> &#60; 1 gives <i>x&#770;</i>&#8242; satisfying</p>
<p class="image"><img src="../images/pg35_1.png" alt="image"/></p>
<p class="noindent">with probability 1 &#8722; 1/<i>n</i> and running time <img src="../images/in35_2.png" alt="image"/>.</p>
<p class="noindentt"><b>Proof</b> Define</p>
<p class="image"><img src="../images/pg35_2.png" alt="image"/></p>
<p class="noindent">Lemma 3.2 says that in each location iteration <i>r</i>, for any <i>i</i> with |<i>x&#770;<sub>i</sub></i>| &#8805; 4<i>E</i>,</p>
<p class="image"><img src="../images/pg35_3.png" alt="image"/></p>
<p class="noindent">Thus, <span class="f1">E</span>[<i>s<sub>i</sub></i>] &#8805; 3<i>L</i>/4, and each iteration is an independent trial, so by a Chernoff bound the chance that <i>s<sub>i</sub></i> &#60; <i>L</i>/2 is at most 1/2<sup><i>&#937;</i>(<i>L</i>)</sup> &#60; 1/<i>n</i><sup>3</sup>. Therefore by a union bound, with probability at least 1 &#8722; 1/<i>n</i><sup>2</sup>, <i>i</i> &#8712; <i>I</i>&#8242; for all <i>i</i> with |<i>x&#770;<sub>i</sub></i>| &#8805; 4<i>E</i>.</p>
<p class="indent"><a id="page_36"/>Next, Lemma 3.1 says that for each estimation iteration <i>r</i> and index <i>i</i>,</p>
<p class="image"><img src="../images/pg36_1.png" alt="image"/></p>
<p class="noindent">Therefore, with probability <img src="../images/in36_8.png" alt="image"/> in at least 2<i>L</i>/3 of the iterations.</p>
<p class="indent">Since real <img src="../images/in36_1.png" alt="image"/> is the median of the real <img src="../images/in36_2.png" alt="image"/>, there must exist two <i>r</i> with <img src="../images/in36_3.png" alt="image"/> but one real <img src="../images/in36_2.png" alt="image"/> above real <img src="../images/in36_1.png" alt="image"/> and one below. Hence, one of these <i>r</i> has <img src="../images/in36_9.png" alt="image"/>, and similarly for the imaginary axis. Then</p>
<p class="image"><img src="../images/pg36_2.png" alt="image"/></p>
<p class="indent">By a union bound over <i>I</i>&#8242;, with probability at least 1 &#8722; 1/<i>n</i><sup>2</sup> we have <img src="../images/in36_4.png" alt="image"/> for all <i>i</i> &#8712; <i>I</i>&#8242;. Since all <i>i</i> &#8713; <i>I</i>&#8242; have <img src="../images/in36_5.png" alt="image"/> and |<i>x&#770;<sub>i</sub></i>| &#8804; 4<i>E</i> with probability 1 &#8722; 1/<i>n</i><sup>2</sup>, with total probability 1 &#8722; 2/<i>n</i><sup>2</sup> we have</p>
<p class="image"><img src="../images/in36_6.png" alt="image"/></p>
<p class="noindent">Rescaling <i>&#8714;</i> and <i>&#948;</i> gives our theorem. &#9632;</p>
<p class="h2"><a id="ch3_2_3"/><b><span class="big1">3.2.3</span>&#160;&#160;&#160;&#160;Extension</b></p>
<p class="noindent">In this section, we present an extension of the SFT 1.0 algorithm which adds a heuristic to improve the runtime. We refer to this new algorithm as SFT 2.0 and it is shown in Algorithm 3.2. The idea of the heuristic is to apply the aliasing filter to restrict the locations of the large coefficients. The algorithm is parameterized by <i>M</i> that divides <i>n</i>. It performs the aliasing filter as a preprocessing step to SFT 1.0 and uses its output to restrict the frequency locations in the set <i>I<sub>r</sub></i> outputted by the location loops, as shown in Algorithm 3.2.</p>
<p class="indent">Observe that <img src="../images/in36_7.png" alt="image"/>. Thus,</p>
<p class="image"><img src="../images/pg36_3.png" alt="image"/></p>
<p class="noindent">This means that the filter is very efficient, in that it has no leakage at all. Also, it is simple to compute. Unfortunately, it cannot be &#8220;randomized&#8221; using <i>P</i><sub><i>&#963;, &#964;, b</i></sub>: after permuting by <i>&#963;</i> and <i>b</i>, any two colliding elements <i>j</i> and <i>j</i>&#8242; (i.e., such that <i>j</i> = <i>j</i>&#8242; mod <i>M</i>) continue to collide. Nevertheless, if <i>x&#770;<sub>j</sub></i> is large, then <i>j</i> mod <i>M</i> is likely to lie in <i>T</i>&#8212;at least heuristically on random input.</p>
<p class="indent">SFT 2.0 assumes that all &#8220;large&#8221; coefficients <i>j</i> have <i>j</i> mod <i>M</i> in <i>T</i>. That is, we restrict our sets <i>I<sub>r</sub></i> to contain only coordinates <i>i</i> with <i>i</i> mod <i>M</i> &#8712; <i>T</i>. We expect that <img src="../images/in37_2.png" alt="image"/> rather than the previous <i>dkn</i>/<i>B</i>. This means that our heuristic will improve the runtime of the inner loops from <i>O</i>(<i>B</i> log(<i>n</i>/<i>&#948;</i>) + <i>dkn</i>/<i>B</i>) to <img src="../images/in37_3.png" alt="image"/>, at the cost of <i>O</i>(<i>M</i> log <i>M</i>) preprocessing.</p>
<p class="noindentt"><a id="page_37"/><b>Algorithm 3.2 SFT 2.0: Non-iterative Sparse Fourier Transform with heuristic for</b> <img src="../images/in37_1.png" alt="image"/></p>
<p class="image"><img src="../images/alg3_2.png" alt="image"/></p>
<p class="indent">Note that on worst case input, SFT 2.0 may give incorrect output with high probability. For example, if <i>x<sub>i</sub></i> = 1 when <i>i</i> is a multiple of <i>n</i>/<i>M</i> and 0 otherwise, then <i>y</i> = 0 with probability 1 &#8722; <i>M</i>/<i>n</i> and the algorithm will output 0 over supp(<i>x</i>). However, in practice the algorithm works for &#8220;sufficiently random&#8221; <i>x</i>.</p>
<p class="noindentt"><b>Claim 3.1</b> As a heuristic approximation, SFT 2.0 runs in <i>O</i>((<i>k</i><sup>2</sup><i>n</i> log(<i>n</i>/<i>&#948;</i>)/<i>&#8714;</i>)<sup>1/3</sup> log <i>n</i>) as long as <i>k</i> &#8804; <i>&#8714;</i><sup>2</sup><i>n</i> log(<i>n</i>/<i>&#948;</i>).</p>
<p class="indentt"><i>Justification</i>. First we will show that the heuristic improves the inner loop running time to <img src="../images/in37_3.png" alt="image"/>, then we will optimize the parameters <i>M</i> and <i>B</i>.</p>
<p class="indent">Heuristically, one would expect each of the <i>I<sub>r</sub></i> to be a <img src="../images/in37_4.png" alt="image"/> factor smaller than if we did not require the elements to lie in <i>T</i> modulo <i>M</i>. Hence, we expect each of the <i>I<sub>r</sub></i> and <i>I</i>&#8242; to have size <img src="../images/in37_5.png" alt="image"/>. Then in each location loop, rather than spending <i>O</i>(<i>dkn</i>/<i>B</i>) time to list our output, we spend <img src="../images/in37_6.png" alt="image"/> time&#8212;plus <a id="page_38"/>the time required to figure out where to start listing coordinates from each of the <i>dk</i> chosen elements <i>J</i> of <i>z&#770;</i>. We do this by sorting <i>J</i> and {<i>&#963;i</i> | <i>i</i> &#8712; <i>T</i>} (mod <i>M</i>), then scanning through the elements. It takes <i>O</i>(<i>M</i> + <i>dk</i>) time to sort <i>O</i>(<i>dk</i>) elements in [<i>M</i>], so the total runtime of each location loop is <img src="../images/in38_1.png" alt="image"/>. The estimation loops are even faster, since they benefit from |<i>I</i>&#8242;| being smaller but avoid the <i>M</i> + <i>dk</i> penalty.</p>
<p class="indent">The full algorithm does <i>O</i>(<i>M</i> log <i>M</i>) preprocessing and runs the inner loop <i>L</i> = <i>O</i>(log <i>n</i>) times with <i>d</i> = <i>O</i>(1/<i>&#8714;</i>). Therefore, given parameters <i>B</i> and <i>M</i>, the algorithm takes <img src="../images/in38_2.png" alt="image"/> time. Optimizing over <i>B</i>, we take</p>
<p class="image"><img src="../images/pg38_1.png" alt="image"/></p>
<p class="noindent">time. Then, optimizing over <i>M</i>, this becomes</p>
<p class="image"><img src="../images/pg38_2.png" alt="image"/></p>
<p class="noindent">time. If <i>k</i> &#60; <i>&#8714;</i><sup>2</sup><i>n</i> log(<i>n</i>/<i>&#948;</i>), the first term dominates.</p>
<p class="indent">Note that this is an <img src="../images/in38_3.png" alt="image"/> factor smaller than the running time of SFT 1.0.</p>
<p class="line"/>
<p class="foot"><a id="rfn1" href="#fn1">1</a>. This fact was implicit in Cormode and Muthukrishnan [2006]. For an explicit statement and proof see Gilbert and Indyk [2010, remarks after Theorem 2].</p>
<p class="foot"><a id="rfn2" href="#fn2">2</a>. Throughout this book, we will use the terms &#8220;Binning&#8221; and &#8220;Bucketization&#8221; interchangeably.</p>
<p class="foot"><a id="rfn3" href="#fn3">3</a>. One can randomize the positions of the frequencies by sampling the signal in time domain appropriately as we showed in <a href="11_Chapter02.xhtml#ch2_2_2">Section 2.2.2</a>.</p>
<p class="foot"><a id="rfn4" href="#fn4">4</a>. The Dirichlet kernel is the discrete version of the sinc function.</p>
<p class="foot"><a id="rfn5" href="#fn5">5</a>. A more efficient filter can be obtained by replacing the Gaussian function with a Dolph-Chebyshev function. (See <a href="11_Chapter02.xhtml#fig2_1">Figure 2.1</a> for an illustration.)</p>
<p class="foot"><a id="rfn6" href="#fn6">6</a>. Although it is plausible that one could combine our filters with the binary search technique of Gilbert et al. [2005a] and achieve an algorithm with a <i>O</i>(<i>k</i> log<sup><i>c</i></sup> <i>n</i>) runtime, our preliminary analysis indicates that the resulting algorithm would be slower. Intuitively, observe that for <i>n</i> = 2<sup>22</sup> and <i>k</i> = 2<sup>11</sup>, the values of <img src="../images/in32_7.png" alt="image"/> and <i>k</i> log<sub>2</sub> <i>n</i> = 45056 are quite close to each other.</p>
<p class="foot"><a id="rfn7" href="#fn7">7</a>. Note that <i>B</i> is chosen in order to minimize the running time. For the purpose of correctness, it suffices that <i>B</i> &#8805; <i>ck</i>/<i>&#8714;</i> for some constant <i>c</i>.</p>
</body>
</html>