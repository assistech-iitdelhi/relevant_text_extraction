<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Handbook of Multimodal-Multisensor Interfaces, Volume 2: Signal Processing, Architectures, and Detection of Emotion and Cognition</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet.css"/>
<link rel="stylesheet" type="application/vnd.adobe-page-template+xml" href="../styles/page-template.xpgt"/>
</head>
<body>
<p class="fmtitlec"><a id="page_xi"/><b>Contents</b></p>
<p class="tocx"><a href="08_Preface.xhtml">Preface</a></p>
<p class="tocx"><a href="09_ListofFig.xhtml">Figure Credits</a></p>
<p class="tocx"><a href="10_Introduction.xhtml">Introduction: Trends in Intelligent Multimodal-Multisensorial Interfaces: Cognition, Emotion, Social Signals, Deep Learning, and More</a></p>
<p class="toc2"><a href="10_Introduction.xhtml#int_1">A Very Brief History of HCI and AI&#8212;and Their Relationship in Time</a></p>
<p class="toc2"><a href="10_Introduction.xhtml#int_2">Increasingly Robust AI as a Game-Changer for HCI</a></p>
<p class="toc2"><a href="10_Introduction.xhtml#int_3">Multimodal Signal Processing, Architectures and Deep Learning</a></p>
<p class="toc2"><a href="10_Introduction.xhtml#int_4">The Advent of Artificial Emotional and Social Intelligence</a></p>
<p class="toc2"><a href="10_Introduction.xhtml#int_5">Insights in the Chapters Ahead</a></p>
<p class="toc2"><a href="10_Introduction.xhtml#int_6">References</a></p>
<p class="toctt"><a href="11_Part01.xhtml"><b>PART&#160;I&#160;&#160;&#160;MULTIMODAL SIGNAL PROCESSING AND ARCHITECTURES</b></a></p>
<p class="tocc"><a href="12_Chapter01.xhtml"><b>Chapter&#160;1&#160;&#160;Challenges and Applications in Multimodal Machine Learning</b></a></p>
<p class="toca"><i>Tadas Baltru&#353;aitis, Chaitanya Ahuja, Louis-Philippe Morency</i></p>
<p class="toc"><a href="12_Chapter01.xhtml#ch1_1">1.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="12_Chapter01.xhtml#ch1_2">1.2&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Applications</a></p>
<p class="toc"><a href="12_Chapter01.xhtml#ch1_3">1.3&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Representations</a></p>
<p class="toc"><a href="12_Chapter01.xhtml#ch1_4">1.4&#160;&#160;&#160;&#160;&#160;&#160;Co-learning</a></p>
<p class="toc"><a href="12_Chapter01.xhtml#ch1_5">1.5&#160;&#160;&#160;&#160;&#160;&#160;Conclusion</a></p>
<p class="toc1"><a id="page_xii"/><a href="12_Chapter01.xhtml#ch1_6">Focus Questions</a></p>
<p class="toc1"><a href="12_Chapter01.xhtml#ch1_7">References</a></p>
<p class="tocc"><a href="13_Chapter02.xhtml"><b>Chapter&#160;2&#160;&#160;Classifying Multimodal Data</b></a></p>
<p class="toca"><i>Ethem Alpaydin</i></p>
<p class="toc"><a href="13_Chapter02.xhtml#ch2_1">2.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="13_Chapter02.xhtml#ch2_2">2.2&#160;&#160;&#160;&#160;&#160;&#160;Classifying Multimodal Data</a></p>
<p class="toc"><a href="13_Chapter02.xhtml#ch2_3">2.3&#160;&#160;&#160;&#160;&#160;&#160;Early, Late, and Intermediate Integration</a></p>
<p class="toc"><a href="13_Chapter02.xhtml#ch2_4">2.4&#160;&#160;&#160;&#160;&#160;&#160;Multiple Kernel Learning</a></p>
<p class="toc"><a href="13_Chapter02.xhtml#ch2_5">2.5&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Deep Learning</a></p>
<p class="toc"><a href="13_Chapter02.xhtml#ch2_6">2.6&#160;&#160;&#160;&#160;&#160;&#160;Conclusions and Future Work</a></p>
<p class="toc1"><a href="13_Chapter02.xhtml#ch2_7">Acknowledgments</a></p>
<p class="toc1"><a href="13_Chapter02.xhtml#ch2_8">Focus Questions</a></p>
<p class="toc1"><a href="13_Chapter02.xhtml#ch2_9">References</a></p>
<p class="tocc"><a href="14_Chapter03.xhtml"><b>Chapter&#160;3&#160;&#160;Learning for Multimodal and Affect-Sensitive Interfaces</b></a></p>
<p class="toca"><i>Yannis Panagakis, Ognjen Rudovic, Maja Pantic</i></p>
<p class="toc"><a href="14_Chapter03.xhtml#ch3_1">3.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="14_Chapter03.xhtml#ch3_2">3.2&#160;&#160;&#160;&#160;&#160;&#160;Correlation Analysis Methods</a></p>
<p class="toc"><a href="14_Chapter03.xhtml#ch3_3">3.3&#160;&#160;&#160;&#160;&#160;&#160;Temporal Modeling of Facial Expressions</a></p>
<p class="toc"><a href="14_Chapter03.xhtml#ch3_4">3.4&#160;&#160;&#160;&#160;&#160;&#160;Context Dependency</a></p>
<p class="toc"><a href="14_Chapter03.xhtml#ch3_5">3.5&#160;&#160;&#160;&#160;&#160;&#160;Model Adaptation</a></p>
<p class="toc"><a href="14_Chapter03.xhtml#ch3_6">3.6&#160;&#160;&#160;&#160;&#160;&#160;Conclusion</a></p>
<p class="toc1"><a href="14_Chapter03.xhtml#ch3_7">Focus Questions</a></p>
<p class="toc1"><a href="14_Chapter03.xhtml#ch3_8">References</a></p>
<p class="tocc"><a href="15_Chapter04.xhtml"><b>Chapter&#160;4&#160;&#160;Deep Learning for Multisensorial and Multimodal Interaction</b></a></p>
<p class="toca"><i>Gil Keren, Amr El-Desoky Mousa, Olivier Pietquin, Stefanos Zafeiriou, Bj&#246;rn Schuller</i></p>
<p class="toc"><a href="15_Chapter04.xhtml#ch4_1">4.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="15_Chapter04.xhtml#ch4_2">4.2&#160;&#160;&#160;&#160;&#160;&#160;Fusion Models</a></p>
<p class="toc"><a href="15_Chapter04.xhtml#ch4_3">4.3&#160;&#160;&#160;&#160;&#160;&#160;Encoder-Decoder Models</a></p>
<p class="toc"><a href="15_Chapter04.xhtml#ch4_4">4.4&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Embedding Models</a></p>
<p class="toc"><a href="15_Chapter04.xhtml#ch4_5">4.5&#160;&#160;&#160;&#160;&#160;&#160;Perspectives</a></p>
<p class="toc1"><a href="15_Chapter04.xhtml#ch4_6">Focus Questions</a></p>
<p class="toc1"><a href="15_Chapter04.xhtml#ch4_7">References</a></p>
<p class="toct1"><a id="page_xiii"/><a href="16_Part02.xhtml"><b>PART&#160;II&#160;&#160;&#160;MULTIMODAL PROCESSING OF SOCIAL AND EMOTIONAL STATES</b></a></p>
<p class="tocc"><a href="17_Chapter05.xhtml"><b>Chapter&#160;5&#160;&#160;Multimodal User State and Trait Recognition: An Overview</b></a></p>
<p class="toca"><i>Bj&#246;rn Schuller</i></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_1">5.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_2">5.2&#160;&#160;&#160;&#160;&#160;&#160;Modeling</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_3">5.3&#160;&#160;&#160;&#160;&#160;&#160;An Overview on Attempted Multimodal Stait and Trait Recognition</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_4">5.4&#160;&#160;&#160;&#160;&#160;&#160;Architectures</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_5">5.5&#160;&#160;&#160;&#160;&#160;&#160;A Modern Architecture Perspective</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_6">5.6&#160;&#160;&#160;&#160;&#160;&#160;Modalities</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_7">5.7&#160;&#160;&#160;&#160;&#160;&#160;Walk-through of an Example State</a></p>
<p class="toc"><a href="17_Chapter05.xhtml#ch5_8">5.8&#160;&#160;&#160;&#160;&#160;&#160;Emerging Trends and Future Directions</a></p>
<p class="toc1"><a href="17_Chapter05.xhtml#ch5_9">Focus Questions</a></p>
<p class="toc1"><a href="17_Chapter05.xhtml#ch5_10">References</a></p>
<p class="tocc"><a href="18_Chapter06.xhtml"><b>Chapter&#160;6&#160;&#160;Multimodal-Multisensor Affect Detection</b></a></p>
<p class="toca"><i>Sidney K. D&#8217;Mello, Nigel Bosch, Huili Chen</i></p>
<p class="toc"><a href="18_Chapter06.xhtml#ch6_1">6.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="18_Chapter06.xhtml#ch6_2">6.2&#160;&#160;&#160;&#160;&#160;&#160;Background from Affective Sciences</a></p>
<p class="toc"><a href="18_Chapter06.xhtml#ch6_3">6.3&#160;&#160;&#160;&#160;&#160;&#160;Modality Fusion for Multimodal-Multisensor Affect Detection</a></p>
<p class="toc"><a href="18_Chapter06.xhtml#ch6_4">6.4&#160;&#160;&#160;&#160;&#160;&#160;Walk-throughs of Sample Multisensor-Multimodal Affect Detection Systems</a></p>
<p class="toc"><a href="18_Chapter06.xhtml#ch6_5">6.5&#160;&#160;&#160;&#160;&#160;&#160;General Trends and State of the Art in Multisensor-Multimodal Affect Detection</a></p>
<p class="toc"><a href="18_Chapter06.xhtml#ch6_6">6.6&#160;&#160;&#160;&#160;&#160;&#160;Discussion</a></p>
<p class="toc1"><a href="18_Chapter06.xhtml#ch6_7">Acknowledgments</a></p>
<p class="toc1"><a href="18_Chapter06.xhtml#ch6_8">Focus Questions</a></p>
<p class="toc1"><a href="18_Chapter06.xhtml#ch6_9">References</a></p>
<p class="tocc"><a href="19_Chapter07.xhtml"><b>Chapter&#160;7&#160;&#160;Multimodal Analysis of Social Signals</b></a></p>
<p class="toca"><i>Alessandro Vinciarelli, Anna Esposito</i></p>
<p class="toc"><a href="19_Chapter07.xhtml#ch7_1">7.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="19_Chapter07.xhtml#ch7_2">7.2&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Communication in Life and Human Sciences</a></p>
<p class="toc"><a href="19_Chapter07.xhtml#ch7_3">7.3&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Analysis of Social Signals</a></p>
<p class="toc"><a href="19_Chapter07.xhtml#ch7_4">7.4&#160;&#160;&#160;&#160;&#160;&#160;Next Steps</a></p>
<p class="toc"><a href="19_Chapter07.xhtml#ch7_5">7.5&#160;&#160;&#160;&#160;&#160;&#160;Conclusions</a></p>
<p class="toc1"><a id="page_xiv"/><a href="19_Chapter07.xhtml#ch7_6">Focus Questions</a></p>
<p class="toc1"><a href="19_Chapter07.xhtml#ch7_7">References</a></p>
<p class="tocc"><a href="20_Chapter08.xhtml"><b>Chapter&#160;8&#160;&#160;Real-Time Sensing of Affect and Social Signals in a Multimodal Framework: A Practical Approach</b></a></p>
<p class="toca"><i>Johannes Wagner, Elisabeth Andr&#233;</i></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_1">8.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_2">8.2&#160;&#160;&#160;&#160;&#160;&#160;Database Collection</a></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_3">8.3&#160;&#160;&#160;&#160;&#160;&#160;Multimodal Fusion</a></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_4">8.4&#160;&#160;&#160;&#160;&#160;&#160;Online Recognition</a></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_5">8.5&#160;&#160;&#160;&#160;&#160;&#160;Requirements for a Multimodal Framework</a></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_6">8.6&#160;&#160;&#160;&#160;&#160;&#160;The Social Signal Interpretation Framework</a></p>
<p class="toc"><a href="20_Chapter08.xhtml#ch8_7">8.7&#160;&#160;&#160;&#160;&#160;&#160;Conclusion</a></p>
<p class="toc1"><a href="20_Chapter08.xhtml#ch8_8">Focus Questions</a></p>
<p class="toc1"><a href="20_Chapter08.xhtml#ch8_9">References</a></p>
<p class="tocc"><a href="21_Chapter09.xhtml"><b>Chapter&#160;9&#160;&#160;How Do Users Perceive Multimodal Expressions of Affects?</b></a></p>
<p class="toca"><i>Jean-Claude Martin, C&#233;line Clavel, Matthieu Courgeon, Mehdi Ammi, Michel-Ange Amorim, Yacine Tsalamlal, Yoren Gaffary</i></p>
<p class="toc"><a href="21_Chapter09.xhtml#ch9_1">9.1&#160;&#160;&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="21_Chapter09.xhtml#ch9_2">9.2&#160;&#160;&#160;&#160;&#160;&#160;Emotions and Their Expressions</a></p>
<p class="toc"><a href="21_Chapter09.xhtml#ch9_3">9.3&#160;&#160;&#160;&#160;&#160;&#160;How Humans Perceive Combinations of Expressions of Affects in Several Modalities</a></p>
<p class="toc"><a href="21_Chapter09.xhtml#ch9_4">9.4&#160;&#160;&#160;&#160;&#160;&#160;Impact of Context on the Perception of Expressions of Affects</a></p>
<p class="toc"><a href="21_Chapter09.xhtml#ch9_5">9.5&#160;&#160;&#160;&#160;&#160;&#160;Conclusion</a></p>
<p class="toc1"><a href="21_Chapter09.xhtml#ch9_6">Focus Questions</a></p>
<p class="toc1"><a href="21_Chapter09.xhtml#ch9_7">References</a></p>
<p class="toct"><a href="22_Part03.xhtml"><b>PART&#160;III&#160;&#160;&#160;MULTIMODAL PROCESSING OF COGNITIVE STATES</b></a></p>
<p class="tocc1"><a href="23_Chapter10.xhtml"><b>Chapter&#160;10&#160;&#160;Multimodal Behavioral and Physiological Signals as Indicators of Cognitive Load</b></a></p>
<p class="toca"><i>Jianlong Zhou, Kun Yu, Fang Chen, Yang Wang, Syed Z. Arshad</i></p>
<p class="toc"><a href="23_Chapter10.xhtml#ch10_1">10.1&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="23_Chapter10.xhtml#ch10_2">10.2&#160;&#160;&#160;&#160;State-of-the-Art</a></p>
<p class="toc"><a href="23_Chapter10.xhtml#ch10_3">10.3&#160;&#160;&#160;&#160;Behavioral Measures for Cognitive Load</a></p>
<p class="toc"><a id="page_xv"/><a href="23_Chapter10.xhtml#ch10_4">10.4&#160;&#160;&#160;&#160;Physiological Measures for Cognitive Load</a></p>
<p class="toc"><a href="23_Chapter10.xhtml#ch10_5">10.5&#160;&#160;&#160;&#160;Multimodal Signals and Data Fusion</a></p>
<p class="toc"><a href="23_Chapter10.xhtml#ch10_6">10.6&#160;&#160;&#160;&#160;Conclusion</a></p>
<p class="toc1"><a href="23_Chapter10.xhtml#ch10_7">Funding</a></p>
<p class="toc1"><a href="23_Chapter10.xhtml#ch10_8">Focus Questions</a></p>
<p class="toc1"><a href="23_Chapter10.xhtml#ch10_9">References</a></p>
<p class="tocc1"><a href="24_Chapter11.xhtml"><b>Chapter&#160;11&#160;&#160;Multimodal Learning Analytics: Assessing Learners&#8217; Mental State During the Process of Learning</b></a></p>
<p class="toca"><i>Sharon Oviatt, Joseph Grafsgaard, Lei Chen, Xavier Ochoa</i></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_1">11.1&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_2">11.2&#160;&#160;&#160;&#160;What is Multimodal Learning Analytics?</a></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_3">11.3&#160;&#160;&#160;&#160;What Data Resources are Available on Multimodal Learning Analytics?</a></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_4">11.4&#160;&#160;&#160;&#160;What are the Main Themes from Research Findings on Multimodal Learning Analytics?</a></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_5">11.5&#160;&#160;&#160;&#160;What is the Theoretical Basis of Multimodal Learning Analytics?</a></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_6">11.6&#160;&#160;&#160;&#160;What are the Main Challenges and Limitations of Multimodal Learning Analytics?</a></p>
<p class="toc"><a href="24_Chapter11.xhtml#ch11_7">11.7&#160;&#160;&#160;&#160;Conclusions and Future Directions</a></p>
<p class="toc1"><a href="24_Chapter11.xhtml#ch11_8">Focus Questions</a></p>
<p class="toc1"><a href="24_Chapter11.xhtml#ch11_9">References</a></p>
<p class="tocc1"><a href="25_Chapter12.xhtml"><b>Chapter&#160;12&#160;&#160;Multimodal Assessment of Depression from Behavioral Signals</b></a></p>
<p class="toca"><i>Jeffrey F. Cohn, Nicholas Cummins, Julien Epps, Roland Goecke, Jyoti Joshi, Stefan Scherer</i></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_1">12.1&#160;&#160;&#160;&#160;Introduction</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_2">12.2&#160;&#160;&#160;&#160;Depression</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_3">12.3&#160;&#160;&#160;&#160;Multimodal Behavioral Signal Processing Systems</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_4">12.4&#160;&#160;&#160;&#160;Facial Analysis</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_5">12.5&#160;&#160;&#160;&#160;Speech Analysis</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_6">12.6&#160;&#160;&#160;&#160;Body Movement and Other Behavior Analysis</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_7">12.7&#160;&#160;&#160;&#160;Analysis using Other Sensor Signals</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_8">12.8&#160;&#160;&#160;&#160;Multimodal Fusion</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_9">12.9&#160;&#160;&#160;&#160;Implementation-Related Considerations and Elicitation Approaches</a></p>
<p class="toc"><a href="25_Chapter12.xhtml#ch12_10">12.10&#160;&#160;Conclusion and Current Challenges</a></p>
<p class="toc1"><a href="25_Chapter12.xhtml#ch12_11">Acknowledgments</a></p>
<p class="toc1"><a href="25_Chapter12.xhtml#ch12_12">Focus Questions</a></p>
<p class="toc1"><a href="25_Chapter12.xhtml#ch12_13">References</a></p>
<p class="tocc1"><a id="page_xvi"/><a href="26_Chapter13.xhtml"><b>Chapter&#160;13&#160;&#160;Multimodal Deception Detection</b></a></p>
<p class="toca"><i>Mihai Burzo, Mohamed Abouelenien, Veronica Perez-Rosas, Rada Mihalcea</i></p>
<p class="toc"><a href="26_Chapter13.xhtml#ch13_1">13.1&#160;&#160;&#160;&#160;Introduction and Motivation</a></p>
<p class="toc"><a href="26_Chapter13.xhtml#ch13_2">13.2&#160;&#160;&#160;&#160;Deception Detection with Individual Modalities</a></p>
<p class="toc"><a href="26_Chapter13.xhtml#ch13_3">13.3&#160;&#160;&#160;&#160;Deception Detection with Multiple Modalities</a></p>
<p class="toc"><a href="26_Chapter13.xhtml#ch13_4">13.4&#160;&#160;&#160;&#160;The Way Forward</a></p>
<p class="toc1"><a href="26_Chapter13.xhtml#ch13_5">Acknowledgments</a></p>
<p class="toc1"><a href="26_Chapter13.xhtml#ch13_6">Focus Questions</a></p>
<p class="toc1"><a href="26_Chapter13.xhtml#ch13_7">References</a></p>
<p class="toct"><a href="27_Part04.xhtml"><b>PART&#160;IV&#160;&#160;&#160;MULTIDISCIPLINARY CHALLENGE TOPIC</b></a></p>
<p class="tocc1"><a href="28_Chapter14.xhtml"><b>Chapter&#160;14&#160;&#160;Perspectives on Predictive Power of Multimodal Deep Learning: Surprises and Future Directions</b></a></p>
<p class="toca"><i>Samy Bengio, Li Deng, Louis-Philippe Morency, Bj&#246;rn Schuller</i></p>
<p class="toc"><a href="28_Chapter14.xhtml#ch14_1">14.1&#160;&#160;&#160;&#160;Deep Learning as Catalyst for Scientific Discovery</a></p>
<p class="toc"><a href="28_Chapter14.xhtml#ch14_2">14.2&#160;&#160;&#160;&#160;Deep Learning in Relation to Conventional Machine Learning</a></p>
<p class="toc"><a href="28_Chapter14.xhtml#ch14_3">14.3&#160;&#160;&#160;&#160;Expected Surprises of Deep Learning</a></p>
<p class="toc"><a href="28_Chapter14.xhtml#ch14_4">14.4&#160;&#160;&#160;&#160;The Future of Deep Learning</a></p>
<p class="toc"><a href="28_Chapter14.xhtml#ch14_5">14.5&#160;&#160;&#160;&#160;Responsibility in Deep Learning</a></p>
<p class="toc"><a href="28_Chapter14.xhtml#ch14_6">14.6&#160;&#160;&#160;&#160;Conclusion</a></p>
<p class="toc1"><a href="28_Chapter14.xhtml#ch14_7">References</a></p>
<p class="tocxt"><a href="29_Index01.xhtml">Index</a></p>
<p class="tocx"><a href="30_Bm01.xhtml">Biographies</a></p>
<p class="tocx"><a href="31_Glossary.xhtml">Volume 2 Glossary</a></p>
</body>
</html>