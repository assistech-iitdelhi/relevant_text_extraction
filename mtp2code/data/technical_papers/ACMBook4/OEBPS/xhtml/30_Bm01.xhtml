<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Handbook of Multimodal-Multisensor Interfaces, Volume 2: Signal Processing, Architectures, and Detection of Emotion and Cognition</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet.css"/>
<link rel="stylesheet" type="application/vnd.adobe-page-template+xml" href="../styles/page-template.xpgt"/>
</head>
<body>
<p class="bmtitle"><a id="page_499"/><b>Biographies</b></p>
<p class="h2"><b>Editors</b></p>
<p class="noindent"><b>Philip R. Cohen</b> (Monash University) is Director of the Laboratory for Dialogue Research and Professor of Artificial Intelligence in the Faculty of Information Technology at Monash University. His research interests include multimodal interaction, human-computer dialogue, and multi-agent systems. He is a Fellow of the American Association for Artificial Intelligence, past President of the Association for Computational Linguistics, recipient (with Hector Levesque) of the Inaugural Influential Paper Award by the <i>International Foundation for Autonomous Agents and Multi-Agent Systems</i>, and recipient of the 2017 Sustained Achievement Award from the International Conference on Multimodal Interaction.</p>
<p class="indent">He was most recently Chief Scientist in Artificial Intelligence and Senior Vice President for Advanced Technology at Voicebox Technologies, where he led efforts on semantic parsing and dialogue. Cohen founded Adapx Inc. to commercialize multimodal interaction, deploying multimodal systems to civilian and government organizations. Prior to Adapx, he was Professor and Co-Director of the Center for Human-Computer Communication in the Computer Science Department at Oregon Health and Science University and Director of Natural Language in the Artificial Intelligence Center at SRI International. Cohen has published more than 150 articles and has 5 patents. He co-authored the book <i>The Paradigm Shift to Multimodality in Contemporary Computer Interfaces</i> (2015, Morgan &#38; Claypool Publishers) with Dr. Sharon Oviatt. (Contact: <a href="mailto:philip.cohen@monash.edu">philip.cohen@monash.edu</a>)</p>
<p class="noindentt"><b>Antonio Kr&#252;ger</b> (Saarland University and DFKIGmbH) is Professor of Computer Science and Director of the Media Informatics Program at Saarland University, as well as Scientific Director of the Innovative Retail Laboratory at the German Research Center for Artificial Intelligence (DFKI). His research areas focus on intelligent user interfaces, and mobile and ubiquitous context-aware systems. He has been General Chair of the Ubiquitous Computing Conference and Program Chair of MobileHCI, <a id="page_500"/>IUI, and Pervasive Computing. He is also on the Steering Committee of the International Conference on Intelligent User Interfaces (IUI) and an Associate Editor of the journals <i>User Modeling and User-Adapted Interaction</i> and A<i>CM Interactive, Mobile, Wearable and Ubiquitous Technologies</i>. (Contact: <a href="mailto:krueger@dfki.de">krueger@dfki.de</a>)</p>
<p class="noindentt"><b>Sharon Oviatt</b> (Monash University) is internationally known for her multidisciplinary work on multimodal and mobile interfaces, human-centered interfaces, educational interfaces, and learning analytics. She has been recipient of the inaugural ACM-ICMI Sustained Accomplishment Award, National Science Foundation Special Creativity Award, and ACM-SIGCHI CHI Academy award. She has published over 160 scientific articles in a wide range of venues and is an Associate Editor of the major journals and edited book collections in the field of human-centered interfaces. Her other books include <i>The Design of Future Educational Interfaces</i> (2013, Routledge) and <i>The Paradigm Shift to Multimodality in Contemporary Computer Interfaces</i> (2015, Morgan &#38; Claypool Publishers). (Contact: <a href="mailto:sharon.oviatt@monash.edu">sharon.oviatt@monash.edu</a>)</p>
<p class="noindentt"><b>Gerasimos Potamianos</b> (University of Thessaly) is Associate Professor and Director of Graduate Studies in Electrical and Computer Engineering. His research spans multisensory and multimodal speech processing and scene analysis, with applications to human-computer interaction and ambient intelligence. He has authored over 120 articles and has 7 patents. He received a Diploma degree from the National Technical University of Athens, and a M.Sc. and Ph.D. from Johns Hopkins University, all in electrical and computer engineering. In addition to his academic experience, he has worked at AT&#38;T Research Labs, IBM Thomas J. Watson Research Center (US), and at the FORTH and NCSR &#8216;Demokritos&#8217; Research Centers in Greece. (Contact: <a href="mailto:gpotam@ieee.org">gpotam@ieee.org</a>)</p>
<p class="noindentt"><b>Bj&#246;rn Schuller</b> (University of Augsburg and Imperial College London) is currently ZD.B Chair of Embedded Intelligence for Health Care and Wellbeing at University of Augsburg and Reader in Machine Learning at Imperial College. He is best known for his work on multisensorial/multimodal intelligent signal processing for affective, behavioral, and human-centered computing. In 2015 and 2016, he was honored by the World Economic Forum as one of 40/50 extraordinary scientists under age 40. In 2018, he was elevated to Fellow of the IEEE and Senior Member of the ACM. He has published over 700 peer-reviewed scientific contributions across a range of disciplines and venues, and is Editor-in-Chief of <i>IEEE Transactions on Affective Computing</i>. His books include <i>Intelligent Audio Analysis</i> (2013, Springer) and <i>Computational Paralinguistics</i> (2013, Wiley). (Contact: <a href="mailto:bjoern.schuller@imperial.ec.uk">bjoern.schuller@imperial.ec.uk</a>)</p>
<p class="noindentt"><a id="page_501"/><b>Daniel Sonntag</b> (German Research Center for Artificial Intelligence, DFKI) is a Principal Researcher and Research Fellow. His research interests include multimodal and mobile AI-based interfaces, common-sense modeling, and explainable machine learning methods for cognitive computing and improved usability. He has published over 130 scientific articles and was the recipient of the German High Tech Champion Award in 2011 and the AAAI Recognition and IAAI Deployed Application Award in 2013. He is the Editor-in-Chief of the <i>German Journal on Artificial Intelligence (KI)</i> and editor-in-chief of Springer&#8217;s Cognitive Technologies book series. Currently, he leads both national and European projects from the Federal Ministry of Education and Research, the Federal Ministry for Economic Affairs and Energy, and Horizon 2020. (Contact: <a href="mailto:daniel.sonntag@dfki.de">daniel.sonntag@dfki.de</a>)</p>
<p class="h2"><b>Authors and Challenge Discussants</b></p>
<p class="noindent"><b>Mohamed Abouelenien</b> (University of Michigan-Dearborn) is an Assistant Professor in the Department of Computer and Information Science at the University of Michigan-Dearborn. He was a Postdoctoral Research Fellow in the Electrical Engineering and Computer Science Department at the University of Michigan, Ann Arbor from 2014&#8211;2017. In 2013, he received his Ph.D. in Computer Science and Engineering from the University of North Texas. His areas of interest broadly cover data science topics, including applied machine learning, computer vision, and natural language processing. He has worked on a number of projects in these areas, including affective computing, deception detection, ensemble learning, video and image processing, face and action recognition, and others. His recent research involves data analytics projects as well as modeling of human behavior for different applications. Abouelenien has published extensively in international journals and conferences in IEEE, ACM, Springer, and SPIE. He also served as the chair for the ACM Workshop on Multimodal Deception Detection, a reviewer for <i>IEEE Transactions</i> and Elsevier journals, and a program committee member for multiple international conferences.</p>
<p class="noindentt"><b>Chaitanya Ahuja</b> (Carnegie Mellon University) is a doctoral candidate at the Language Technologies Institute in the School of Computer Science at Carnegie Mellon University. His interests range in various topics in natural language, computer vision, computational music, and machine learning. Before starting graduate school, Chaitanya completed his Bachelor&#8217;s degree at the Indian Institute of Technology, Kanpur, with a research focus on spatial audio.</p>
<p class="noindentt"><a id="page_502"/><b>Ethem Alpaydin</b> (Bogazici University) received his degree of Docteur es Sciences from &#201;cole Polytechnique F&#233;d&#233;rale de Lausanne in 1990. Currently, he is a Professor in the Department of Computer Engineering of Bogazici University and a member of The Science Academy, Istanbul. As a visiting researcher, he worked in the Department of Brain and Cognitive Sciences at MIT in 1994, at the International Computer Science Institute at UC Berkeley in 1997, at the Idiap Research Institute in Switzerland in 1998, and at TU Delft in 2014. He was a Fulbright Senior Scholar in 1997/1998 and received the Research Excellence Award from the Bogazici University Foundation in 1998 (junior faculty) and 2008 (senior faculty), the Young Scientist Award from the Turkish Academy of Sciences in 2001, and the Scientific Encouragement Award from the Turkish Scientific and Technical Research Council in 2002. His book <i>Introduction to Machine Learning</i>, published by MIT Press, is now in its third edition and was translated into Chinese, German, and Turkish. <i>Machine Learning: The New AI</i> was also published by MIT Press as part of the Essential Knowledge Series in 2016, and has since been translated into Russian and Japanese. He is a senior Member of the IEEE and an Editorial Board Member of the Pattern Recognition journal, published by Elsevier.</p>
<p class="noindentt"><b>Mehdi Ammi</b> (University of Paris-Saclay) is an Associate Professor at the University of Paris-Saclay. He is also the head of the Pervasive and Ubiquitous Environments team and member of the Architecture and Models for Interaction group at the multidisciplinary LIMSI-CNRS lab. He earned his Ph.D. at the University of Orleans in 2005 with an emphasis on robotics and virtual reality.</p>
<p class="noindentt"><b>Michel-Ange Amorim</b> (Universit&#233; Paris-Sud) is a Full Professor at the Universit&#233; Paris-Sud (UPSUD), Universit&#233; Paris-Saclay, Orsay, France. He received his Ph.D. in cognitive psychology from Universit&#233; Ren&#233; Descartes, Paris, France, in 1997. At UPSUD, he leads CIAMS, a multidisciplinary laboratory investigating human movement, including motor control, psychology, biomechanics, physiology, and behavioral and cognitive neuroscience. His research interests are in embodied cognition combining psychophysics&#8212;the Information Integration Theory approach&#8212;with neuroimaging techniques in normals and patients, in order to decipher the neurocognitive processes underlying spatial and motoric embodiment of self, self-environment, and self-other relationships.</p>
<p class="noindentt"><b>Elisabeth Andr&#233;</b> (Augsburg University) is a Full Professor of Computer Science and Founding Chair of Human-Centered Multimedia at Augsburg University in Germany. She has a long track record in multimodal human-machine interaction, embodied conversational agents, social robotics, affective computing, and social <a id="page_503"/>signal processing. Elisabeth Andr&#233; has served as a General and Program Co-Chair of major international conferences, including ACM International Conference on Intelligent User Interfaces (IUI), ACM International Conference on Multimodal Interfaces (ICMI), and International Conference on Autonomous Agents and Multiagent Systems (AAMAS). In 2010, Elisabeth Andr&#233; was elected a member of the prestigious Academy of Europe, the German Academy of Sciences Leopoldina, and AcademiaNet. To honor her achievements in bringing artificial intelligence techniques to HCI, she was awarded a EurAI (European Coordinating Committee for Artificial Intelligence) fellowship in 2013. Most recently, she was elected to the CHI Academy, an honorary group of leaders in the field of human-computer interaction.</p>
<p class="noindentt"><b>Syed Z. Arshad</b> (University of New South Wales) has a Ph.D. in computer science from the University of New South Wales, Australia. He is a member of IEEE, ACM, SIGCHI, and SIGKDD. His research interests include cognitive computing, intelligent user interfaces, machine learning, and data visualization techniques.</p>
<p class="noindentt"><b>Tadas Baltru&#353;aitis</b> (Microsoft) is a scientist at Microsoft in Cambridge, UK. His primary research interests lie in the automatic understanding of non-verbal human behavior, computer vision, and multimodal machine learning. In particular, he is interested in the application of such technologies to healthcare settings, with a focus on mental health. Before joining Microsoft, he was a post-doctoral researcher at Carnegie Mellon University, working on multimodal machine learning and automatic facial behavior analysis. He received his Ph.D. at the University of Cambridge, where his work focused on automatic facial expression analysis in especially difficult real-world settings.</p>
<p class="noindentt"><b>Samy Bengio</b> (Google) has been a research scientist at Google since 2007. Before that, he had been a senior researcher in statistical machine learning at IDIAP Research Institute, where he supervised Ph.D. students and postdoctoral fellows. His research interests span many areas of machine learning such as deep architectures, representation learning, sequence processing, speech recognition, image understanding, support vector machines, mixture models, large-scale problems, multi-modal (face and voice) person authentication, brain&#8211;computer interfaces, and document retrieval. He was the program chair of NIPS 2017 and ICLR 2015 and 2016; was the general chair of BayLearn 2012&#8211;2015, the Workshops on Machine Learning for Multimodal Interactions (MLMI) 2004&#8211;2006, and the IEEE Workshop on Neural Networks for Signal Processing (NNSP) in 2002; and served on the program committees of several international conferences such as NIPS, ICML, ICLR, ECML and IJCAI.</p>
<p class="noindentt"><a id="page_504"/><b>Nigel Bosch</b> (University of Illinois at Urbana-Champaign) is a postdoctoral researcher with the National Center for Supercomputing Applications. His research utilizes data mining and machine learning techniques to understand human experiences including emotion, cognition, and behavior. His current interests are focused on developing methods to model new forms of big multimodal data in online educational contexts, as well as studying the ethical implications of machine learning models trained in these contexts. He received his Ph.D. in computer science from the University of Notre Dame.</p>
<p class="noindentt"><b>Mihai Burzo</b> (University of Michigan-Flint) is an Assistant Professor of Mechanical Engineering at the University of Michigan-Flint. Prior to joining University of Michigan in 2013, he was an Assistant Professor at University of North Texas. His research interests include heat transfer in microelectronics and nanostructures, thermal properties of thin films of new and existing materials, multimodal sensing of human behavior, and computational modeling of forced and natural heat convection. He has published over 50 articles in peer-reviewed journals and conference proceedings. He is the recipient of several awards, including the 2006 Harvey Rosten Award For Excellence for &#8220;outstanding work in the field of thermal analysis of electronic equipment,&#8221; best paper award at the Semitherm conferences in 2013 and 2006, Young Engineer of the Year from the North Texas Section of ASME in 2006, and Leadership Award from SMU in 2002.</p>
<p class="noindentt"><b>Fang Chen</b> (DATA61, CSIRO) is a Senior Principal Research Scientist of Analytics in DATA61, CSIRO. She holds a Ph.D. in Signal and Information Processing, an M.Sc. and B.Sc. in Telecommunications and Electronic Systems, respectively, and an MBA. Her research interests are behavior analytics, machine learning, and pattern recognition in human and system performance prediction and evaluation. She has done extensive work on human-machine interaction and cognitive load modeling. She pioneered the theoretical framework of measuring cognitive load through multimodal human behavior and provided much of the empirical evidence on using human behavior signals and physiological responses to measure and monitor cognitive load.</p>
<p class="noindentt"><b>Huili Chen</b> (MIT) is a Ph.D. student at the MIT Media Lab. She obtained a Bachelor of Arts degree in Psychology and earned a Bachelor of Science degree in Computer Science from the University of Notre Dame in 2016. She is very interested in human-machine interaction and interactive artificial intelligence.</p>
<p class="noindentt"><b>Lei Chen</b> (Liulishuo Inc.) is a Principal Research Scientist at Liulishuo&#8217;s AI Lab located in Silicon Valley who explores using AI technologies on improving language <a id="page_505"/>education. Prior to Liulishuo, he worked at Educational Testing Service (ETS) from 2008&#8211;2017. At ETS, his research focused on the automated assessment of spoken language using speech recognition, natural language processing, and machine learning technologies. Since 2013, he has been working on multimodal signal processing technology for assessing video-based performance tests in areas such as public-speaking. In the 2009 International Conference of Multimodal Interface (ICMI), he won the Outstanding Paper Award sponsored by Google. He received a B.Eng. degree from Tianjin University in China, an M.Sc. degree from the Chinese Academy of Science (CAS), and a Ph.D. degree from Purdue University. All of his degrees are in electrical engineering.</p>
<p class="noindentt"><b>C&#233;line Clavel</b> (Universit&#233; Paris-Sud) received a Ph.D. in Cognitive Psychology from the Universit&#233; Paris Ouest Nanterre La D&#233;fense in 2007. In September 2010, she became an Assistant Professor at Universit&#233; Paris-Sud and teaches in the department of Accounting and Management in the Sceaux Institute of Applied Sciences and in the Ergonomic Master. Her research is focused on the emotional process in a virtual or real social interaction context and on the multi-user multimodal interactions in Collaborative Virtual Environments (CVEs). Her main research interest is to specify the psychology models to computer science applications and evaluate their contributions and/or study their impacts on behavior.</p>
<p class="noindentt"><b>Jeffrey Cohn</b>, Ph.D. (University of Pittsburg and Carnegie Mellon University), is Professor of Psychology and Psychiatry at the University of Pittsburgh and Adjunct Professor at the Robotics Institute, Carnegie Mellon University. He leads interdisciplinary and inter-institutional efforts to develop advanced methods of automatic analysis and synthesis of face and body movement and applies them to research in human emotion, communication, psychopathology, and biomedicine. His research has been supported by grants from the U.S. National Institutes of Health and U.S. National Science Foundation, among other sponsors. He chairs the Steering Committee of the IEEE International Conference on Automatic Face and Gesture Recognition (FG) and has served as General Chair of international conferences on automatic face and gesture recognition, affective computing, and multimodal interfaces.</p>
<p class="noindentt"><b>Matthieu Courgeon</b> (&#201;cole Nationale d&#8217;Ing&#233;nieurs de Brest) defended his Ph.D. thesis in 2011 on affective computing and interactive autonomous virtual characters. He is the creator of the Multimodal Affective and Reactive Characters toolkit, used by several research teams around the world. His research area spans interactive expressive artificial humans and robots to collaborative immersive virtual reality. He earned a Best Paper Award at Ubicomp 2013 for his work with expressive virtual humans with the Affective Computing team at the MIT Medialab.</p>
<p class="noindentt"><a id="page_506"/><b>Dr. Nicholas Cummins</b> (University of Augsburg) is a habilitation candidate at the Chair of Embedded Intelligence for Health Care and Wellbeing at the University of Augsburg. He received his Ph.D. in Electrical Engineering from UNSW Australia in February 2016. He is currently involved in the Horizon 2020 projects DE-ENIGMA, RADAR-CNS, and TAPAS. His current research interests include multisenory signal analysis, affective computing, and computer audition with a particular focus on the understanding and analysis of different health states. He has (co)authored over 50 conference and journal papers (over 400 citations, h-index 12). Dr. Cummins is a reviewer for IEEE, ACM, and ISCA journals and conferences, as well as serving on their program and organizational committees. He is a member of ACM, ISCA, IEEE, and the IET.</p>
<p class="noindentt"><b>Li Deng</b> (Citadel) has been the Chief Artificial Intelligence Officer of Citadel since May 2017. Prior to Citadel, he was the Chief Scientist of AI, the founder of Deep Learning Technology Center, and Partner Research Manager at Microsoft (2000&#8211;2017). Prior to Microsoft, he was a tenured full professor at the University of Waterloo and held teaching and research positions at Massachusetts Institute of Technology (1992&#8211;1993), Advanced Telecommunications Research Institute (1997&#8211;1998), and HK University of Science and Technology (1995). He has been a Fellow of the IEEE since 2004, a Fellow of the Acoustical Society of America since 1993, and a Fellow of the ISCA since 2011. He has also been an Affiliate Professor at University of Washington, Seattle, since 2000. He was elected to the Board of Governors of the IEEE Signal Processing Society and served as editor-in-chief of the <i>IEEE Signal Processing Magazine</i> and IEEE/ACM <i>Transactions on Audio, Speech, and Language Processing</i> from 2008&#8211;2014, for which he received the IEEE SPS Meritorious Service Award. In recognition of his pioneering work on disrupting the speech recognition industry using large-scale deep learning, he received the 2015 IEEE SPS Technical Achievement Award for &#8220;Outstanding Contributions to Automatic Speech Recognition and Deep Learning.&#8221; He also received numerous best paper and patent awards for contributions to artificial intelligence, machine learning, information retrieval, multimedia signal processing, speech processing and recognition, and human language technology. He is an author or co-author of six technical books on deep learning, speech processing, pattern recognition and machine learning, and natural language processing.</p>
<p class="noindentt"><b>Sidney D&#8217;Mello</b> (University of Colorado Boulder) is an Associate Professor in the Institute of Cognitive Science and Department of Computer Science at the University <a id="page_507"/>of Colorado Boulder. He is interested in the dynamic interplay between cognition and emotion while individuals and groups engage in complex real-world tasks. He applies insights gleaned from this basic research program to develop intelligent technologies that help people achieve their fullest potential by coordinating what they think and feel with what they know and do. D&#8217;Mello has co-edited 6 books and published over 220 journal papers, book chapters, and conference proceedings (13 of these have received awards). His work has been funded by numerous grants and he serves or has served as associate editor for four journals and on the editorial boards for six others while also playing leadership roles in several professional organizations.</p>
<p class="noindentt"><b>Julien Epps</b> (UNSW Sydney and Data61, CSIRO) is an Associate Professor of Signal Processing with UNSW Sydney and a Contributed Principal Researcher at Data61, CSIRO. He has authored or co-authored more than 200 publications and 4 patents, mainly on topics related to emotion and mental state recognition of speech and behavioral signals. He is serving as an Associate Editor for <i>IEEE Transactions on Affective Computing</i> and <i>Frontiers in ICT</i> (the Human-Media Interaction and Psychology sections), and he recently served as a member of the Advisory Board of the ACM International Conference on Multimodal Interaction. He has delivered invited tutorials on topics related to this book for major conferences, including INTERSPEECH 2014 and 2015 and APSIPA 2010, and invited keynotes for the 4th International Workshop on Audio-Visual Emotion Challenge (part of ACM Multimedia 2014) and the 4th International Workshop on Context-Based Affect Recognition (part of AAAC/IEEE Affective Computing and Intelligent Interaction 2017).</p>
<p class="noindentt"><b>Marc Ernst</b> (Ulm University) heads the Department of Applied Cognitive Psychology at Ulm University. He studied physics in Heidelberg and Frankfurt/Main. In 2000, he received his Ph.D. from the Eberhard-Karls-University T&#252;bingen for investigations into the human visuomotor behavior that he conducted at the Max Planck Institute for Biological Cybernetics. For this work, he was awarded the Attempto-Prize from the University of T&#252;bingen and the Otto-Hahn-Medaille from the Max Planck Society. He was a research associate at the University of California, Berkeley working with Prof. Martin Banks on psychophysical experiments and computational models investigating the integration of visual-haptic information before returning to the MPI in T&#252;bingen and becoming principle investigator of the Sensorimotor Lab in the Department of Professor Heinrich B&#252;lthoff. In 2007, he became leader of the Max Planck Research Group on Human Multisensory Perception and Action, before joining the University of Bielefeld and the Cognitive Interaction Technology Center of Excellence (CITEC) in 2011.</p>
<p class="noindentt"><a id="page_508"/><b>Anna Esposito</b> (Wright State University) received her Laurea degree <i>summa cum laude</i> in Information Technology and Computer Science from the Universit&#224; di Salerno in 1989 with the thesis &#8220;The Behavior and Learning of a Deterministic Neural Net&#8221; (published in <i>Complex System</i>, 6(6), 507&#8211;517, 1992). She received her Ph.D. in Applied Mathematics and Computer Science from the Universit&#224; di Napoli Federico II in 1995. Her Ph.D. thesis &#8220;Vowel Height and Consonantal Voicing Effects: Data from Italian&#8221; (published in <i>Phonetica</i>, 59(4),197&#8211;231, 2002) was developed at the MIT Research Laboratory of Electronics (RLE), under the supervision of professor Kenneth N. Stevens. She completed a postdoctoral program at the International Institute for Advanced Scientific Studies (IIASS), and was Assistant Professor in the Department of Physics at Universit&#224; di Salerno, where she taught classes on cybernetics, neural networks, and speech processing (1996&#8211;2000). She was a Research Professor in the Department of Computer Science and Engineering at Wright State University (WSU) (2000&#8211;2002). She is currently a Research Affiliate at WSU and Associate Professor in Computer Science in the Department of Psychology at Universit&#224; della Campania Luigi Vanvitelli. She has authored more than 170 peer-reviewed publications in international journals, books, and conference proceedings and edited or co-edited over 25 international books with Italian, EU, and overseas colleagues.</p>
<p class="noindentt"><b>Yoren Gaffary</b> (Insa Rennes) is an expert research engineer on haptic simulations in virtual environments at Insa Rennes, France. His research interests are in affective computing, haptics, and augmented reality. He received a Master&#8217;s degree in Information, Learning, and Cognition at Universit&#233; Paris-Sud. His Ph.D.thesis, also at Universit&#233; Paris-Sud, concerned affective computing using mediated touch with robotic devices coupled with virtual humans.</p>
<p class="noindentt"><b>Roland Goecke</b> (University of Canberra) is Professor of Affective Computing in the School of Information Technology &#38; Systems in the Faculty of Science &#38; Technology at the University of Canberra. Professor Goecke holds a Master&#8217;s degree in Computer Science (1998) from the University of Rostock, Germany, and a Ph.D. (2004) in Computer Science from the Australian National University, Canberra, Australia. Prior to joining the University of Canberra in 2008, he worked as a Senior Research Scientist with Seeing Machines, as a Researcher at the NICTA Canberra Research Lab, and as a Research Fellow at the Fraunhofer Institute for Computer Graphics, Germany. His research interests are in affective computing, computational behavior analysis, social signal processing, pattern recognition, computer vision, human-computer interaction, multimodal signal processing, and e-research.</p>
<p class="noindentt"><a id="page_509"/><b>Joseph F. Grafsgaard</b> (University of Colorado Boulder) received a B.A. in Computer Science from the University of Minnesota Twin Cities in 2005, and M.Sc. and Ph.D. degrees in Computer Science from North Carolina State University in 2012 and 2014, respectively. He is currently a postdoctoral research associate at the Institute of Cognitive Science at the University of Colorado Boulder. His research interests include affective computing, advanced learning technologies, detection/modeling of nonverbal behavior and physiology, and multimodal affective interaction. He is a member of the Association for the Advancement of Affective Computing (AAAC), the ACM, the IAIED Society, the IEDM Society, and the IEEE.</p>
<p class="noindentt"><b>Jyoti Joshi</b> (University of Canberra) is a postdoctoral researcher at the University of Waterloo. She earned a Ph.D. at the Human-Centred Computing lab at the University of Canberra, Australia, and is supervised by Prof. Roland Goecke and Prof. Michael Wagner. Before starting her Ph.D., she worked as a research assistant with Vision and Sensing Group, University of Canberra. She also worked as a consultant at a leading EDA company Cadence Design Systems, India prior to coming to Australia. Her current research revolves around applications of pattern recognition, computer vision, and machine learning techniques with a focus on affect-based multimedia analysis.</p>
<p class="noindentt"><b>Gil Keren</b> (University of Passau) is a doctoral student at the University of Passau, Germany. Prior to that, he completed Bachelor&#8217;s and Master&#8217;s degrees in Psychology and Mathematics at Ben Gurion University, Israel. He conducts research and publishes academic papers on the topics of artificial neural networks, artificial intelligence, and models of human cognition.</p>
<p class="noindentt"><b>Jean-Claude Martin</b> (Universit&#233; Paris-Sud) is first-class Full Professor of Computer Science at Universit&#233; Paris-Sud. He is the head of the pluridisciplinary Cognition Perception Use research group at LIMSI-CNRS. He conducts research on the sensory-motor bases of social cognition in humans and in multimodal interfaces, such as expressive virtual agents and social robots. He considers several application areas related to social skills training: autism; job and medical interviews; virtual coaches; leadership and teamwork; stress management; and sports and e-Health. He is the Editor-in-Chief of the Springer <i>Journal on Multimodal User Interfaces</i> (JMUI). He has been involved in several projects about how we perceive (in)congruent blends of expressions of emotions in several modalities. He supervised and co-supervised 14 defended Ph.D. theses.</p>
<p class="noindentt"><b>Rada Mihalcea</b> (University of Michigan) is a Professor in the Computer Science and Engineering department at the University of Michigan. Her research interests <a id="page_510"/>are in computational linguistics with a focus on lexical semantics, computational social sciences, and conversational interfaces. She serves or has served on the editorial boards of the <i>Journals of Computational Linguistics, Language Resources and Evaluations, Natural Language Engineering, Research in Language in Computation, IEEE Transactions on Affective Computing</i>, and <i>Transactions of the Association for Computational Linguistics</i>. She was a program co-chair for the Conferences of the Association for Computational Linguistics (2011) and the Empirical Methods in Natural Language Processing (2009), and general chair for the Conference of the North American Chapter of the Association for Computational Linguistics (2015). She is the recipient of a National Science Foundation CAREER award (2008) and a Presidential Early Career Award for Scientists and Engineers (2009).</p>
<p class="noindentt"><b>Louis-Philippe Morency</b> (Carnegie Mellon University) is Assistant Professor in the Language Technology Institute at Carnegie Mellon University, where he leads the Multimodal Communication and Machine Learning Laboratory (MultiComp Lab). He was formerly a research assistant professor in the Computer Sciences Department at the University of Southern California and a research scientist at the USC Institute for Creative Technologies. Professor Morency received his Ph.D. and Master&#8217;s degrees from MIT Computer Science and Artificial Intelligence Laboratory. His research focuses on building the computational foundations to enable computers with the abilities to analyze, recognize, and predict subtle human communicative behaviors during social interactions. In particular, Professor Morency was lead co-investigator for the multi-institution effort that created SimSensei and Multi-Sense, two technologies to automatically assess nonverbal behavior indicators of psychological distress. He is currently chair of the advisory committee for ACM International Conference on Multimodal Interaction and associate editor at <i>IEEE Transactions on Affective Computing</i>.</p>
<p class="noindentt"><b>Amr El-Desoky Mousa</b> (Apple Inc.) received his Ph.D. in 2014 from the Chair of Human Language Technology and Pattern Recognition at RWTH Aachen University, Germany, where his research was focused on automatic speech recognition. In 2014&#8211;2015, he worked as a postdoctoral researcher at the Machine Intelligence and Signal Processing Group at the Technical University of Munich, Germany. In 2016&#8211;2017, he worked as a Research and Teaching Associate at the Chair of Complex and Intelligent Systems, University of Passau, Germany. In June 2017, he moved to Apple Inc. to work as a senior Machine Learning Engineer taking part in the research and development related to Siri, one of the most well-known speech-based Intelligent Assistants in the world. His main research interests include deep learning, <a id="page_511"/>large vocabulary continuous speech recognition, language modeling, acoustic modeling, and natural language processing.</p>
<p class="noindentt"><b>Xavier Ochoa</b> (Escuela Superior Polit&#233;cnica del Litoral) is currently a Full Professor in the Faculty of Electrical and Computer Engineering at Escuela Superior Polit&#233;cnica del Litoral (ESPOL) in Guayaquil, Ecuador. He directs the Information Technology Center (CTI) and the research group on Teaching and Learning Technologies (TEA) at ESPOL. He is currently the Vice President of the Society for the Research in Learning Analytics (SoLAR), member of the coordination team of the Latin American Community on Learning Technologies (LACLO), and president of the Latin American Open Textbooks Initiative (LATIn). He is editor of the <i>Journal of Learning Analytics</i> and member of the Editorial Board of the <i>IEEE Transactions on Learning Technologies</i>. He coordinates several regional and international projects in the field of learning technologies. His main research interests revolve around learning analytics, multimodal learning analytics, and data science.</p>
<p class="noindentt"><b>Yannis Panagakis</b> (Middlesex University and Imperial College London) is an assistant professor at Middlesex University London and research faculty at the Department of Computing, Imperial College London. His research interests lie in machine learning and its interface with signal processing, high-dimensional statistics, and computational optimization. Specifically, Yannis is working on models and algorithms for robust and efficient learning from high-dimensional data and signals representing audio, visual, affective, and social phenomena. He received his M.Sc. and Ph.D. from the Department of Informatics at Aristotle University of Thessaloniki and his B.Sc. in Informatics and Telecommunication from the University of Athens, Greece. Yannis has been awarded the prestigious Marie-Curie Fellowship, among various scholarships and awards for his studies and research.</p>
<p class="noindentt"><b>Maja Panti&#263;</b> (Imperial College London) is a Professor of Affective and Behavioral Computing and leader of the i&#183;BUG group at Imperial College London, working on machine analysis of human non-verbal behavior and its applications to humancomputer, human-robot, and computer-mediated human-human interaction. Professor Panti&#263; has published more than 250 technical papers in the areas of machine analysis of facial expressions, machine analysis of human body gestures, audiovisual analysis of emotions and social signals, and human-centered machine interfaces. She has served as the keynote speaker, chair and co-chair, and an organization or program committee member at numerous conferences in her areas of expertise. She received a B.Sc. from Delft University in 1995, followed by an M.Sc. <a id="page_512"/>in Artificial Intelligence in 1997. Panti&#263; earned a Ph.D. in 2001 at the Delft University of Technology, with a thesis on facial expression analysis by computational intelligence techniques.</p>
<p class="noindentt"><b>Veronica Perez-Rosas</b> (University of Michigan) is an Assistant Research Scientist of Computer Science and Engineering at the University of Michigan. Her main research interest areas are natural language processing (NLP), computational linguistics, applied machine learning, and multimodal interaction. Her work examines human communication to build computational models able to analyze, recognize, and predict affect-related behaviors during social interaction. She has developed methods that make use of multimodal information present during the social interaction (verbal and non-verbal) and combine data-driven approaches with linguistic and psycho-linguistic knowledge to build novel solutions to diverse NLP problems such as sentiment analysis and deception detection. She has publications in reputable journals and conferences, including IEEE, ACM, and ACL. She also served as a reviewer for <i>IEEE Transactions</i> and Elsevier journals and served as a program committee member for multiple international conferences in the NLP community.</p>
<p class="noindentt"><b>Olivier Pietquin</b> (Google) completed his Ph.D. under the Faculty of Engineering at l&#8217;Universiste de Mons, Belgium, and the University of Sheffield, UK. He then did a postdoctoral program with Philips in Germany before joining the Ecole Sup&#233;rieure d&#8217;Electricit&#233;, France, in 2005, as an Associate Professor and, later, Professor. He headed the computer science program of the UMI GeorgiaTech-CNRS (joint lab in Metz) and also worked with the INSERM IADI team. In 2013, he moved to the University of Lille, France, as a Full Professor and joined the Inria SequeL (Sequential Learning) team. Since 2016, Olivier has been on leave with Google, first with DeepMind in London, and then with Brain in Paris. His current research is about direct and inverse reinforcement learning, learning from demonstrations, and applications to human-machine interaction.</p>
<p class="noindentt"><b>Fabio Ramos</b> (University of Sydney) is an Associate Professor in Machine Learning and Robotics at the School of Information Technologies and co-Director of the Centre for Translational Data Science at the University of Sydney. He received B.Sc. and M.Sc. degrees in Mechatronics Engineering at the University of Sao Paulo, Brazil, in 2001 and 2003, respectively, and a Ph.D. at the University of Sydney, Australia, in 2008. He was an ARC postdoctoral fellow from 2008&#8211;2010, and an ARC DECRA fellow from 2012&#8211;2014. He has authored over 130 peer-reviewed publications and received numerous awards. His research focuses on statistical machine learning <a id="page_513"/>techniques for large-scale data fusion with applications in robotics, mining, environmental monitoring, and healthcare.</p>
<p class="noindentt"><b>Arun Ross</b> (Michigan State University) is a Professor in the Department of Computer Science and Engineering and the Director of the i-PRoBe Lab at Michigan State University (MSU). He was a faculty member at West Virginia University (WVU) from 2003&#8211;2012 and the Assistant Site Director of the NSF Center for Identification Technology and Research (CITeR) from 2010&#8211;2012. Arun received his B.E. (Hons.) in Computer Science from the Birla Institute of Technology and Science, Pilani, India, and his M.S. and Ph.D. in Computer Science and Engineering from MSU. He coauthored the textbook <i>Introduction to Biometrics</i> and the monograph <i>Handbook of Multibiometrics</i>, and coedited the <i>Handbook of Biometrics</i>. He received the IAPR JK Aggarwal Prize, the IAPR Young Biometrics Investigator Award, and the NSF CAREER Award and was an invited speaker at the Frontiers of Science Symposium organized by the National Academy of Sciences in 2006. He also received the 2005 Biennial Best Paper Award from the <i>Pattern Recognition Journal</i> and the Five-Year Highly Cited BTAS 2009 Paper Award. Arun served as a panelist at an event organized by the United Nations Counter-Terrorism Committee (CTC) at the UN Headquarters in 2013. He was an Associate Editor of <i>IEEE Transactions on Information Forensics and Security</i> (2009&#8211;2013) and <i>IEEE Transactions on Image Processing</i> (2008&#8211;2013). He currently serves as Associate Editor of <i>IEEE Transactions on Circuits and Systems for Video Technology</i>, Senior Area Editor of <i>IEEE Transactions on Image Processing</i>, Area Editor of the <i>Computer Vision and Image Understanding Journal</i>, Associate Editor of the <i>Image and Vision Computing Journal</i>, and Chair of the IAPR TC4 on Biometrics.</p>
<p class="noindentt"><b>Ognjen</b> (Oggi) Rudovic (MIT) is a Postdoctoral, Marie Curie, Fellow in the Affective Computing Group at MIT Media Lab, working on personalized machine learning for affective robots and analysis of human data. His background is in automatic control theory, computer vision, artificial intelligence, and machine learning. In 2014, he received a Ph.D. from Imperial College London, UK, where he worked on machine learning and computer vision models for automated analysis of human facial behavior. His current research focus is on developing machine-learning-driven assistive technologies for individuals on the autism spectrum.</p>
<p class="noindentt"><b>Stefan Scherer</b> (Embodied, Inc. and USC) is the CTO of Embodied, Inc. and a Research Assistant Professor in the Department of Computer Science at the University of Southern California (USC) and the USC Institute for Creative Technologies (ICT), where he leads research projects funded by National Science Foundation and the 765Army Research Laboratory. Stefan Scherer directs the lab for Behavior Analytics <a id="page_514"/>and Machine Learning and is the Associate Director of Neural Information Processing at the ICT. He received the degree of Dr. rer. nat. from the faculty of Engineering and Computer Science at Ulm University in Germany with the grade <i>summa cum laude</i> (i.e. with distinction) in 2011. His research aims to automatically identify characterize, model, and synthesize individuals&#8217; multimodal nonverbal behavior within both human-machine as well as machine-mediated human-human interaction. His research was recently featured in the <i>Economist</i>, the <i>Atlantic</i>, and the <i>Guardian</i>, and was awarded a number of best paper awards in renowned international conferences. His work is focused on machine learning, multimodal signal processing, and affective computing. Stefan Scherer serves as an Associate Editor of the Journal <i>IEEE Transactions on Affective Computing</i> and is the Vice Chair of the IAPR Technical Committee 9 on Pattern Recognition in Human-Machine Interaction.</p>
<p class="noindentt"><b>Mohamed Yacine Tsalamlal</b> (LIMSI-CNRS Lab) received a Master&#8217;s degree in Human-Machine Systems engineering from Universit&#233; de Lorraine, France, and a Ph.D. degree in Computer Science from the Universit&#233; Paris-Saclay. He is a postdoctoral researcher with the Architectures and Models for Interaction Group at the LIMSI-CNRS Lab. His research interests include the study of tactile interaction techniques for mediated social communication. He exploits multiple approaches (mechanics, robotics, experimental phycology) to help in the design of efficient multimodal affective interaction systems.</p>
<p class="noindentt"><b>Alessandro Vinciarelli</b> (University of Glasgow) is a Full Professor in the School of Computing Science at the University of Glasgow and an associated academic at the Institute of Neuroscience and Psychology. His main research interest is social signal processing, the domain aimed at modeling, analyzing, and synthesizing nonverbal behavior in human-human and human-machine interactions. He has published over 130 works and has been Principal Investigator or co-Principle Investigator of more than 15 national and international projects. He has chaired and co-chaired more than 30 international events and is the co-founder of Klewel, a knowledge management company recognized with several awards.</p>
<p class="noindentt"><b>Johannes Wagner</b> (University of Augsburg) graduated with a Master of Science in Informatics and Multimedia in 2007 and received a doctoral degree for his study &#8220;Online Systems for Multimodal Behaviour Analysis&#8221; in 2016. He is currently employed as a research assistant at the lab of Human Centered Multimedia (HCM) at he University of Augsburg and has been working on several European projects (Humaine, Callas, Ilhaire, CEEDs, Kristina, AriaValuspa). His main research focus <a id="page_515"/>is the integration of Social Signal Processing (SSP) in real-life applications. He is the founder of the Social Signal Interpretation (SSI) framework, a general framework for the integration of multiple sensors into multimedia applications.</p>
<p class="noindentt"><b>Yang Wang</b> (DATA61, CSIRO) is a Principal Research Scientist of Analytics in DATA61, CSIRO. He received his Ph.D. in Computer Science from the National University of Singapore in 2004. His research interests include machine learning and information fusion techniques and their applications to intelligent infrastructure, cognitive, and emotive computing.</p>
<p class="noindentt"><b>Kun Yu</b> (DATA61, CSIRO) is a Research Scientist in DATA61, CSIRO. He received his Ph.D. in Electrical Engineering from University of New South Wales, Australia. His research interests include human-computer interaction, cognitive load examination, human trust calibration, and multimodal human-machine interfaces.</p>
<p class="noindentt"><b>Stefanos Zafeiriou</b> (Imperial College London) is a Reader in Machine Learning and Computer Vision with the Department of Computing, Imperial College London and a Distinguishing Research Fellow with the University of Oulu in the Finish Distinguishing Professor Program. In 2011, he was a recipient of the Prestigious Junior Research Fellowships from Imperial College London to start his own independent research group. He was the recipient of the President&#8217;s Medal for Excellence in Research Supervision for 2016. He has coauthored more than 55 papers, mainly on novel statistical machine learning methodologies applied to computer vision problems, such as 2-D/3-D face analysis, deformable object fitting and tracking, shape from shading, and human behavior analysis, published in the most prestigious journals in his field of research and many top conferences, such as CVPR, ICCV, ECCV, and ICML.</p>
<p class="noindentt"><b>Jianlong Zhou</b> (DATA61, CSIRO) is a Senior Research Scientist of Analytics in DATA61, CSIRO. He earned a Ph.D. in Computer Science from the University of Sydney, Australia. His research interests include transparent machine learning, human-computer interaction, cognitive computing, visualization, spatial augmented reality, and related applications.</p>
</body>
</html>