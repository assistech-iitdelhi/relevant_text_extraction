<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Handbook of Multimodal-Multisensor Interfaces, Volume 2: Signal Processing, Architectures, and Detection of Emotion and Cognition</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet.css"/>
<link rel="stylesheet" type="application/vnd.adobe-page-template+xml" href="../styles/page-template.xpgt"/>
</head>
<body>
<p class="chno"><a id="page_419"/>13</p>
<p class="chtitle"><b>Multimodal Deception Detection</b></p>
<p class="chauthor"><b>Mihai Burzo, Mohamed Abouelenien, Veronica Perez-Rosas, Rada Mihalcea</b></p>
<p class="h1-1"><a id="ch13_1"/><b><span class="bg1">13.1</span>&#160;&#160;&#160;&#160;Introduction and Motivation</b></p>
<p class="noindent">Deception is defined as an intentional attempt to mislead others [Depaulo et al. 2003]. Deceptive behavior ranges from simple harmless lies to major threats. The detection of such behaviors has been receiving increased attention from different research communities, including computer vision, psychology, and language processing, as deception permeates almost every human interaction and can have costly consequences. Additionally, there exists an international interest in detecting deceivers due to the alarming security incidents that occurred in the recent years. For example, airports are places where detecting deception is vital. Terrorists can deceive customs and borders interviewers and conceal essential information that could be life-threatening. Another example can be seen in the court of law. Thousands of trials occur daily where juries have to take on serious decisions that can affect the lives of suspects and victims based not only on evidence, but on human judgment as well [Fornaciari and Poesio 2013a].</p>
<p class="indent">Applications such as security, business, and criminal investigation triggered research interest in different fields. Existing methodologies rely mainly on polygraph tests that extract physiological measurements such as heart rate, respiration rate, skin conductance, and skin temperature. This approach had proven to falsely accuse the innocent and free the guilty in multiple cases. Employing polygraph tests was shown to be unreliable in many cases as it requires decisions from human experts, which is subject to bias and error [Derksen 2012, Gannon et al. 2009]. Reports dating back three decades indicated that polygraph results were false one third of the time [Lykken 1984].</p>
<p class="indent"><a id="page_420"/>Multiple factors can affect the reliability of polygraphs such as the fear of being perceived as deceptive and the anxiety about being tested [Council 2003]. Furthermore, with the appropriate training, suspects can easily fake innocence using specific countermeasures [Ganis et al. 2011], such as lying in the pre-test questions, muscle tensing, or tongue biting.</p>
<p class="indent">An existing problem with evaluating polygraph testing is that the quality of the data available for evaluation is relatively low [Council 2003]. However, an evaluation attempt was conducted using 59 datasets collected during different decades from 57 studies (52 laboratory, 7 field) including 3,681 polygraph examinations. The study reported a wide range of accuracy index values starting from approximately 0.5 to more than 0.95 for the 52 laboratory studies and from approximately 0.7 to 1 for the field studies. As a result of the unreliability of polygraph testing, the U.S. Supreme court acted to restrict their use in legal proceedings in 1998.</p>
<p class="indent">As detecting deceit has expanded to other applications such as social media, interviews, online transactions, and deception in daily life, alternative approaches were proposed in order to improve the reliability of deception detection systems [Granhag and Hartwig 2008]. In particular, physiological, psychological, visual, linguistic, acoustic, and thermal modalities have been analyzed in order to detect discriminative features and clues to identify deceptive behavior [Owayjan et al. 2012, Pfister and Pietik&#228;inen 2012, Hillman et al. 2012, Zhou et al. 2013, Rajoub and Zwiggelaar 2014, Feng et al. 2012].</p>
<p class="indent">Linguistic features were usually extracted from the language, words usage, and consistency of the statements made by a person [Howard and Kirchh&#252;bel 2011, Vrij et al. 2010, Mihalcea and Strapparava 2009b]. Visual clues of deception include facial emotions, expression intensity, hands and body movements, and microexpressions. These features were shown to be capable of discriminating between deceptive and truthful behavior [Ekman 2001, Owayjan et al. 2012]. The psychology of lying using non-verbal and verbal characteristics was analyzed to identify deception clues [Vrij 2001]. Deception was also detected by observing increased activity in the nervous system that were determined using physiological measurements, such as heart rate, blood pressure, skin conductance, and respiration rate. The physiological aspect of the human body was expanded in terms of the thermal variations that occurred in the faces and specifically in the periorbital areas as a person acted deceptively [Shastri et al. 2012, Pavlidis et al. 2012]. Acoustic features took into account the pitch and speaking rate, among other measurements, to specify whether or not certain features are associated with an act of deceit [Hirschberg et al. 2005].</p>
<p class="indent"><a id="page_421"/>Recently, multimodal analysis has gained a lot of attention due to their superior performance compared to the use of individual modalities [P&#233;rez-Rosas et al. 2015b, Abouelenien et al. 2016a, Abouelenien et al. 2015a].</p>
<p class="indent"><a href="18_Chapter06.xhtml">Chapter 6</a> presented an overview on multimodal approaches for affect recognition tasks. In the deception detection field, several multimodal approaches have been suggested to improve deception detection by integrating features from different modalities including thermal and visual data streams [Abouelenien et al. 2014, Abouelenien et al. 2015b, Abouelenien et al. 2016b]. This integration created a more reliable system that is not susceptible to factors affecting sole modalities and polygraph tests such as the fear of being caught in a lie, stress from daily responsibilities, and tiredness.</p>
<p class="indent">In order to be able to develop improved deception detection systems, deception data needs to be collected and evaluated. There are two ways to collect data, either using a lab-setting [Abouelenien et al. 2014] or using real-life data [P&#233;rez-Rosas et al. 2015a, P&#233;rez-Rosas et al. 2015b]. While earlier work relied on polygraph tests and manual human efforts, most of the work proposed for automatic deception detection relies on crowdsourcing or artificial acted data. Only recently, automated techniques were proposed to detect deceit from real-life scenarios such as court trials and TV interviews.</p>
<p class="indent">These strategies have different strengths and weaknesses that need to be evaluated according to the research hypothesis. Observing deceptive behavior in natural settings allows for the collection of spontaneous and real-life responses, particularly during high stake scenarios. However, this type of data lacks the choice and availability of the modalities to be used and hence misses multiple features. On the other hand, simulated data allows for the use of multiple pre-determined modalities and scenarios, but instead has lower stakes and subjects are less motivated to elicit a deceptive response as compared to real-life situations.</p>
<p class="indent">This chapter will overview the state-of-the-art in multimodal deception detection, covering physiological (e.g., <i><b>physiological sensors</b></i> and thermal imaging), visual (e.g., facial expressions and gestures), speech (e.g., pitch and pause length), and linguistic modalities. We will describe the features that are typically extracted from each of these modalities, as well as means to combine these modalities into an overall system that can detect deception in multimodal content. We will cover methods that make use of lab recordings, as well as methods that rely on real-life data (e.g., recent work on multimodal deception detection from trial data).</p>
<p class="indent">A terminology of the terms commonly used through the chapter can be found in the Glossary</p>
<div class="box">
<p class="bhead"><a id="page_422"/><b>Glossary</b></p>
<p class="hangbx"><b>Feature-level multimodal fusion</b>. The process of integrating features from different modalities using diverse methodologies such as concatenating the features together (early fusion) or combining the models obtained from each modality at decision level (late fusion).</p>
<p class="hangbx"><b>Leave-one-out cross validation</b>. Cross validation is the process of dividing a dataset into batches where one batch is reserved for testing and all the other batches are used for training a system. Leave-one-out means each batch is formed of a single instance.</p>
<p class="hangbx"><b>Physiological sensor</b>. A device that uses a transducer and a biological element to collect physiological responses, such as heart rate and skin conductance, and convert them into an electrical signal. The measures obtained with such devices provide quantitative feedback about physiological changes or processes experienced by research subjects.</p>
<p class="hangbx"><b>T-unit analysis</b>. The analysis of terminable units of language (T-unit), which is the smallest group of words that could be considered as a grammatical sentence, regardless of how is punctuated. T-unit analysis is used extensively to measure the overall complexity of both speech and writing samples and consists mainly on measuring different aspects of their syntactic construction in text such as mean length of the t-units, and number of clauses present in each unit, among others.</p>
</div>
<p class="h1-1"><a id="ch13_2"/><b><span class="bg1">13.2</span>&#160;&#160;&#160;&#160;Deception Detection with Individual Modalities</b></p>
<p class="noindent">Multiple approaches have been explored targeting the identification of deceptive behavior. These approaches can be roughly divided into verbal and nonverbal [Henningsen et al. 2005] or into contact and non-contact approaches.</p>
<p class="indent">Earlier methodologies for detecting deceit, especially in law-enforcement, fell mostly under the contact-based approaches and were focused on polygraph tests, which use devices that measure responses from the nervous system [Vrij 2001]. In particular, techniques relying on the extraction of physiological and biological measurements, such as skin conductance and heart rate, fell under this category. With the limitations of the invasive contact-based methods, which included the need of physically attaching devices to the subject&#8217;s body to measure a given response, and also require human interpretation, deception detection research shifted towards non-contact, non-invasive methods. Among others, non-contact approaches include the development of verbal and acoustic, psychological, and physiological, visual, and thermal techniques.</p>
<p class="indent"><a id="page_423"/>In the following sections we provide an overview of research work conducted from different research fields, using both verbal and non-verbal approaches, toward building automatic and reliable systems for deception detection.</p>
<p class="h2-1"><a id="ch13_2_1"/><b><span class="bg2">13.2.1</span>&#160;&#160;Psychology</b></p>
<p class="noindent">Initial explorations on deception detection were conducted in the psychology domain, where researchers examined lying and lie detection phenomena in search of behavioral cues to deception. These studies focused on the micro and macro analysis of verbal and non-verbal exchanges between the deceiver and the lie detector [Zuckerman et al. 1981]. Psychology researchers posed questions related to deceiver&#8217;s self-presentation such as: will their faces be prone to leakage by showing exaggerated or suppressed facial expressions? Will their voices be louder, slower or faster? Furthermore, which are the thoughts, feelings, or physiological processes that are more likely to occur when people are lying compared to when they are telling the truth? For instance, to what extent do liars show behaviors than indicate guilt and fear as compared to truth tellers? Are deceivers more fearful as the stakes becomes higher? The reader can find a more detailed discussion in DePaulo [1992].</p>
<p class="indent">To answer these questions, multiple approaches were explored focusing on four aspects.</p>
<p class="numlistt">1.&#160;&#160;Control: deceiver&#8217;s attempted behavior control that might appear planned, rehearsed, and lacking of spontaneity.</p>
<p class="numlistt">2.&#160;&#160;Arousal: indicators of deceiver&#8217;s arousal responses such as pupil dilation, eye blinking, and speech disturbances.</p>
<p class="numlistt">3.&#160;&#160;Felt emotion: markers of deceiver&#8217;s experience of negative or positive affect including grooming, scratching, anxiety, evasive responses, among others.</p>
<p class="numlistt">4.&#160;&#160;Cognitive processing: indicators of cognitive load such as longer response latency, hesitation, and fewer illustrators.</p>
<p class="indentt">Depaulo et al. [2003] presents an extensive analysis of psychology work conducted on deception detection exploring these factors and describe 158 cues to deception compiled from over 120 independent samples. Results show that there are indeed important differences among liars and truth tellers.</p>
<p class="indent">Motivated by these findings and the increasing access to larger amounts of observational data, researchers from study fields such as computational linguistics, speech processing, computer vision, psychology, and physiology started exploring the identification of deceit from a data-driven perspective. Thus, allowing approaching the identification of deceit by automatic means.</p>
<p class="indent"><a id="page_424"/>For further reading, readers can refer to <a href="23_Chapter10.xhtml">Chapter 10</a>, which investigates multimodal behavioral and physiological signals as indicators of cognitive load. In particular, the chapter describes the integration of physiological features such as galvanic skin response and visual aspects, such as eye-based features, which are shown to be robust measures of cognitive load.</p>
<p class="h2-1"><a id="ch13_2_2"/><b><span class="bg2">13.2.2</span>&#160;&#160;Language</b></p>
<p class="noindent">The identification of deceit in written content has been addressed in a large number of studies in the psychology and computational linguistics communities.</p>
<p class="indent">From the psychology perspective, several studies showed the relationship between people&#8217;s linguistic choices and deceptive behavior. Newman et al. [2003] presented an examination of linguistic manifestations of falsehood in written stories. In this study, authors measured and tested several linguistic dimensions from a set of linguistic categories that were previously found correlated to deception, including self-references, negative emotion words, and markers of cognitive complexity [Depaulo et al. 2003]. Using a text analysis tool called Linguistic Inquiry and Word Count (LIWC) [Pennebaker and Francis 1999], a lexicon of words are grouped into semantic categories relevant to psychological processes, including thoughts, emotions, and motives, authors generated linguistic profiles of participants who were either lying or telling the truth about different topics in different contexts. Then, several regression models were built for each topic to test the discriminating power of the different linguistic categories over deceptive and truthful samples.</p>
<p class="indent">Five scenarios were used in this study and each subject was asked to provide both a truthful and a deceptive response in four scenarios. They were equally divided into a deceptive and truthful groups for a fifth &#8220;Mock Crime&#8221; scenario, resulting in an overall balanced population with a baseline of 50%. Using this method, authors were able to identify deception with an overall accuracy rate of 61%. Further analysis of word usage provided evidence of linguistic differences between truth-tellers and liars. In particular, liars were found to use fewer first-person pronouns and more negative emotions words than truth-tellers. On the other hand, liars seemed to use third-person references at higher rates.</p>
<p class="indent">Work on computational linguistics initially attempted to replicate the findings of psychological experimentation by applying computational approaches to distinguish between written samples of deceptive and truthful statements. [Mihalcea and Strapparava 2009a] proposed a data-driven method to build classifiers able to distinguish between deceptive and truthful essays covering three topics: opinions on abortion, opinions about death penalty, and feelings about a best friend. Data was <a id="page_425"/>collected via crowd sourcing and learning features consisted of counts of unique words (unigrams) present in each deceptive/truthful essay. Authors presented experiments using machine learning classifiers such as Support Vector Machines and Naive Bayes. Results showed a clear separation between truthful and deceptive texts regardless of the topic being discussed. Further analysis identified salient words on deceptive text using the LIWC and Wordnet Affect [Strapparava and Valitutti 2004] dictionaries and reported similar findings to Newman et al. [2003]. For instance, deceivers used more references to others, i.e., third-person pronouns, whereas truth-tellers showed preference for words connected to the self, i.e., I, myself. A similar study is presented in Feng et al. [2012], where authors focused on applying syntactic stylometry techniques to identify deception in text from essays and product reviews. Authors explore shallow and deep syntactic representations derived from Probabilistic Context Free Grammar (PCFG) parse trees, such as part of speech tags (POS), syntactic patterns encoded as production rules, as well as n-gram representations. Experimental results showed significant performance gain in deception detection when adding deep syntax information into the learning process.</p>
<p class="indent">Computational linguistic approaches have also covered the identification of deception on a variety of domains where computer-mediated communication happens, including chats, forums, online dating websites, social networks&#8212;e.g., Facebook and Twitter&#8212;as well as product review websites that are prone to have fake product reviews and spam content [Toma and Hancock 2010, Guadagno et al. 2012, Warkentin et al. 2010, Joinson and Dietz-Uhler 2002, Ott et al. 2011, Li et al. 2014].</p>
<p class="indent">In the product reviews domain, Ott et al. [2011] addressed the identification of spam producers by analyzing linguistic patterns in deceptive reviews. Using a similar approach to Mihalcea and Strapparava [2009a], i.e, using n-grams and semantic features derived from the LIWC dictionary, authors built accurate machine learning classifiers that identified fake reviews with accuracies above the human baseline performance (which was found slightly better than chance). This study showed that automatic deception detection can be accurately conducted on the product reviews domain and that humans are generally poor deception detectors for this task with inter-annotator agreement scores in the range (0.00,0.20), which indicates &#8220;slight agreement&#8221; between annotators. Interestingly, this study also showed that annotators suffered from &#8220;truth bias,&#8221; a psychological phenomenon in which humans judges tend to believe others thus making it more likely to classify information as truthful rather than deceptive. Furthermore, authors found that features derived <a id="page_426"/>from LIWC are not as effective for building deception detection models in the product review domain. In a following study, Ott et al. [2013] presented an analysis of the sentiment associated to deceitful reviews focusing particularly in those containing negative sentiment as it largely affects consumer purchase decisions.</p>
<p class="indent">Regarding studies that analyzed deception in online interaction, Yu et al. [2015] analyzed the role of deception in online networks by detecting deceptive groups in a social elimination-game; Toma and Hancock [2010] conducted linguistic analyses in online dating profiles and identified significant correlation between deceptive dating profiles, self-references, negations, and lower levels of word usage. Other works have targeted the identification of deceptive behavior during face-to-face interactions. A study focusing on deception aspects related to syntactic complexity in children speech is presented by Yancheva and Rudzicz [2013], where authors examine the relation between speech syntactic complexity and children&#8217;s age. Authors analyzed children&#8217;s verbal responses in short interviews regarding an unambiguous minor transgression involving playing with a toy. Several linguistic features such as readability index of the verbal statements, sentence complexity based on <i><b>T-unit analysis,</b></i> and the use of passive constructions were evaluated to identify differences in the complexity of the language used by a child while either lying or telling the truth. Results showed a clear association between the complexity of deceptive speech and children&#8217;s age.</p>
<p class="indent">There have been also a number of efforts on exploring the deception detection task in languages other than English. Almela et al. [2012] approached the deception detection task in Spanish essays by using Support Vector Machine (SVM) classifiers and linguistic categories, obtained from the Spanish version of the LIWC dictionary. Fornaciari and Poesio Fornaciari and Poesio [2013b] examined deception in Italian court cases. In this work, authors explore several strategies for identifying deceptive clues, such as utterance length, LIWC features, lemmas, and part-of-speech patterns. P&#233;rez-Rosas and Mihalcea [2014] presented a study that examined cultural differences among deceptive and truthful essays written by English, Spanish, and Romanian speakers. The authors addressed the deception detection task by first building classifiers separately for each culture and then by conducting several experiments across cultures. The authors proposed the use of automatic machine translation and the LIWC version in each language to build deception classifiers across-languages. Experimental results suggest important differences among cultures and also the feasibility of using semantic information as a cross-lingual bridge when deceptive data is not readily available for a given language. In addition, analyses on word usage showed interesting findings such as shared lying patterns among cultures including the use of negation, negative emotions, and references to others. <a id="page_427"/>Furthermore, truth-tellers related patterns are also shared among cultures, where the most salient words were related to family, positive emotions, and positive feelings.</p>
<p class="indent">Overall, techniques used for deception detection frequently include n-grams, and word statistics such as sentence length, word type ratio, and word diversity. The addition of syntactic information, i.e., a sentence&#8217;s grammatical structure, has also been found useful to identify linguistic patters associated to deception. Semantic information has been also a great source of information about the deceiver&#8217;s psychological processes. In this category, LIWC and Wordnet Affect had been proved as valuable resources to analyze deceivers&#8217; word usage.</p>
<p class="indent">Finally, it is worth mentioning that learning resources for automatic deception detection are limited. Most of the research work in this area included a data collection step using either manual or crowd sourced means. However, there is an increasing number of research work that has directed their efforts to the construction of deception resources [Gokhman et al. 2012]. Some deception corpora publicly available include: a dataset on deceptive and truthful essays [Mihalcea and Strapparava 2009a],<sup><a id="rfn1" href="#fn1">1</a></sup> and a fake hotel reviews dataset collected from trip advisor [Ott et al. 2011],<sup><a id="rfn2" href="#fn2">2</a></sup> a fake product review dataset collected using Mechanical Turk [Li et al. 2014].<sup><a id="rfn3" href="#fn3">3</a></sup> In addition, there are a couple of deception datasets for languages other than English such as a German deception dataset of product reviews [Verhoeven and Daelemans 2014], a Spanish and Romanian essay dataset provided by P&#233;rez-Rosas and Mihalcea [2014] covering opinions about different topics such as death penalty and abortion, and a Spanish essay dataset from Almela et al. [2012] that includes topics such as homosexual adoption and bullfighting.<sup><a id="rfn4" href="#fn4">4</a></sup></p>
<p class="h2-1"><a id="ch13_2_3"/><b><span class="bg2">13.2.3</span>&#160;&#160;Vision</b></p>
<p class="noindent">Vision is the most common way people can detect liars as deception occurs on a daily basis in human interactions. Visual body language was explored in order to detect deceit. Spontaneous facial expressions and hand gestures were of special interest due to their usage to express people&#8217;s emotions [Ekman 2001]. Using a machine learning approach, these features are used to train a classifier for automatic lie detection as well as multiple applications. More information on machine learning approaches can be found in <a href="12_Chapter01.xhtml">Chapter 1</a>.</p>
<div class="cap" id="fig13_1">
<p class="image"><a id="page_428"/><img src="../images/fig13_1.jpg" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.1</b>&#160;&#160;An example of spontaneous expressions with a truthful response (left) and a deceptive response (right).</p>
</div>
<p class="indent">Psychologists were interested in observing the expressions, movements, and emotions that occur spontaneously and the ones the subjects aim at hiding. Micro-and squelched-expressions were studied to specify whether or not they were associated with an act of deception [Ekman 2001]. Microexpressions are involuntary expressions that last for a short period of time while squelched-expressions last longer but are immediately changed into a different expression. The asymmetry, duration, and smoothness of these expressions were shown to vary as a person speaks deceptively [Ekman 2003]. A publicly available database of micro-expressions was published in Pfister and Pietik&#228;inen [2012].<sup><a id="rfn5" href="#fn5">5</a></sup> A kernel-based method was integrated in a temporal interpolation framework in order to extract clues of lies from the microexpressions in the dataset. Furthermore, geometric-based dynamic templates were extracted from the video frames of the deception recordings to extract geometric measurements from microexpressions. Following this, multiple systems were developed to detect visual features, facial expressions, and emotions that could indicate deceptive behaviors [Bartlett et al. 2006, Pfister and Pietik&#228;inen 2012]. An example of spontaneous expressions can be seen in <a href="#fig13_1">Figure 13.1</a>.</p>
<p class="indent">In order to standardize the process, the Facial Action Coding System (FACS) [Ekman and Rosenberg 2005] was developed by psychologists and behavioral scientists. FACS provided taxonomy of facial features using muscle movements. Examples of these action units include inner brow raiser, nose wrinkle, lip raiser, cheek raiser, chin raiser, eye widen, and others.<sup><a id="rfn6" href="#fn6">6</a></sup> Several attempts were made to code these gestures automatically for efficient detection of human behavior and emotions. For instance, a real-time automated system to recognize spontaneous facial expressions that was introduced to detect attempts of deception using FACS can be found in Ekman and Rosenberg [2005]. Another example and one of the most famous tools is the Computer Expression Recognition Toolbox (CERT<sup><a id="rfn7" href="#fn7">7</a></sup>) [Littlewort et al. 2011].</p>
<p class="indent"><a id="page_429"/>In addition to the action units, CERT provides 12 facial expressions such as yaw, pitch, roll, smile detector, anger, contempt, disgust, fear, joy, sad, surprise, and neutral. The software tool detects faces in each frame using Viola-Jones extension in a boosting framework followed by specifying the eyes corners, nose, and mouth corners and center. The algorithm determines the log-likelihood ratio of the presence of these regions in specific locations. Hence, the output of CERT consists of the distance to the hyperplane of an SVM-trained classifier for each action unit, which specifies the intensity of the facial actions. Using a combination of different action units, the global facial expressions are determined.</p>
<p class="indent">It was reported that automatically detecting these action units and expressions using CERT did not perform better than random guessing [Abouelenien et al. 2015b]. The performance was reported using a dataset that was collected in a labsetting using several scenarios. However, using feature selection, it was reported that some of these features had potential of detecting deceit. The list consisted of eight action units and six expressions, which provided the highest accuracy of 63%. The list included brow lowering, chin raising, cheek raising, lip puckering, eye closure, distress brow, left turning AU 10, left AU 14, yaw, roll, contempt, disgust, sadness, and neutral. Additionally, with the integration with features from other modalities, the performance improved.</p>
<p class="indent">In order to detect visual features that more personalized to the subjects and their individual differences, templates from the subjects&#8217; video recordings were extracted to determine the neutral baseline. This is followed by comparing the deceptive and truthful responses to the neutral baseline to specify the differences, which achieved an accuracy exceeding 60% for measurements such as the blinking rates, head pose, and intensity of the facial expression [Tian et al. 2005].</p>
<p class="indent">Furthermore, using the visual modality, correlation between specific hand gestures and deception were detected [Caso et al. 2006]. A noticeable decrease in the frequency of gestures was observed when subjects narrated stories in a deceptive manner compared to narrating the same stories truthfully [Cohen et al. <a id="page_430"/>2010]. Additionally, individuals acting truthfully produced more rhythmic pulsing gestures while those acting deceptively made more frequent speech prompting gestures [Hillman et al. 2012].</p>
<div class="cap" id="fig13_2">
<p class="image"><img src="../images/fig13_2.jpg" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.2</b>&#160;&#160;Physiological sensing system including (a) encoder, (b) skin conductance, (c) blood volume pulse, (d) skin temperature, and (e) abdominal respiration sensors.</p>
</div>
<p class="h2-1"><a id="ch13_2_4"/><b><span class="bg2">13.2.4</span>&#160;&#160;Physiology</b></p>
<p class="noindent">Physiological signals play a crucial role in monitoring human health as well as detecting changes in human behavior. <a href="17_Chapter05.xhtml">Chapter 5</a> discusses the theoretical foundations of multimodal interfaces and systems in the health care domain, especially multimodal interaction, distributing multimodal processing, and multisensory-multimodal facilitation of health systems.</p>
<p class="indent">For lie detection, physiological measurements were traditionally collected from sensors that were placed on the human body such as blood volume pulse (BVP sensor), skin conductance (SC sensor), skin temperature (T sensor), and abdominal respiration (BR sensor). An example of these sensors can be seen in <a href="#fig13_2">Figure 13.2</a>. Biological measurements, such as brain waves detected by MRI scanners, were also utilized as an indicator of deception [Kozel et al. 2004, Ganis et al. 2011]. The idea was to observe the variations that occur in the measurements generated from these sensors as the subjects shifted from truthful to deceptive responses.</p>
<p class="indent">Relying on such techniques were shown to have several shortcomings such as falsely accusing innocent people of committing crimes and freeing guilty persons [Vrij 2001, Derksen 2012, Gannon et al. 2009, Verschuere et al. 2009, Maschke and Scalabrini 2005]. By using proper countermeasures the suspects could take control of their physiological signals or manipulate the results. Improvements were <a id="page_431"/>made to the style of questions directed to the subjects to avoid potential errors associated with polygraphs by using Guilty Knowledge Test (GKT) compared to the widely used Control Question Test (CQT) [Taylor et al. 2010]. GKT is a multiple choice form of questions that aimed at detecting concealed knowledge that a suspect might be hiding. However, GKT still ran across multiple challenges that could manipulate its performance [Carmel et al. 2003]. In an attempt to develop more accurate methods to detect deceit, reaction time analysis in combination with event-related brain potentials using electroencephalogram were used to identify liars from a pool of 62 participants [Mohammadian et al. 2008]. The study reported that bootstrapped analysis of reaction time method achieved 81.35% accuracy compared to 80% accuracy for event-related brain potentials approach.</p>
<p class="indent">Alternative methods to improve deception detection rates were explored using biological measurements, such as the functional magnetic resonance imaging (fMRI) technology [Kozel et al. 2004]. Using fMRI, specific brain activity such as an increased activity in the right anterior frontal cortices of the brain was observed in the case of well-rehearsed lies [Ganis et al. 2003]. However, the employment of such methodology in large-scale applications was unfeasible.</p>
<p class="indent">The physiological aspect of the human body was expanded in terms of the responses of the nervous system and the changes in the blood distribution, which could be detected using thermal imaging. The new approach targeted exploring alternatives to the limitations and invasiveness of the polygraph tests. Pavlidis et al. Pavlidis et al. [2002] developed a high-definition thermal imaging method to analyze facial thermal reactions associated with deceptive responses determined by the physiological signature of the faces. It was shown that as the nervous system reacted with an act of deceit, a peripheral change in the blood flow distribution was detected toward the musculoskeletal tissue [Pavlidis and Levine 2001, Pavlidis and Levine 2002b]. Hence, bioheat transfer models that described the geometry and anatomy of large blood vessels in the facial area were developed to analyze their relation to deceit [Garbey et al. 2004].</p>
<p class="indent">Pavlidis and his collaborators noticed that the subjects exhibited elevated blood flow in the orbital muscle area resulting in elevated temperatures in certain local areas [Tsiamyrtzis et al. 2007]. They reported an overall accuracy exceeding 80% using two-class distinction; deceptive and non-deceptive. The system was compared with the traditional polygraph test designed and implemented by the Department of Defense Polygraph Institute, and was found to achieve equivalent result.</p>
<p class="indent">With further analysis, distinct non-overlapping facial thermal patterns were detected with an increase in the blood flow around the eyes when subjects acted deceptively. Hence, thermodynamic modeling was applied to transform the raw thermal data from the periorbital area in the face to blood flow rates that had the potential of indicating deceit. <a href="#fig13_3">Figure 13.3</a> demonstrates the regions of interest found to be most indicative of deceit.</p>
<div class="cap" id="fig13_3">
<p class="image"><img src="../images/fig13_3.png" alt="Image"/></p>
<p class="figcaption"><a id="page_432"/><b>Figure 13.3</b>&#160;&#160;(a) A facial frame of the subject, (b) the periorbital area found to be the most indicative of deceit with the 10% hottest pixels highlighted in pink, and (c) the region of interest superimposed on the facial and ophthalmic arteriovenous complex. Image is provided by Tsiamyrtzis et al. [2007]</p>
</div>
<p class="indent">Further experiments were conducted to improve the detection accuracy achieved using thermal imaging. Tandem tracking and noise suppression methods were used to extract thermal features from the periorbital area without applying restrictions on the face movements of the subjects in order to improve deception detection rates [Tsiamyrtzis et al. 2005]. Landmark detection systems were introduced to track landmarks on the regions of interest in the facial areas to track subjects as they lie [Jain et al. 2012].</p>
<p class="indent">Interestingly, a lie detection system was experimented in an airport using a set of 51 travelers by extracting thermal features such as the maximum, minimum, and average temperatures [Warmelink et al. 2011]. The system achieved accuracy above 64%. However, trained custom interviewers were able to detect liars with an accuracy exceeding 70%.</p>
<p class="indent">Other facial areas were additionally investigated in order to determine their capability of indicating deceit. A system for automatic blush detection was developed while focusing on areas such as the cheeks to identify changes in the skin temperature [Harmer et al. 2010]. A potential importance of the forehead region in detecting lies was suggested due to the presence of multiple blood vessels in this particular area [Zhu et al. 2007, Zhu et al. 2008]. A comparison between different thermal facial regions in the face illustrated that the forehead area provided features that achieved improved performance compared to other regions [Abouelenien et al. 2015b]. An example of segmenting the region of interest can be seen in <a href="#fig13_4">Figure 13.4</a>.</p>
<div class="cap" id="fig13_4">
<p class="image"><a id="page_433"/><img src="../images/fig13_4.png" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.4</b>&#160;&#160;An overview of the region of interest segmentation process including determining the bounding box, cropping and masking, binarization, multiplication of the original and binarized images, and isolation of the region of interest.</p>
</div>
<p class="h1-1"><a id="ch13_3"/><b><span class="bg1">13.3</span>&#160;&#160;&#160;&#160;Deception Detection with Multiple Modalities</b></p>
<p class="noindent">In search of more sophisticated lie detection systems, researchers explored multimodal approaches where features from several modalities are integrated. These approaches aim to avoid the uncertainty associated with the use of single modalities, as well as the human efforts required for the analysis and decision-making processes used in earlier approaches. Additionally, the integration of features from different modalities enriches the dataset with information that is not available when these modalities are used separately, which can be reflected in the overall performance and the confidence level of the classifier.</p>
<p class="indent">For example, Henningsen et al. [2005] examined the classification of deception cues into verbal and nonverbal, and how these cues influenced the perception of deception. Burgoon et al. [2009] combined verbal and nonverbal features such as speech act profiling, feature extraction, and kinetic analysis for improved deception detection rates. Jensen et al. [2010] extracted features from acoustic, verbal, and visual modalities following a multimodal approach. Nunamaker et al. [2012] provided a review of approaches for evaluating human credibility using physiological, visual, acoustic, and linguistic features.</p>
<p class="indent">In the following section we provide an overview of research integrating multiple modalities in order to detect deceit. We also present some of the used datasets, extracted features, and evaluation results.</p>
<p class="h2-1"><a id="ch13_3_1"/><b><span class="bg2">13.3.1</span>&#160;&#160;Thermal Imaging, Physiological Sensors, and Language Analysis</b></p>
<p class="noindent">Recent work analyzed the combination of linguistic and thermal features [Nunamaker et al. 2012]. A novel approach that integrated features from the thermal, linguistic, and physiological modalities was presented in Abouelenien et al. [2014] using data collected in a lab-setting environment. This research made two important contributions. First, a new dataset was collected with the participation <a id="page_434"/>of 30 subjects. The subjects were asked to discuss two different topics in both truthful and deceptive manners, while they were recorded using a microphone, a thermal camera, and several physiological sensors. Second, a multimodal system that integrated features extracted from three different modalities was developed in order to automate and improve the detection of deceptive behavior, avoid human efforts and the limitations associated with individual methods, and increase the efficiency of the decision making process. The research hypothesized that as a person acts/speaks deceptively, there will be subtle changes in his or her physiological and behavioral response, which can be detected using discriminant feature extraction.</p>
<p class="h3"><b>13.3.1.1&#160;&#160;Dataset and Devices</b></p>
<p class="noindent">Measurements were acquired in a lab setting using a thermal camera FLIR Thermovision A40 with a resolution of 340 <i><b>x</b></i> 240 and a frame rate of 60 frames per second, as well as 4 biosensors including: blood volume pulse, skin conductance, skin temperature, and abdominal respiration sensors. Audiovisual recordings were also obtained using a Logitech web camera. The scenarios that were used to elicit deceptive and truthful responses are as follows.</p>
<p class="hangt"><b>Abortion</b>. The subjects provided two separate statements, including a description of the subject&#8217;s truthful opinion on abortion, and a deceptive description of the opposite opinion on abortion presented as if it was the subject&#8217;s true opinion</p>
<p class="hangt"><b>Best Friend</b>. The subjects provided two separate statements including a true description of the subject&#8217;s best friend, as well as a deceptive description about a person that the subject cannot stand described as if s/he were a best friend.</p>
<p class="h3"><b>13.3.1.2 Multimodal Feature Extraction</b></p>
<p class="noindent">The physiological features included assessments for temperature, heart rate, blood volume pulse, skin conductance, and respiration rate. Moreover, the features included a set of statistical descriptors of the raw measurements such as the maximum and minimum values, means, power means, standard deviations, and mean amplitudes (epochs).</p>
<p class="indent">The linguistic features included unigram counts, representing the frequency of occurrence of words in the transcript of subjects responses, and features derived <a id="page_435"/>from the frequency counts of word classes in the Linguistic Inquiry and Word Count (LIWC) lexicon.<sup><a id="rfn8" href="#fn8">8</a></sup></p>
<p class="indent">The thermal features were extracted by isolating the thermal facial areas in the video frames by employing image binarization techniques in addition to using relative measurements to locate the neck area and eliminate the back ground. Once the thermal faces were located in each frame, a thermal map was created by extracting the maximum, minimum, average, and standard deviation of the temperatures in addition to a histogram representing the temperature distribution in the faces.</p>
<p class="h3"><b>13.3.1.3 Results</b></p>
<p class="noindent"><i><b>Feature-level multimodal fusion</b></i> was used to integrate the features from individual modalities in order to train a decision tree classifier. A <i><b>leave-one-out cross validation</b></i> scheme was used and the average overall and per class accuracies were reported.</p>
<p class="indent">This data distribution resulted in a baseline performance of 51.01% and 48.99% for the deceptive and truthful classes, respectively. Additionally, across-topic learning scheme was used, where the classifier was trained with features extracted from one topic while tested on the other.</p>
<p class="indent"><a href="#fig13_5">Figure 13.5</a> illustrates the performance of the features extracted from both topics together for all modalities. The use of multimodal features further enhanced the classification accuracy. In particular, the integration of all three modalities together in addition to the integration of the thermal and linguistic features obtained higher accuracy in comparison to all other combinations as well as all individual modalities. Although the best performing single modalities were linguistic and physiological, the combination of thermal and linguistic modalities exceeded 70% for both classes and for the overall accuracy.</p>
<p class="indent"><a href="#fig13_6">Figures 13.6</a> and <a href="#fig13_7">13.7</a> illustrate the deceptive and truthful detection rates and the overall accuracy for the across-topic learning process using individual and combined modalities. In this learning scheme, the classifier was trained using features from one topic and then tested on the other topic. In both cases, it can be noticed that the linguistic modality created a large imbalance between the detection rate of the deception and truthfulness classes, which indicates the failure <a id="page_436"/>of the learning process. The disposition of the results can be explained with the dependency of the linguistic features on the corresponding topic.</p>
<div class="cap" id="fig13_5">
<p class="image"><img src="../images/fig13_5.png" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.5</b>&#160;&#160;Deception, truthfulness, and overall accuracy percentages for individual and integrated modalities using features extracted from both the abortion and best friend topics.</p>
</div>
<div class="cap" id="fig13_6">
<p class="image"><img src="../images/fig13_6.png" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.6</b>&#160;&#160;Deception, truthfulness, and overall accuracy percentages for individual and integrated modalities using across-topic learning. Best friend features are used for training and abortion features are used for testing.</p>
</div>
<p class="indent">Experimental results suggested that features extracted from linguistic and thermal modalities can potentially be good indicators of deceptive behaviors, which paves the way towards a completely automated, non-invasive deception detection process. Moreover, creating a multimodal classifier by integrating features from different modalities proved to be superior compared to learning from individual <a id="page_437"/>modalities. The experiments showed that the quality of the extracted features is topic-dependent as the physiological and thermal features were topic-independent while the linguistic features were not.</p>
<div class="cap" id="fig13_7">
<p class="image"><img src="../images/fig13_7.png" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.7</b>&#160;&#160;Deception, truthfulness, and overall accuracy percentages for individual and integrated modalities using across-topic learning. Abortion features are used for training and best friend features are used for testing.</p>
</div>
<p class="indent">This work was extended later in Abouelenien et al. [2015b], where a &#8220;Mock Crime&#8221; scenario was added and different thermal regions in the face were tracked. In this scenario, a $20 bill was hidden in an envelope and the subjects were supposed to steal the money and deny it. This work reported that the forehead thermal features outperformed other facial features in its ability in detecting deceit.</p>
<p class="h2-1"><a id="ch13_3_2"/><b><span class="bg2">13.3.2</span>&#160;&#160;Language and Acoustics</b></p>
<p class="noindent">Psychology literature have found a significant correlation between deceptive behavior and speech attributes such as pitch, pitch accent, intonation, rhythm, and loudness [Depaulo et al. 2003, Zuckerman et al. 1981]. The speech community have addressed the identification of deceptive speech using machine learning approaches mainly by combining prosodic and cepstral speech features. Speech feature extraction is usually conducted at small intervals, also called audio frames, or globally by calculating representative statistics of the whole utterances. Most researchers use descriptive statistics such as mean, medians, standard deviations, and ranges of prosody features. Among them, fundamental frequency, pitch, energy, pauses, and formants are the most commonly used features. While initial efforts explored the use of lexical features derived from speech transcriptions or acoustic features extracted from the raw speech signals separately, more recent <a id="page_438"/>studies have addressed the relation between language and acoustics on the identification of deceptive behaviors.</p>
<p class="indent">Hirschberg et al. Hirschberg et al. [2005] presented one of the first studies to explore the potential of combining prosodic and lexical cues on the identification of deceptive speech. Their experiments were conducted on a self-acquired dataset, the Columbia-SRI-Colorado corpus CSC. The dataset consists of audio recorded interviews containing deceptive and truthful responses from 32 speakers and comprises approximately 7 hours of speech. In this work, authors built classifiers using the linguistic and speech modalities separately as well a combination of both modalities. Their experimental results showed noticeable improvement when combining the linguistic and acoustic modalities by reducing the baseline error by 6%. Overall, this study showed that identifying deception in speech content is a very challenging task as speech shows a high degree of variation among individuals making difficult to develop speaker independent models. Graciarena et al. [2006] reported additional experiments on the CSC corpus where authors use cepstral features to investigate speaker variability on the deception detection task. This study also evaluated the use of automatic speech recognition as alternative to manual transcription. Results showed a reasonable trade-off in quality of deception classifiers build from transcripts obtained with noisy speech to text recognition. Following the same line of research, Enos et al. [2007] analyzed speaking segments, previously identified as emotionally charged and cognitively loaded, as a way to determine if a subject was telling the truth or lying. These events, also termed as hot spots by the psychology community, are particularly useful in the identification of lies as they indicate salient topics of the speaker&#8217;s deception that are highly associated to deceptive statements. Authors approach consisted of annotating the CSC corpus with critical segments and using lexical features, pauses, and vocal energy features to build models able to predict their occurrence. Their experimental results showed 20% relative improvement of performance over a random baseline while identifying deceptive speech.</p>
<p class="indent">In addition, acoustics and language analysis has been also applied to explore cultural differences in deceptive behavior. A study on examining cultural differences in deceptive behavior among American and Chinese native speakers&#8212;all speaking English&#8212;is presented in Levitan et al. [2015]. This study also introduces a deception dataset that includes personality, gender, and ethnicity information as well as confidence ratings on subjects&#8217; ability to deceive and to detect deception. Deceptive and truthful responses were elicited using the &#8220;fake resume&#8221; paradigm, where subjects provided true and false biographical information in a game setting in which they played the role of interviewer or interviewee. This dataset contains <a id="page_439"/>information from 139 subject pairs and comprised about 100 hours of speech. The ground truth was provided by the participants during each interview using key presses to indicate truth or lie labels. In this work, authors sought to distinguish between deceptive and non-deceptive behavior using features derived from the individual&#8217;s speech, speaker&#8217;s gender, ethnicity, and personality factors. Acoustic features included F0, pitch, voice quality, speaking rate among others while personally factors included measurements derived from the Neuroticism, Extraversion, Openness, and Five Factor Inventory. Several machine learning experiments were conducted to evaluate these features on the identification of deceptive utterances. Research findings indicate that information about speaker&#8217;s gender and their native language improves the performance of acoustic models for deception detection and further suggests cultural differences during deceptive behavior.</p>
<p class="indent">Deception detection on audio content has also been addressed in competitive role-playing games (RPGs). Chittaranjan and Hung [2010] created an audio-visual recordings of the &#8220;Are you a Werewolf?&#8221; game in order to detect deceptive behavior using non-verbal audio cues and to predict the subjects&#8217; decisions in the game. Authors were able to identity suspicious behavior based on players interactions measured through several game features such as speaking statistics, speaker&#8217;s turns information, player interruption activity, and pitch analysis.</p>
<p class="indent">Overall, the inclusion of the acoustic channel into deception detection models is a promising research direction. However, current technologies for speech processing make challenging to process noisy data coming from natural scenarios, particularly those where the speech signal suffer from significant quality loss such as data coming from phone calls or multi-party conversations. Other challenges include noise introduced due to speech recognition errors. In addition, speaker&#8217;s individual variability including gender, age, accent, voice tone, and cultural background requires building specific models that incorporate these dimensions into the analysis.</p>
<p class="h2-1"><a id="ch13_3_3"/><b><span class="bg2">13.3.3</span>&#160;&#160;Vision and Language</b></p>
<p class="noindent">More recently, the interest shifted towards detection of real-life deceptive behavior. A study used facial expressions, gestures, gaze, and conversational features in order to identify signals of trustworthiness between human negotiators [Lucas et al. 2016]. The study reported that multimodal approaches were better predictors of objective trustworthiness, whereas facial expression modality was more informative for perceived trustworthiness, suggesting that human mainly rely on facial expressions when judging trustworthiness.</p>
<p class="indent"><a id="page_440"/>The first reported multimodal deception detection approach in high stakes real-life data was presented in P&#233;rez-Rosas et al. [2015b]. This work introduced a novel dataset consisting of 121 deceptive and truthful video clips, from real court trials. The transcription of these videos was used to extract several linguistic features, and the videos were manually annotated for the presence of multiple gestures that were used to extract non-verbal features. Moreover, a system that jointly used the verbal and non-verbal modalities was developed to automatically detect the presence of deception. The performance of the system was compared to that of human annotators.</p>
<p class="h3"><a id="ch13_3_3_1"/><b>13.3.3.1&#160;&#160;Dataset</b></p>
<p class="noindent">The dataset consists of 121 videos including 61 deceptive and 60 truthful trial clips.<sup><a id="rfn9" href="#fn9">9</a></sup> The average length of the videos in the dataset is 28.0 seconds. The data consists of 21 unique female and 35 unique male speakers, with their ages approximately ranging between 16 and 60 years. The video clips were labeled as deceptive or truthful based on guilty verdict, non-guilty verdict, and exoneration. Examples of famous trials included in the dataset are the trials of Jodi Arias, Donna Scrivo, Jamie Hood, Andrea Sneiderman, Mitchelle Blair, Amanda Hayes, Crystal Mangum, Marissa Devault, Carlos Miller, Michael Dunn, Bessman Okafor, Jonathan Santillan, among other trials.</p>
<p class="h3"><a id="ch13_3_3_2"/><b>13.3.3.2&#160;&#160;Multimodal Feature Extraction</b></p>
<p class="noindent">All the video clips were transcribed via crowd sourcing using Amazon Mechanical Turk. The final set of transcriptions consisted of 8,055 words, with an average of 66 words per transcript. The verbal features consisted of unigrams and bigrams derived from the bag-of-words representation of the video transcripts.</p>
<p class="indent">The gesture annotation was performed using the MUMIN coding scheme, which is a standard multimodal annotation scheme for interpersonal interactions [Allwood et al. 2007]. In the MUMIN scheme, facial displays include several different facial expressions associated with overall facial expressions, eyebrows, eyes and mouth movements, gaze direction, as well as head movements. In addition, the scheme includes a separate category for general face displays, which codes four facial expressions: smile, laughter, scowl, and other. Hand movements are also labeled in terms of handedness and trajectory. Using this coding scheme, binary feature vectors were created from annotations that indicate the presence or absence of each gesture in the video clips.</p>
<div class="cap" id="fig13_8">
<p class="image"><a id="page_441"/><img src="../images/fig13_8.png" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.8</b>&#160;&#160;Distribution of non-verbal features for deceptive and truthful groups.</p>
</div>
<p class="h3"><a id="ch13_3_3_3"/><b>13.3.3.3&#160;&#160;Results</b></p>
<p class="noindent">The results were reported as statistical measurements and frequency counts of the gestures associated with both classes in addition to a machine learning approach to learn from both modalities.</p>
<p class="indent"><a href="#fig13_8">Figure 13.8</a> shows the non-verbal features for which noticeable differences were observed in the two classes. Each bar pair shows the percentage distribution of the given gesture occurring during the deceptive and truthful conditions. For instance, it can be seen that eyebrow and eye gestures differentiated between the deceptive and truthful conditions as the non-overlapping error bars suggest statistically significant difference (P &#x003C; 0.05). In this figure, we can also observe that truth-tellers raised their eyebrows (Eyebrows raising), shook their head (Head repeated shake), and blinked (Eyes closing repeated) more frequently than deceivers. Interestingly, deceivers seemed to blink and shake their head less frequently than truth-tellers.</p>
<p class="indent">Deception classifiers were built using two classification algorithms: Decision Tree (DT) and Random Forest (RF) using leave-one-out cross-validation. The choice of these classifiers is based on their success and recommendation from previous work [Qin et al. 2004, 2005]. Moreover, a decision tree facilitates the visualization of the constructed tree model and determines the sequence and importance of the multimodal features at different tree levels.</p>
<p class="indent"><a href="#tab13_1">Table 13.1</a> shows the accuracy figures obtained by the two classifiers. As shown in this table, the combined classifier that learned from all the features (using Decision Tree) and the individual classifier that relied on the facial displays features <a id="page_442"/>(using Random Forest) achieved the best results. Comparing the integration of verbal features and visual features, the non-verbal features clearly outperformed the verbal features.</p>
<p class="tcaption" id="tab13_1"><b>Table 13.1</b>&#160;&#160;Deception classifiers decision tree (DT) and random forest (RF) using individual and combined sets of verbal and non-verbal features</p>
<table class="table1">
<tr>
<td><p class="tab1">Feature Set</p></td>
<td><p class="tab1">DT</p></td>
<td><p class="tab1">RF</p></td>
</tr>
<tr>
<td><p class="tab1">Unigrams</p></td>
<td><p class="tab1">60.33%</p></td>
<td><p class="tab1">56.19%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">Bigrams</p></td>
<td class="t1"><p class="tab1">53.71%</p></td>
<td class="t1"><p class="tab1">51.20%</p></td>
</tr>
<tr>
<td><p class="tab1">Facial displays</p></td>
<td><p class="tab1">70.24%</p></td>
<td><p class="tab1">76.03%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">Hand gestures</p></td>
<td class="t1"><p class="tab1">61.98%</p></td>
<td class="t1"><p class="tab1">62.80%</p></td>
</tr>
<tr>
<td><p class="tab1">Uni+Facial displays</p></td>
<td><p class="tab1">66.94%</p></td>
<td><p class="tab1">57.02%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">All verbal</p></td>
<td class="t1"><p class="tab1">60.33%</p></td>
<td class="t1"><p class="tab1">50.41%</p></td>
</tr>
<tr>
<td><p class="tab1">All non-verbal</p></td>
<td><p class="tab1">68.59%</p></td>
<td><p class="tab1">73.55%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">All features</p></td>
<td class="t1"><p class="tab1">75.20%</p></td>
<td class="t1"><p class="tab1">50.41%</p></td>
</tr>
</table>
<p class="tcaption" id="tab13_2"><b>Table 13.2</b>&#160;&#160;Feature ablation study</p>
<table class="table1">
<tr>
<td><p class="tab1">Feature Set</p></td>
<td><p class="tab1">DT</p></td>
</tr>
<tr>
<td><p class="tab1">All</p></td>
<td><p class="tab1">75.20%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">Hand gestures</p></td>
<td class="t1"><p class="tab1">71.90%</p></td>
</tr>
<tr>
<td><p class="tab1">Facial displays</p></td>
<td><p class="tab1">59.50%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">Bigrams</p></td>
<td class="t1"><p class="tab1">66.94%</p></td>
</tr>
<tr>
<td><p class="tab1">Unigrams</p></td>
<td><p class="tab1">61.98%</p></td>
</tr>
</table>
<p class="indent"><a href="#tab13_2">Table 13.2</a> shows the accuracies obtained when one feature group is removed and the deception classifier is built using the remaining features. Interestingly, the facial displays contributed the most to the classifier performance, followed by the unigram features.</p>
<p class="indent"><a href="#fig13_9">Figure 13.9</a> shows the five most predictive features of the presence of deception were the presence of frowning (Frowning), eyebrows movement (Eyebrows raising), lip gestures (Lip corners up, Lips protruded, Lips retracted), and head turns (Head side turn). These gestures were frequently portrayed by defendants and witnesses while being interrogated.</p>
<div class="cap" id="fig13_9">
<p><a id="page_443"/><img src="../images/fig13_9.png" alt="Image"/></p>
<p class="figcaption"><b>Figure 13.9</b>&#160;&#160;Weights of top non-verbal features in the multimodal deception classifier. The weights shown in this figure are normalized between 0 and 1 to easily observe the contribution of each feature.</p>
</div>
<p class="tcaption" id="tab13_3"><b>Table 13.3</b>&#160;&#160;Performance of three annotators (A1, A2, A3) and the developed automatic system (Sys) on the real-deception dataset over four modalities</p>
<table class="table1">
<tr>
<td></td>
<td><p class="tab1">Text</p></td>
<td><p class="tab1">Audio</p></td>
<td><p class="tab1">Silent video</p></td>
<td><p class="tab1">Full video</p></td>
</tr>
<tr>
<td><p class="tab1">A1</p></td>
<td><p class="tab1">54.55%</p></td>
<td><p class="tab1">51.24%</p></td>
<td><p class="tab1">45.30%</p></td>
<td><p class="tab1">56.20%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">A2</p></td>
<td class="t1"><p class="tab1">47.93%</p></td>
<td class="t1"><p class="tab1">55.37%</p></td>
<td class="t1"><p class="tab1">46.28%</p></td>
<td class="t1"><p class="tab1">53.72%</p></td>
</tr>
<tr>
<td><p class="tab1">A3</p></td>
<td><p class="tab1">50.41%</p></td>
<td><p class="tab1">59.50%</p></td>
<td><p class="tab1">47.93%</p></td>
<td><p class="tab1">59.50%</p></td>
</tr>
<tr>
<td class="t1"><p class="tab1">Sys</p></td>
<td class="t1"><p class="tab1">60.33%</p></td>
<td class="t1"><p class="tab1">NA</p></td>
<td class="t1"><p class="tab1">68.59%</p></td>
<td class="t1"><p class="tab1">75.20%</p></td>
</tr>
</table>
<p class="indent">The proposed system was compared to the human ability to identify deceit on trial recordings when exposed to four different modalities: <i>Text</i>, consisting of the language transcripts; <i>Audio</i>, consisting of the audio track of the clip; <i>Silent video</i>, consisting of only the video with muted audio; and <i>Full video</i>, where audio and video are played simultaneously. The results, shown in <a href="#tab13_3">Table 13.3</a>, support the argument that human judges have difficulty performing the deception detection task [Ott et al. 2011]. Human detection of deception on silent video was more challenging than the rest of the modalities due to the lesser amount of deception cues available to the raters.</p>
<p class="indent"><a id="page_444"/>In summary, the analysis of non-verbal behaviors occurring in deceptive and truthful videos brought insight into the gestures that play a role in deception. Additional analysis showed the role played by the various feature sets used in the experiments. The proposed system achieved accuracies in the range of 60&#8211;75% and outperformed humans using different modalities with a relative percentage improvement of up to 51%. This showed that multimodal deception detection can provide valuable support for the trials decision making process.</p>
<p class="h1-1"><a id="ch13_4"/><b><span class="bg1">13.4</span>&#160;&#160;&#160;&#160;The Way Forward</b></p>
<p class="noindent">Based on the success of multimodal approaches in detecting deceit, improvements can be made to further achieve higher detection rates. For instance, improvements could be made in the multimodal data acquisition process, including the design of deceptive scenarios and data collection; in the selection of modalities to be extracted and their representation; or in the implementation of more efficient multimodal data fusion techniques.</p>
<p class="indent">Most of the developed deception datasets were in the range of 15&#8211;40 subjects. Larger datasets need to be collected in order to be able to detect reliable clues of deception as well as be able to generalize well to different real-life deception situations.</p>
<p class="indent">In a lab-setting environment where stakes are low or subjects are not motivated enough, the challenge is to develop creative scenarios other than the famous &#8220;Mock Crime&#8221; scenario in order to surprise the subjects and observe their initial reactions. This can be achieved by hiding the actual scenarios from the subjects before the recordings and surprising them with unexpected questions during the interviews. In real-life scenarios, there is a limit on the number of modalities used but no restrictions on the number of subjects. Efforts need to be exerted in order to collect larger datasets for deception detection. For instance, by taking advantage of publicly available data such as trials, 911 calls, police interrogations, political speeches, TV shows, and interviews.</p>
<p class="indent">For both lab-setting and real-life data, the cultural differences must be considered. Several cultural norms in a certain country could be easily considered suspicious behavior in another country. Hence, cross-cultural studies need to be conducted in order to identify such differences and develop a system that avoids bias and takes those differences into consideration.</p>
<p class="indent">The number of modalities used for feature extraction can further increase, which can result in a more reliable deception detection system. For instance, an integration of psychological, visual, physiological, linguistic, acoustic, and thermal <a id="page_445"/>modalities can reach the desired performance, especially in a lab-setting environment.</p>
<p class="indent">Finally, different techniques can be explored in order to enhance the quality of the extracted features. Temporal fusion for example can be used for this purpose. This type of fusion accounts for the temporal relationships between the modalities in the input datastream. One important research question when modeling the multimodal latent structure is the granularity of the input. Treating the deception data as a time series can also be used to determine the relationships and dependencies between different features as well as modalities and specify the variations that occur within a certain window right before an act of deceit.</p>
<p class="indent">Furthermore, different classifiers and deep learning approaches can be used to detect deceit. For instance, deep learning uses multiple layers of linear and nonlinear transformations in order to interpret different levels of abstractions in the data, as can be seen in <a href="15_Chapter04.xhtml">Chapter 4</a>. In particular, Deep Neural Networks have shown success in detecting visual concepts in computer vision, which could add to the reliability of a multimodal deception detection system.</p>
<p class="h1n"><a id="ch13_5"/><b>Acknowledgments</b></p>
<p class="noindent">This material is based in part upon work supported by National Science Foundation awards #1344257 and #1355633 and by DARPA-BAA-12-47 DEFT grant #12475008. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the Defense Advanced Research Projects Agency.</p>
<p class="h1n"><a id="ch13_6"/><b>Focus Questions</b></p>
<p class="noindent"><b>13.1.</b> What is deception detection and why is it important?</p>
<p class="noindentt"><b>13.2.</b> What is meant by multimodal deception detection?</p>
<p class="noindentt"><b>13.3.</b> Which modalities can be used for deception detection?</p>
<p class="noindentt"><b>13.4.</b> What are the typical features that can be extracted from each modality to benefit the process of detecting deceit?</p>
<p class="noindentt"><b>13.5.</b> How can the multimodal features be integrated?</p>
<p class="noindentt"><b>13.6.</b> What are the advantages of using multimodal features compared to features from a single modality?</p>
<p class="noindentt"><b>13.7.</b> What are the differences, advantages, and limitations of processing multimodal lab-setting data and real-life deception data?</p>
<p class="noindentt"><b>13.8.</b> <a id="page_446"/>How can deception detection be improved in the future? Design a high-performing deception detection system, and argue for its specific strengths.</p>
<p class="noindentt"><b>13.9.</b> What evidence is there that automatic multimodal-multisensor deception detection systems may outperform human judgment in the future? How can future systems be designed to further leverage these strengths of automated deception detection?</p>
<p class="noindentt"><b>13.10.</b> Discuss the problem of intentionally faking innocence on deception tests, which is a form of spoofing the system that creates potential security risks, and how systems can be designed to avoid it.</p>
<p class="h1-1"><a id="ch13_7"/><b>References</b></p>
<p class="ref">M. Abouelenien, V. P&#233;rez-Rosas, R. Mihalcea, and M. Burzo. 2014. Deception detection using a multimodal approach. In <i>16th ACM International Conference on Multimodal Interaction, ICMI 2014</i>. DOI: 10.1145/2663204.2663229. 421, 433</p>
<p class="ref">M. Abouelenien, M. Burzo, and R. Mihalcea. 2015a. Cascaded multimodal analysis of alertness related features for drivers safety applications. In <i>Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA &#8217;15</i>, pp. 59:1&#8211;59:8. ACM, New York. DOI: 10.1145/2769493.2769505. 421</p>
<p class="ref">M. Abouelenien, R. Mihalcea, and M. Burzo. 2015b. Trimodal analysis of deceptive behavior. In <i>Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection, WMDD &#8217;15</i>, pp. 9&#8211;13. ACM, New York. DOI: 10.1145/2823465.2823470. 421, 429, 432, 437</p>
<p class="ref">M. Abouelenien, M. Burzo, and R. Mihalcea. 2016a. Human acute stress detection via integration of physiological signals and thermal imaging. In <i>The 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2016</i>. ACM. DOI: 10.1145/2910674.2910705. 421</p>
<p class="ref">M. Abouelenien, R. Mihalcea, and M. Burzo. June 2016b. Analyzing thermal and visual clues of deception for a non-contact deception detection approach. In <i>The 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2016</i>. ACM. DOI: 10.1145/2910674.2910682. 421</p>
<p class="ref">J. Allwood, L. Cerrato, K. Jokinen, C. Navarretta, and P. Paggio. 2007. The mumin coding scheme for the annotation of feedback, turn management and sequencing phenomena. <i>Language Resources and Evaluation</i>, 41(3-4): 273&#8211;287. DOI: 10.1007/s10579-007-9061-5. 440</p>
<p class="ref">A. Almela, R. Valencia-Garc&#237;a, and P. Cantos. 2012. Seeing through deception: A computational approach to deceit detection in written communication. In <i>Proceedings of the Workshop on Computational Approaches to Deception Detection</i>, pp. 15&#8211;22. Association for Computational Linguistics, Avignon, France. DOI: 10.5195/lesli.2013.5. 426, 427</p>
<p class="ref"><a id="page_447"/>M. Bartlett, G. Littlewort, M. Frank, C. Lainscsek, I. Fasel, and J. Movellan. 2006. Automatic recognition of facial actions in spontaneous expressions. <i>Journal of Multimedia</i>, 1(6): 22&#8211;35. DOI: 10.4304/jmm.1.6.22-35. 428</p>
<p class="ref">J. K. Burgoon, D. P. Twitchell, M. L. Jensen, T. O. Meservy, M. Adkins, J. Kruse, A. Deokar, G. Tsechpenakis, S. Lu, D. N. Metaxas, J. Nunamaker, J. F., and R. E. Younger. March 2009. Detecting concealment of intent in transportation screening: A proof of concept. <i>IEEE Transactions on Intelligent Transportation Systems</i>, 10(1): 103&#8211;112. DOI: 10.1109/TITS.2008.2011700. 433</p>
<p class="ref">D. Carmel, E. Dayan, A. Naveh, O. Raveh, and G. Ben-Shakhar. 2003. Estimating the validity of the guilty knowledge test from simulated experiments: The external validity of mock crime studies. <i>Journal of experimental psychology: Applied</i>, 9(4): 261&#8211;269. DOI: 10.1037/1076-898X.9.4.261. 431</p>
<p class="ref">L. Caso, F. Maricchiolo, M. Bonaiuto, A. Vrij, and S. Mann. 2006. The impact of deception and suspicion on different hand movements. <i>Journal of Nonverbal Behavior</i>, 30(1): 1&#8211;19. DOI: 10.1007/s10919-005-0001-z. 429</p>
<p class="ref">G. Chittaranjan and H. Hung. 2010. Are you awerewolf? detecting deceptive roles and outcomes in a conversational role-playing game. In <i>2010 IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP)</i>, pp. 5334&#8211;5337. DOI: 10.1109/ICASSP.2010.5494961. 439</p>
<p class="ref">D. Cohen, G. Beattie, and H. Shovelton. 2010. Nonverbal indicators of deception: How iconic gestures reveal thoughts that cannot be suppressed. <i>Semiotica</i>, 2010(182): 133&#8211;174. DOI: 10.1515/semi.2010.055. 429, 430</p>
<p class="ref">N. R. Council. 2003. <i>The Polygraph and Lie Detection</i>. The National Academies Press, Washington, DC. <a href="http://www.nap.edu/catalog/10420/the-polygraph-and-lie-detection">http://www.nap.edu/catalog/10420/the-polygraph-and-lie-detection</a>. DOI: 10.17226/10420. 420</p>
<p class="ref">B. M. DePaulo. 1992. Nonverbal behavior and self-presentation. <i>Psychological Bulletin</i>, 111(2): 203. DOI: 10.1037//0033-2909.111.2.203. 423</p>
<p class="ref">B. M. Depaulo, B. E. Malone, J. J. Lindsay, L. Muhlenbruck, K. Charlton, H. Cooper, B. M. Depaulo, B. E. Malone, D. O. Psychology, J. J. Lindsay, L. Muhlenbruck, and K. Charlton. 2003. Cues to deception. <i>Psychological Bulletin</i>, pp. 74&#8211;118. 419, 423, 424, 437</p>
<p class="ref">M. Derksen. 2012. Control and resistance in the psychology of lying. <i>Theory and Psychology</i>, 22(2): 196&#8211;212. DOI: 10.1177/0959354311427487. 419, 430</p>
<p class="ref">P. Ekman. 2001. <i>Telling Lies: Clues to Deceit in the Marketplace, Politics and Marriage</i>. Norton, W.W. and Company. 420, 427, 428</p>
<p class="ref">P. Ekman. 2003. Darwin, deception, and facial expression. <i>Annals of the New York Academy of Sciences</i>, 1000(EMOTIONS INSIDE OUT: 130 Years after Darwin&#8217;s The Expression of the Emotions in Man and Animals): 205&#8211;221. DOI: 10.1196/annals.1280.010. 428</p>
<p class="ref">P. Ekman and E. Rosenberg. 2005. <i>What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS)</i>. Series in Affective Science. Oxford University Press. 428, 429</p>
<p class="ref"><a id="page_448"/>F. Enos, E. Shriberg, M. Graciarena, J. Hirschberg, and A. Stolcke. 2007. Detecting deception using critical segments. In <i>INTERSPEECH</i>, pp. 2281&#8211;2284. 438</p>
<p class="ref">S. Feng, R. Banerjee, and Y. Choi. 2012. Syntactic stylometry for deception detection. In <i>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</i>, ACL &#8217;12, pp. 171&#8211;175. Association for Computational Linguistics, Stroudsburg, PA. 420, 425</p>
<p class="ref">T. Fornaciari and M. Poesio. 2013a. Automatic deception detection in italian court cases. <i>Artificial Intelligence and Law</i>, 21(3): 303&#8211;340. DOI: 10.1007/s10506-013-9140-4. 419</p>
<p class="ref">T. Fornaciari and M. Poesio. 2013b. Automatic deception detection in italian court cases. <i>Artificial Intelligence and Law</i>, 21(3): 303&#8211;340. DOI: 10.1007/s10506-013-9140-4. 426</p>
<p class="ref">G. Ganis, S. M. Kosslyn, S. Stose, W. L. Thompson, and D. A. Yurgelun-Todd. August 2003. Neural correlates of different types of deception: An fmri investigation. <i>Cerebral Cortex</i>, 13(8): 830&#8211;836. DOI: 10.1093/cercor/13.8.830. 431</p>
<p class="ref">G. Ganis, J. P. Rosenfeld, J. Meixner, R. A. Kievit, and H. E. Schendan. 2011. Lying in the scanner: Covert countermeasures disrupt deception detection by functional magnetic resonance imaging. <i>NeuroImage</i>, 55(1): 312&#8211;319. DOI: 10.1016/j.neuroimage.2010.11.025. 420, 430</p>
<p class="ref">T. A. Gannon, A. R. Beech, and T. Ward. 2009. <i>Risk Assessment and the Polygraph</i>, pp. 129&#8211;154. John Wiley and Sons Ltd. DOI: 10.1002/9780470743232.ch8. 419, 430</p>
<p class="ref">M. Garbey, A. Merla, and I. Pavlidis. 2004. Estimation of blood flow speed and vessel location from thermal video. In <i>Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004</i>, vol. 1, pp. I&#8211;356&#8211;I&#8211;363. DOI: 10.1109/CVPR.2004.1315054. 431</p>
<p class="ref">S. Gokhman, J. Hancock, P. Prabhu, M. Ott, and C. Cardie. 2012. In search of a gold standard in studies of deception. In <i>Proceedings of the Workshop on Computational Approaches to Deception Detection</i>, pp. 23&#8211;30. Association for Computational Linguistics. 427</p>
<p class="ref">M. Graciarena, E. Shriberg, A. Stolcke, F. Enos, J. Hirschberg, and S. Kajarekar. 2006. Combining prosodic lexical and cepstral systems for deceptive speech detection. In <i>2006 IEEE International Conference on Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings</i>., vol. 1, pp. I&#8211;I. IEEE. DOI: 10.1109/ICASSP.2006.1660200. 438</p>
<p class="ref">P. A. Granhag and M. Hartwig. 2008. A new theoretical perspective on deception detection: On the psychology of instrumental mind-reading. <i>Psychology, Crime &#38;Law</i>, 14(3): 189&#8211;200. DOI: 10.1080/10683160701645181. 420</p>
<p class="ref">R. Guadagno, B. Okdie, and S. Kruse. Mar. 2012. Dating deception: Gender, online dating, and exaggerated self-presentation. <i>Computers in Human Behavior</i>, 28(2): 642&#8211;647. DOI: 10.1016/j.chb.2011.11.010. 425</p>
<p class="ref">K. Harmer, S. Yue, K. Guo, K. Adams, and A. Hunter. December 2010. Automatic blush detection in &#8220;concealed information&#8221; test using visual stimuli. In <i>2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR)</i>, pp. 259&#8211;264. DOI: 10.1109/SOCPAR.2010.5686076. 432</p>
<p class="ref"><a id="page_449"/>D. D. Henningsen, K. Valde, and E. Davies. 2005. Exploring the effect of verbal and nonverbal cues on perceptions of deception. <i>Communication Quarterly</i>, 53(3): 359&#8211;375. DOI: 10.1080/01463370500101329. 422, 433</p>
<p class="ref">J. Hillman, A. Vrij, and S. Mann. 2012. Um &#8230; they were wearing &#8230;: The effect of deception on specific hand gestures. <i>Legal and Criminological Psychology</i>, 17(2): 336&#8211;345. DOI: 10.1111/j.2044-8333.2011.02014.x. 420, 430</p>
<p class="ref">J. Hirschberg, S. Benus, J. Brenier, F. Enos, S. Friedman, S. Gilman, C. Gir, G. Graciarena, A. Kathol, and L. Michaelis. 2005. Distinguishing deceptive from non-deceptive speech. In <i>In Proceedings of Interspeech 2005 - Eurospeech</i>, pp. 1833&#8211;1836. 420, 438</p>
<p class="ref">D. Howard and C. Kirchh&#252;bel. 2011. Acoustic correlates of deceptive speech: an exploratory study. In <i>Proceedings of the 9th International Conference on Engineering psychology and Cognitive Ergonomics</i>, EPCE&#8217;11, pp. 28&#8211;37. Springer-Verlag, Berlin, Heidelberg. DOI: 10.1007/978-3-642-21741-8_4. 420</p>
<p class="ref">U. Jain, B. Tan, and Q. Li. March 2012. Concealed knowledge identification using facial thermal imaging. In <i>2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, pp. 1677&#8211;1680. DOI: 10.1109/ICASSP.2012.6288219. 432</p>
<p class="ref">M. L. Jensen, T. O. Meservy, J. K. Burgoon, and J. Nunamaker. 2010. Automatic, multimodal evaluation of human interaction. <i>Group Decision and Negotiation</i>, 19(4): 367&#8211;389. DOI: 10.1007/s10726-009-9171-0. 433</p>
<p class="ref">A. N. Joinson and B. Dietz-Uhler. 2002. Explanations for the perpetration of and reactions to deception in a virtual community. <i>Social Science Computer Review</i>, 20(3): 275&#8211;289. DOI: 10.1177/089443930202000305. 425</p>
<p class="ref">F. A. Kozel, L. J. Revell, J. P. Lorberbaum, A. Shastri, J. D. Elhai, M. D. Horner, A. Smith, Z. Nahas, D. E. Bohning, and M. S. George. 2004. A pilot study of functional magnetic resonance imaging brain correlates of deception in healthy young men. <i>The Journal of Neuropsychiatry and Clinical Neurosciences</i>, 16(3): 295&#8211;305. DOI: 10.1176/appi.neuropsych.16.3.295. 430, 431</p>
<p class="ref">S. I. Levitan, G. An, M. Wang, G. Mendels, J. Hirschberg, M. Levine, and A. Rosenberg. 2015. Cross-cultural production and detection of deception from speech. In <i>Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection</i>, pp. 1&#8211;8. ACM. DOI: 10.1145/2823465.2823468. 438</p>
<p class="ref">J. Li, M. Ott, C. Cardie, and E. Hovy. June 2014. Towards a general rule for identifying deceptive opinion spam. In <i>Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</i>. Baltimore, MD. DOI: 10.3115/v1/P14-1147. 425, 427</p>
<p class="ref">G. Littlewort, J. Whitehill, T. Wu, I. Fasel, M. Frank, J. Movellan, and M. Bartlett. March 2011. The computer expression recognition toolbox (cert). In <i>2011 IEEE International Conference on Automatic Face Gesture Recognition and Workshops (FG 2011)</i>, pp. 298&#8211;305. DOI: 10.1109/AFGR.2008.4813406. 429</p>
<p class="ref">G. Lucas, G. Stratou, S. Lieblich, and J. Gratch. 2016. Trust me: Multimodal signals of trustworthiness. In <i>Proceedings of the 18th ACM International Conference on</i> <a id="page_450"/><i>Multimodal Interaction, ICMI 2016</i>, pp. 5&#8211;12. ACM, New York. <a href="http://doi.acm.org/10.1145/2993148.2993178">http://doi.acm.org/10.1145/2993148.2993178</a>. DOI: 10.1145/2993148.2993178. 439</p>
<p class="ref">D. T. Lykken. 1984. Polygraphic interrogation. <i>Nature</i>, 307(5953): 681&#8211;684. DOI: 10.1038/307681a0. 419</p>
<p class="ref">G. Maschke and G. Scalabrini. 2005. <i>The Lie Behind the Lie Detector</i>. <a href="http://antipolygraph.org">http://antipolygraph.org</a>. 430</p>
<p class="ref">R. Mihalcea and C. Strapparava. 2009a. The lie detector: Explorations in the automatic recognition of deceptive language. In <i>Proceedings of the Association for Computational Linguistics, ACL 2009</i>. Singapore. 424, 425, 427</p>
<p class="ref">R. Mihalcea and C. Strapparava. 2009b. The lie detector: Explorations in the automatic recognition of deceptive language. In <i>Proceedings of the ACL-IJCNLP 2009 Conference Short Papers</i>, pp. 309&#8211;312. Association for Computational Linguistics, Suntec, Singapore. 420</p>
<p class="ref">A. Mohammadian, V. Abootalebi, M. Moradi, and M. Khalilzadeh. 2008. Multimodal detection of deception using fusion of reaction time and p300 component. In <i>Biomedical Engineering Conference, 2008, CIBEC 2008, Cairo International</i>, pp. 1&#8211;4. DOI: 10.1109/CIBEC.2008.4786064. 431</p>
<p class="ref">M. Newman, J. Pennebaker, D. Berry, and J. Richards. 2003. Lying words: Predicting deception from linguistic styles. <i>Personality and Social Psychology Bulletin</i>, 29. DOI: 10.1177/0146167203029005010. 424, 425</p>
<p class="ref">J. Nunamaker, J.F., J. Burgoon, N. Twyman, J. Proudfoot, R. Schuetzler, and J. Giboney. June 2012. Establishing a foundation for automated human credibility screening. In <i>2012 IEEE International Conference on Intelligence and Security Informatics (ISI)</i>, pp. 202&#8211;211. DOI: 10.1109/ISI.2012.6284309. 433</p>
<p class="ref">M. Ott, Y. Choi, C. Cardie, and J. Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In <i>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT &#8217;11</i>, pp. 309&#8211;319. Association for Computational Linguistics, Stroudsburg, PA. 425, 427, 443</p>
<p class="ref">M. Ott, C. Cardie, and J. T. Hancock. 2013. Negative deceptive opinion spam. In <i>Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Short Papers</i>. Association for Computational Linguistics, Atlanta, GA. 426</p>
<p class="ref">M. Owayjan, A. Kashour, N. Al Haddad, M. Fadel, and G. Al Souki. Dec 2012. The design and development of a lie detection system using facial micro-expressions. In <i>2012 2nd International Conference on Advances in Computational Tools for Engineering Applications (ACTEA)</i>, pp. 33&#8211;38. DOI: 10.1109/ICTEA.2012.6462897. 420</p>
<p class="ref">I. Pavlidis and J. Levine. 2001. Monitoring of periorbital blood flow rate through thermal image analysis and its application to polygraph testing. In <i>Proceedings of the 23rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society</i>, vol. 3, pp. 2826&#8211;2829. DOI: 10.1109/IEMBS.2001.1017374. 431</p>
<p class="ref"><a id="page_451"/>I. Pavlidis and J. Levine. 2002b. Thermal image analysis for polygraph testing. <i>IEEE Engineering in Medicine and Biology Magazine</i>, 21(6): 56&#8211;64. DOI: 10.1109/MEMB.2002.1175139. 431</p>
<p class="ref">I. Pavlidis, N. L. Eberhardt, and J. A. Levine. 2002. Human behavior: Seeing through the face of deception. <i>Nature</i>, 415(6867): 35&#8211;35. DOI: 10.1038/415035a. 431</p>
<p class="ref">I. Pavlidis, P. Tsiamyrtzis, D. Shastri, A. Wesley, Y. Zhou, P. Lindner, P. Buddharaju, R. Joseph, A. Mandapati, B. Dunkin. 2012. Fast by nature-how stress patterns define human experience and performance in dexterous tasks. <i>Scientific Reports</i>, 2. DOI: 10.1038/srep00305. 420</p>
<p class="ref">J. Pennebaker and M. Francis, 1999. Linguistic Inquiry and Word Count: LIWC. Erlbaum Publishers. 424</p>
<p class="ref">V. P&#233;rez-Rosas and R. Mihalcea. 2014. Cross-cultural deception detection. In <i>Proceedings of the Association for Computational Linguistics</i>. DOI: 10.1002/9781118510001.ch8. 426, 427</p>
<p class="ref">V. P&#233;rez-Rosas, M. Abouelenien, R. Mihalcea, Y. Xiao, C. Linton, and M. Burzo. 2015a. Verbal and nonverbal clues for real-life deception detection. In <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</i>, pp. 2336&#8211;2346. Association for Computational Linguistics, Lisbon, Portugal. DOI: 10.1145/2818346.2820758. 421</p>
<p class="ref">V. P&#233;rez-Rosas, M. Abouelenien, R. Mihalcea, Y. Xiao, C. Linton, and M. Burzo. 2015b. Deception detection using real-life trial data. In <i>17th ACM International Conference on Multimodal Interaction, ICMI 2015</i>. 421, 440</p>
<p class="ref">T. Pfister and M. Pietik&#228;inen. 2012. Electronic imaging &#38; signal processing automatic identification of facial clues to lies. <i>SPIE Newsroom</i>. <a href="http://tomas.pfister.fi/">http://tomas.pfister.fi/</a>. 420, 428</p>
<p class="ref">T. Qin, J. Burgoon, and J. Nunamaker. 2004. An exploratory study on promising cues in deception detection and application of decision tree. In <i>System Sciences, 2004. Proceedings of the 37th Annual Hawaii International Conference on</i>, pp. 23&#8211;32. DOI: 10.1109/HICSS.2004.1265083. 441</p>
<p class="ref">T. Qin, J. K. Burgoon, J. P. Blair, and J. F. Nunamaker. 2005. Modality effects in deception detection and applications in automatic deception-detection. In <i>Proceedings of the 38th Hawaii International Conference on System Sciences</i>. DOI: 10.1109/HICSS.2005.436. 441</p>
<p class="ref">B. Rajoub and R. Zwiggelaar. 2014. Thermal facial analysis for deception detection. <i>IEEE Transactions on Information Forensics and Security</i>, PP(99): 1&#8211;1. DOI: 10.1109/TIFS.2014.2317309. 420</p>
<p class="ref">D. Shastri, M. Papadakis, P. Tsiamyrtzis, B. Bass, and I. Pavlidis. July 2012. Perinasal imaging of physiological stress and its affective potential. <i>IEEE Transactions on Affective Computing</i>, 3(3): 366&#8211;378. DOI: 10.1109/T-A1FFC.2012.13. 420</p>
<p class="ref">C. Strapparava and A. Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. In <i>Proceedings of the 4th International Conference on Language Resources and Evaluation</i>. Lisbon. 425</p>
<p class="ref"><a id="page_452"/>M. K. Taylor, D. S. Horning, J. F. Chandler, J. B. Phillips, J. Y. Khosravi, J. E. Bennett, H. Halbert, B. J. Fern, and H. Gao. 2010. A comparison of approaches to detect deception. Technical Report ADA537848, Naval Aerospace Medical Research Laboratory. 431</p>
<p class="ref">Y.-L. Tian, T. Kanade, and J. Cohn. 2005. Facial expression analysis. In <i>Handbook of Face Recognition</i>, pp. 247&#8211;275. New York; Springer. 429</p>
<p class="ref">C. Toma and J. Hancock. 2010. Reading between the lines: linguistic cues to deception in online dating profiles. In <i>Proceedings of the 2010 ACM conference on Computer supported cooperative work</i>, CSCW &#8217;10, pp. 5&#8211;8. ACM, New York. DOI: 10.1145/1718918.1718921. 425, 426</p>
<p class="ref">P. Tsiamyrtzis, J. Dowdall, D. Shastri, I. Pavlidis, M. Frank, and P. Eckman. 2005. Lie detection - recovery of the periorbital signal through tandem tracking and noise suppression in thermal facial video. In <i>SPIE Conference on Sensors and Command Control Communications and Intelligence Technologies for Homeland Security and Homeland Defense IV</i>, pp. 555&#8211;566. 432</p>
<p class="ref">P. Tsiamyrtzis, J. Dowdall, D. Shastri, I. T. Pavlidis, M. G. Frank, and P. Ekman. 2007. Imaging facial physiology for the detection of deceit. <i>International Journal of Computer Vision</i>, 71(2): 197&#8211;214. ISSN 0920-5691. DOI: 10.1007/s11263-006-6106-y. 431, 432</p>
<p class="ref">B. Verhoeven and W. Daelemans. 2014. Clips stylometry investigation (csi) corpus: A dutch corpus for the detection of age, gender, personality, sentiment and deception in text. In N. C. C. Chair, K. Choukri, T. Declerck, H. Loftsson, B. Maegaard, J. Mariani, A. Moreno, J. Odijk, and S. Piperidis, eds., <i>Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&#8217;14)</i>. European Language Resources Association (ELRA), Reykjavik, Iceland. 427</p>
<p class="ref">B. Verschuere, V. Prati, and J. De Houwer. 2009. Cheating the lie-detector: Faking the autobiographical iat. <i>Psychological Science</i>, 20: 410&#8211;413. DOI: 10.1111/j.1467-9280.2009.02308.x. 430</p>
<p class="ref">A. Vrij. 2001. <i>Detecting Lies and Deceit: The Psychology of Lying and the Implications for Professional Practice</i>. Wiley Series in the Psychology of Crime, Policing and Law. Wiley. 420, 422, 430</p>
<p class="ref">A. Vrij, P. Granhag, and S. Porter. dec 2010. Pitfalls and opportunities in nonverbal and verbal lie detection. <i>Psychological Science in the Public Interest</i>, 11(3): 89&#8211;121. DOI: 10.1177/1529100610390861. 420</p>
<p class="ref">D. Warkentin, M. Woodworth, J. Hancock, and N. Cormier. 2010. Warrants and deception in computer mediated communication. In <i>Proceedings of the 2010 ACM conference on Computer supported cooperative work</i>, pp. 9&#8211;12. ACM. DOI: 10.1145/1718918.1718922. 425</p>
<p class="ref">L. Warmelink, A. Vrij, S. Mann, S. Leal, D. Forrester, and R. P. Fisher. 2011. Thermal imaging as a lie detection tool at airports. <i>Law and Human Behavior</i>, 35(1): 40&#8211;48. ISSN 0147&#8211;7307. DOI: 10.1007/s10979-010-9251-3. 432</p>
<p class="ref"><a id="page_453"/>M. Yancheva and F. Rudzicz. August 2013. Automatic detection of deception in child-produced speech using syntactic complexity features. In <i>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>, pp. 944&#8211;953. Association for Computational Linguistics, Sofia, Bulgaria. 426</p>
<p class="ref">D. Yu, Y. Tyshchuk, H. Ji, and W. A. Wallace. 2015. Detecting deceptive groups using conversations and network analysis. In <i>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015</i>, July 26&#8211;31, 2015, Beijing, China, Volume 1: Long Papers, pp. 857&#8211;866. DOI: 10.3115/v1/P15-1083. 426</p>
<p class="ref">Y. Zhou, P. Tsiamyrtzis, P. Lindner, I. Timofeyev, and I. Pavlidis. May 2013. Spatiotemporal smoothing as a basis for facial tissue tracking in thermal imaging. <i>IEEE Transactions on Biomedical Engineering</i>, 60(5): 1280&#8211;1289. DOI: 10.1109/TBME.2012.2232927. 420</p>
<p class="ref">Z. Zhu, P. Tsiamyrtzis, and I. Pavlidis. 2007. Forehead thermal signature extraction in lie detection. In <i>29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 2007. EMBS 2007</i>, pp. 243&#8211;246. DOI: 10.1109/IEMBS.2007.4352269. 432</p>
<p class="ref">Z. Zhu, P. Tsiamyrtzis, and I. Pavlidis. 2008. The segmentation of the supraorbital vessels in thermal imagery. In <i>IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, 2008. AVSS &#8217;08</i>, pp. 237&#8211;244. DOI: 10.1109/AVSS.2008.36. 432</p>
<p class="ref">M. Zuckerman, B. M. DePaulo, and R. Rosenthal. 1981. Verbal and nonverbal communication of deception. <i>Advances in Experimental Social Psychology</i>, 14(1): 59. 423, 437</p>
<p class="line"/>
<p class="note"><a id="fn1" href="#rfn1">1</a>.&#160;&#160;<a href="http://lit.eecs.umich.edu/~deceptiondetection/">http://lit.eecs.umich.edu/~deceptiondetection/</a></p>
<p class="note"><a id="fn2" href="#rfn2">2</a>.&#160;&#160;<a href="http://myleott.com/op_spam/">http://myleott.com/op_spam/</a></p>
<p class="note"><a id="fn3" href="#rfn3">3</a>.&#160;&#160;<a href="http://www.cs.uic.edu/~liub/FBS/fake-reviews.html">http://www.cs.uic.edu/~liub/FBS/fake-reviews.html</a></p>
<p class="note"><a id="fn4" href="#rfn4">4</a>.&#160;&#160;Available from the authors upon request</p>
<p class="note"><a id="fn5" href="#rfn5">5</a>.&#160;&#160;<a href="http://tomas.pfister.fi/">http://tomas.pfister.fi/</a></p>
<p class="note"><a id="fn6" href="#rfn6">6</a>.&#160;&#160;<a href="http://www.cs.cmu.edu/~face/facs.htm">http://www.cs.cmu.edu/~face/facs.htm</a></p>
<p class="note"><a id="fn7" href="#rfn7">7</a>.&#160;&#160;TheCERTtoolkit is no longer freely available. However, theCERTsuccessor, The Facial Analysis Toolbox, is available as a commercial toolkit at <a href="http://imotions.com/">http://imotions.com/</a></p>
<p class="note"><a id="fn8" href="#rfn8">8</a>.&#160;&#160;The LIWC lexicon, available at <a href="http://liwc.wpengine.com/">http://liwc.wpengine.com/</a>, is a resource developed for psycholinguistic analysis and contains about 70 word classes relevant to psychological processes (e.g., emotion, cognition).</p>
<p class="note"><a id="fn9" href="#rfn9">9</a>.&#160;&#160;<a href="http://deceptiondetection.eecs.umich.edu/">http://deceptiondetection.eecs.umich.edu/</a></p>
</body>
</html>