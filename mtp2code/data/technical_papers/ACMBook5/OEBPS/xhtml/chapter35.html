<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >
<head>
<title>The VR Book</title>
<link rel="stylesheet" type="text/css" href="../styles/9781970001143.css"/>
</head>
<body>
<h2 class="h2"><a id="page_473"></a><a id="ch35"></a><span class="blue1">35</span></h2>
<h2 class="h2b"><span class="blue">The Present and Future State of VR</span></h2>
<p class="noindent">In 2015, low-cost consumer VR technology is surpassing professional VR/HMD systems. A couple of years ago, even with an unlimited budget, you could not buy a system with the resolution, field of view, low latency, low weight, and overall quality that is now available at a price that anyone can afford. In addition, tools are accessible by anyone and are quite easy to use. This is resulting in the democratization of VR so that anyone can take part in defining where VR is going. VR is no longer a tool only for academics or corporate entities. The best VR technologies and experiences are just as likely to be created by a team of indie developers as by a Fortune 500 company.</p>
<p class="indent">Some of the challenges described in this chapter will open the door for the greatest opportunities over the next few years and beyond. This chapter describes some of the most exciting possibilities where VR is already going and what the future of VR might look like.</p>
<h3 class="h3"><a id="lev35.1"></a><strong><span class="font">35.1</span> Selling VR to the Masses</strong></h3>
<p class="noindent">Although VR is certainly an exciting industry to be in and many people know about it, the general population is not yet buying it. Instead, VR is being sold to innovators as a technical marvel. However, technology is not what is important for most people. In the future, the manner in which the story, emotions, and benefits are sold will need to be more compelling to reach a wider audience. How will this be done in a way that is more engaging to the masses so that they demand VR?</p>
<p class="indentbullett">&#8226; Through entertainment experienced in a way no other technology can provide?</p>
<p class="indentbullet">&#8226; Through networked worlds that ease and enhance social sharing?</p>
<p class="indentbullet">&#8226; Through fulfilling people&#8217;s needs and making life easier?</p>
<p class="indentbullet">&#8226; Through enhancing quality of life via immersive health care and physical/mental exercise?</p>
<p class="indentbullet"><a id="page_474"></a>&#8226; Through cost savings and increased profitability?</p>
<p class="indentbullet">&#8226; Through new entrepreneurship ventures that we can&#8217;t yet even begin to fathom?</p>
<p class="indentt">Focusing on any one of these is certainly a noble effort. Each will likely play a big part in changing many people&#8217;s lives.</p>
<h3 class="h3"><a id="lev35.2"></a><strong><span class="font">35.2</span> Culture of the VR Community</strong></h3>
<p class="noindent">In some ways, VR culture is already forming. Consider the VR Meetup phenomenon.<a id="rpg474fn1"></a><sup><a href="chapter35.html#pg474fn1">1</a></sup> In 2012, Karl Krantz, a self-proclaimed introvert, began to contact what he thought would be a small number of local VR professionals and enthusiasts to start a VR Meetup to share and discuss their creations. Today, Karl has evolved into somewhat of a VR celebrity. Not only has his local meetup expanded to over 2,000 members, but his model of allowing anyone to showcase their VR experiences at public events has been replicated throughout the world. Pockets of hundreds of VR enthusiasts in every major city gather to share their virtual worlds and discuss the latest VR trends on a regular basis. Non-VR meetups often struggle to have more than a few people attend their events, yet all one needs to do for a VR Meetup is to set up an account, find a <a id="pg474lev1"></a>location, set a date, send out some tweets and emails, and people will flock to the event. In the San Francisco Bay Area alone, there are so many different VR Meetups per month that it is difficult to keep up with all of them. Whereas the popular media has portrayed VR as being anti-social, these meetups have proven VR to be the social lubricant that gets normally introverted individuals passionately conversing.</p>
<p class="indent">Both Brendan Iribe, CEO of Oculus, and Mark Zuckerburg, CEO of Facebook, claim there will someday be a billion or more VR users [<a href="reference.html#ref348"><span class="blue">Zuckerberg 2014</span></a>, <a href="reference.html#ref124"><span class="blue">Hollister 2014</span></a>]. In order for this to happen, an entire cultural shift is going to be required for the masses to accept such advanced mind-altering technology. Will this actually happen? It is certain to happen at some point as both humans and technology evolve. The question is, will that be 5 years from now or 50 years from now? In the short term, will it only be the fortunate few who care as is the case in Neal Stephenson&#8217;s <em>Snow Crash</em> or will VR scale more quickly? Even if the Metaverse is not accessed by the hundreds of millions, various forms of VR will certainly add value to some smaller groups of us.</p>
<p class="indent">Regardless of who uses VR, cultural patterns of rules, hierarchies, and social constraints will certainly form within virtual worlds. Some of these will be coded into the experiences, but much of the social and cultural structure will evolve naturally just as it does in the real world. What actions will be considered rude and what actions will <a id="page_475"></a>be considered polite? What will the penalty be for unacceptable behavior? Will the equivalent of government entities form that impose laws for the common good? Only time will tell, but these questions have important implications for the future of VR and should be considered when designing new worlds.</p>
<h3 class="h3"><a id="lev35.3"></a><strong><span class="font">35.3</span> Communication</strong></h3>
<p class="noindent">The book began with a discussion of how VR at its core is communication (Section <a href="chapter01.html#lev1.2"><span class="blue">1.2</span></a>). This section describes how communication in VR will be taken to the next level beyond just interacting with objects as is done with most current VR applications.</p>
<h4 class="h4"><a id="lev35.3.1"></a><strong><span class="font1">35.3.1</span> A New Generative Language</strong></h4>
<p class="noindent">Languages are not necessarily made of words but are any form of communication (e.g., body language). A <strong>generative language</strong> (also called future-based language), in contrast to a descriptive language, has &#8220;the power to create new futures, to craft vision, and to eliminate the blinders that are preventing people from seeing new possibilities&#8221; [<a href="reference.html#ref343"><span class="blue">Zaffron and Logan 2009</span></a>]. In short, generative language transforms the <a id="pg475lev1"></a>way we preceive the world. VR can be thought of as a new generative language because we are creating new experiences that words cannot fully describe and can only be fully conveyed by actually experiencing it oneself. The language of VR will certainly bring about things that would never be created from traditional language alone, our past experiences, or our current understanding.</p>
<h4 class="h4"><a id="lev35.3.2"></a><strong><span class="font1">35.3.2</span> Symbolic Communication</strong></h4>
<p class="noindent">Direct communication is not always the best way to interact within VR. Indirect <strong>symbolic communication</strong> is the use of abstract symbols (e.g., text) to represent objects, ideas, concepts, quantities, etc. [<a href="reference.html#ref24"><span class="blue">Bowman et al. 2004</span></a>]. Consider how we use indirect symbolic communication in the real world. Symbolic communication enables us to convey information efficiently, precisely, and concisely; provides a way to clearly think, both inside our minds and in the physical world (e.g., paper and whiteboards); and allows structured data to persist throughout time.</p>
<p class="indent">In VR, symbolic output is quite easy to do and is used quite effectively. However, symbolic input is not so straightforward. Other than the widgets and panels interaction techniques described in Section <a href="chapter28.html#lev28.4.1"><span class="blue">28.4.1</span></a> that work well for small numbers of options, symbolic input for more generalized input is rarely used. There are currently no obvious ways to symbolically input data in a way that is effective, efficient, and elegant.</p>
<p class="indent"><a id="page_476"></a>Inventing new widgets can certainly help. Consider a touch wheel interface on a 2D tablet touch screen for entering dates. Such a widget works extremely well for touch screens but is not great for a mouse/keyboard interface. We need equivalent symbolic input techniques specifically for VR. And we need to go beyond that. Theoretically, speech, gestures, chord keyboards, and pinch input are ideal for symbolic input. However, there are multiple practical challenges to getting such theoretical concepts to work well within VR.</p>
<p class="indent">Speech recognition works well in controlled conditions. However, as many can attest to, talking to a voice prompt system via telephone can be extremely frustrating. Even if a system perfectly recognized the spoken word, there still remain significant challenges. In addition to semantic parsing and understanding, challenges include the context words are spoken in (consider the phrase &#8220;Put it to the left&#8221;), some people being resistant to using such systems due to lack of privacy, a perception of bothering others, and feeling awkward talking with a machine. It remains to be seen if speech recognition becomes more common within VR.</p>
<p class="indent">Gestures have similar challenges as voice recognition. In addition to error rates, fatigue can be an issue. Better tracking of the entire hand will certainly help so large dynamic gestures will not be required as is the case with Microsoft Kinect. It remains to be seen if reliability from camera-based systems is inherently a largely unsolvable physics problem due to line-of-sight challenges or if that can somehow be worked around. Gloves may become more common as gesture recognition improves and users accept the inherent encumbrance of wearing hardware. Attempts have been made with sign language recognition but have failed largely due to inaccurate and unreliable finger tracking. However, as gesture recognition continues to improve, sign language may indeed become a useful method of symbolic input. A place to start could be with numeric input since only a small number of gestures would need to be recognized and easy to learn since we already understand how to count with our fingers. The system must recognize more gestures than just the digits 0&#8211;9, such as to start numeric entry and delete an entry, but not many.</p>
<p class="indent">Many challenges have nothing to do with technical capability. The best design does not always win. Consider how smartphones first took input from a 12-digit matrix phone design that maps multiple presses on each digit to alphanumeric input (or word completion that attempts to guess what the user intended by mapping multiple presses to words in a dictionary). Today, smartphones still take symbolic input through a QWERTY keyboard touch interface that was originally designed for ten fingers but is now used with one or two fingers. Swipe pattern recognition as the finger stays on the screen makes it more efficient, but this interface is certainly not ideal. Like the smartphone industry, transition to better symbolic input within VR will take time and will evolve along a non-optimal path. Such a slow response to designing <a id="page_477"></a>for the medium has already been proven to also be the case for VR, as most VR widgets are just replications of desktop widgets.</p>
<p class="indent">Touch can be extremely important for symbolic input. Haptics will help by conveying feedback such as pushing a key on a virtual keyboard. Buttons on chord keyboards inherently provide physical feedback from the feel of the button. Such capability can easily be integrated into tracked hand-held controllers. Pinch gloves also provide the sense of touch when two fingers touch. However, there is a steep learning curve to learning complex new input patterns. If there becomes enough value and demand for reliable symbolic input, then perhaps users will accept the pain of change (such as people were willing to learn to use typewriters).</p>
<h4 class="h4"><a id="lev35.3.3"></a><strong><span class="font1">35.3.3</span> Creating Empathy with Virtual Humans</strong></h4>
<p class="noindent">Science fiction has predicted humans would live and interact with computer entities that resemble humans in natural ways, even to the point of developing an emotional relationship with those artificial entities. That is now already becoming a reality. Researchers from the University of Southern California Institute for Creative Technologies have developed such human-like entities complete with interactive social skills and connection/rapport-building capability. The system works by sensing the <a id="pg477lev1"></a>user&#8217;s emotional state and responding appropriately for psychotherapy applications (Figure <a href="chapter35.html#fig35.1"><span class="blue">35.1</span></a>). Those who believed they were interacting with a computer-controlled virtual human versus a human-controlled virtual human reported a lower fear of self-disclosure, reported lower impression management (only disclosing positive information), displayed sadness more intensely, and were rated by observers as more willing to disclose [<a href="reference.html#ref191"><span class="blue">Lucas et al. 2014</span></a>]. Although challenges certainly exist to integrate such a system within fully immersive VR (e.g., how do the sensors detect emotions conveyed on the face when half the face is covered by an HMD?), it is certainly only a matter of time when such capability is fully integrated into fully immersive VR. With fully immersive VR, virtual humans appear more life-size and real, rather than being confined to a screen, interacting with users as if they were real entities as envisioned by science fiction writers. It is unknown where this might eventually lead, but there is certainly potential to integrate artificial intelligent entities with VR that could result in helping real people overcome barriers that occur with traditional human-to-human communication.</p>
<h4 class="h4"><a id="lev35.3.4"></a><strong><span class="font1">35.3.4</span> Brain-to-Brain Communication</strong></h4>
<p class="noindent">Researchers from Neuroelectrics and other institutions recently conducted a proof-of-concept experiment where individuals were able to directly convey information through brain-to-brain communication without intervention of motor or peripheral sensory systems (Figure <a href="chapter35.html#fig35.2"><span class="blue">35.2</span></a>) [<a href="reference.html#ref103"><span class="blue">Grau et al. 2014</span></a>]. Binary streams of encoded words were <a id="page_478"></a>transmitted between the remote minds of emitter and receiver participants, representing the realization of a human brain-to-brain interface. This was done by capturing voluntary motor imagery-controlled electroencephalographic (EEG) changes from one participant, encoding the information, and sending it from India to a remote participant in France through the Internet. The information was transformed to signals that conveyed to the receiving participant the conscious perception of phosphenes (light flashes) through neuronavigated, robotized transcranial magnetic stimulation (TMS).</p>
<p class="image"><a id="fig35.1"></a><img src="../images/f0478-01.png" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 35.1</span> A computer-controlled virtual human (right) builds empathy with a user (left) by sensing his state and responding appropriately.</strong> (Courtesy of USC Institute for Creative Technologies. Principal Investigators: Albert (Skip) Rizzo and Louis-Philippe Morency)</p>
<p class="indent">The results provided a demonstration for the development of conscious brain-to-brain communication technologies. More fully developed implementations will open new research venues in cognitive, social, and clinical neuroscience and the scientific study of consciousness. Long-term possibilities include being able to modify one&#8217;s sensory VR experience by thought alone. Such communication technologies will certainly have a profound impact on more than just VR technology.</p>
<p class="image"><a id="page_479"></a><a id="fig35.2"></a><img src="../images/f0479-01.png" alt="image"/></p>
<p class="caption"><a id="pg479lev1"></a><strong><span class="blue">Figure 35.2</span> The brain-to-brain communication system as described in <a href="reference.html#ref103"><span class="blue">Grau et al.</span></a> [<a href="reference.html#ref103"><span class="blue">2014</span></a>].</strong></p>
<h4 class="h4"><a id="lev35.3.5"></a><strong><span class="font1">35.3.5</span> Full Neural Input and Output</strong></h4>
<p class="noindent">Direct neural input through some standardized connection, as done in <em>The Matrix</em> trilogy, is certainly many years away. The transition will be very gradual, starting with neural input and output as done with Neuroelectrics described above.</p>
<p class="indent">Visual displays are already moving closer to the brain via virtual retinal displays where a laser draws images onto the retina [<a href="reference.html#ref276"><span class="blue">Schowengerdt et al. 2003</span></a>] as done by the company Magic Leap. Visual displays will eventually move to contact lenses, starting with augmented reality, but eventually providing the capability to not only draw on the world but to completely block out the real world. The next step will be either a projector located inside the eye or signals sent directly to the retina. In fact, multiple companies have already started to pursue direct retinal stimulation. Simple retinal stimulators providing a matrix display of 60 &#8220;pixels&#8221; have already been successfully implanted in blind patients, enabling them to see basic shapes, motions, and even letters/words in the real world (via mapping from a digital camera mounted on glasses to the implanted electrodes) [<a href="reference.html#ref58"><span class="blue">da Cruz et al. 2013</span></a>].</p>
<p class="indent">Things become exceedingly complex beyond the retina as the parvo and magno cells transmitting signals to the superior colliculus and lateral geniculate nucleus <a id="page_480"></a>(Section <a href="chapter08.html#lev8.1.1"><span class="blue">8.1.1</span></a>) are not simply 2D representations of images. Ideas of how to transmit directly to the visual cortex is far beyond what can be predicted today, but it will likely require completely rethinking the concept of visual signals.</p>
<p class="indent">Virtual vestibular input would also be quite challenging to do in an accurate/precise way to be useful in reducing motion sickness. Artificial input to the vestibular system exists today, but in a very primitive form that adds to sickness and imbalance more than it helps. Regardless, if more control can be provided to the vestibular system, or more directly to the vestibular nuclei, then this may someday be feasible.</p>
<p class="indent">There is perhaps less reason for direct audio input as headphones can already be largely hidden from view inside the ear. However, if there is a need, this may be easier to do than other sensory input due to the more simplified nature of audio and lower bandwidth requirements as compared to vision.</p>
<p class="indent">Neural output to control objects within the virtual world and/or the real world is an entirely different story. There is already demand for such capability for those who are disabled. Prosthetic devices are already controlled by electromyography signals. One can easily imagine such technology could be extended to augmented and virtual reality. In fact, one only need to attend the Neurogaming Conference and Expo held every year in San Francisco to control a basic VR interface via thought alone.</p>
<h3 class="h3"><a id="lev35.4"></a><strong><span class="font">35.4</span> Standards and Open Source</strong></h3>
<p class="noindent">Some consider standards to be controversial. At one extreme there are those who say any and all standards hinder innovation whereas there are others who want to standardize everything. In truth, standards are simply a tool that, if used wisely, can simplify life for everyone, ease communication across groups, foster development across multiple platforms, and enable consumers to more objectively compare between competing products. Standards can also provide a catalyst for industry leaders to regularly get together, collaborate, and upgrade their findings as they progress&#8212;which can enhance innovation rather than hinder it. If standards blocked innovation, the automotive industry, the gaming industry, the Internet, and even VR would not be where it is now.</p>
<p class="indent">When defining standards, it&#8217;s a misnomer that they only refer to interoperability, which is often the main issue of contention within the industry. Interoperability is only part of the puzzle as there are other fundamental standards that need to be pursued. Standards can help with quality expectations, basic language, health and safety, and even defining common goals.</p>
<p class="indent">Precise and consistent terminology is one area where standards would be useful. For example, most people casually discuss field of view without specifying if that is the <a id="page_481"></a>horizontal field of view or the diagonal field of view (among other factors). Similarly, latency is not well defined. Contrary to what many people believe, latency is more than simply the inverse of the frame rate or refresh rate (Section <a href="chapter15.html#lev15.4"><span class="blue">15.4</span></a>). Furthermore, in a raster display, is latency from the time of some action until the time that the resulting first pixel in the upper-left corner in a frame (the start of the raster scan) is displayed or until the time the frame&#8217;s center pixel is displayed (a difference of 8 ms for a 60 Hz display)? Or what about the response time of the pixel? Depending on the technology used, pixel response can take several milliseconds, if not tens of milliseconds, to completely reach 100% of its intended intensity. Even if pixel response is immediate, what if the pixel persists for some time? Is latency up to the time the pixel initially appears or up to the average time that it is visible? Such detailed differences can make a big difference when discussing latency. Add these differences due to imprecise/unstandardized definitions together and the variability can easily be 20 ms.</p>
<p class="indent">These are some of the most basic elements of VR, and yet the industry players are far apart from one another, and this contributes to customer misunderstanding and unmet expectations. The importance of standards is just as much about interoperability between people and ideas as it is about compatibility and commonalities between <a id="pg481lev1"></a>vendors.</p>
<h4 class="h4"><a id="lev35.4.1"></a><strong><span class="font1">35.4.1</span> Open Source</strong></h4>
<p class="noindent"><strong>Open source</strong> is a class of licensing that usually pertains to software. It works by allowing everyone to contribute to a given project that is free to use and transparent for all to see [<a href="reference.html#ref275"><span class="blue">Schneider 2015</span></a>]. When something is published as open source, it immediately gives others the right to use the same code from that point on, though they can&#8217;t charge money for it. The idea can be rewritten from scratch and sold outside of the open source world, but modifications of existing code have to be transparent and free.</p>
<h5 class="h5"><strong>Open Source Interoperability</strong></h5>
<p class="noindent">In the 1990s, Russ Taylor led the development of the VR Peripheral Network (VRPN), an open source device-independent and network-transparent system for communicating with VR devices [<a href="reference.html#ref306"><span class="blue">Taylor et al. 2001a</span></a>]. VRPN has since become the most-often-used software library for connecting VR devices to VR applications. Russ claims one reason for its success is that &#8220;you can only standardize what nobody cares about&#8221; [<a href="reference.html#ref307"><span class="blue">Taylor et al. 2001b</span></a>]. VR creators do care about having a standard way of connecting with VR devices where different devices can be used with the same application, but they do not care about the low-level detail of how that is accomplished.</p>
<p class="indent"><a id="page_482"></a>OSVR (Open Source VR) is a collaboration that is owned and maintained by Razer and Sensics. It&#8217;s not a formal organization or non-profit structure but is instead a platform that is defined by signed licensing agreements between Razer and the participating vendors. OSVR is promoted as having over 250 commercial hardware developers, game studios, and research institutions involved.</p>
<p class="indent">Russ is now one of the primary developers for the OSVR platform that includes both open source software and hardware designs so that anyone can freely build their own or modify existing systems.</p>
<h4 class="h4"><a id="lev35.4.2"></a><strong><span class="font1">35.4.2</span> Platform-Specific/De Facto Standards</strong></h4>
<p class="noindent">A <strong>de facto standard</strong> is a system or platform that has achieved a dominant position due to the sheer volume of people associated with it through public acceptance or market forces. For example, the Microsoft Xbox and PC use the DirectX de facto standard. Similarly, Valve has Steam OS. Advanced Micro Devices (AMD) has their own LiquidVR platform while Nvidia has GameWorks VR. They are platforms because their standards work with a range of compliant hardware, but they are not open standards.</p>
<h4 class="h4"><a id="lev35.4.3"></a><a id="pg482lev1"></a><strong><span class="font1">35.4.3</span> Open Standards</strong></h4>
<p class="noindent"><strong>Open standards</strong> are &#8220;standards made available to the general public and are developed (or approved) and maintained via a collaborative and consensus driven process&#8221; [<a href="reference.html#ref139"><span class="blue">ITU-T 2015</span></a>].</p>
<p class="indent">What is key for an open standard is collaboration and agreement across a wide range of individuals with equal voting rights. Contributions can&#8217;t be thrown in and taken out unless there is adequate group discussion and agreement. The Khronos Group has open source platforms, and the finalized spec is determined by the membership through votes. Without balance and equal voting share, huge innovations can get missed because the larger participants don&#8217;t want to collaborate or they simply outgun the smaller players.</p>
<p class="indent">Unless all VR work moves toward a platform that a single vendor controls, the most effective open standards are backed by a formal non-profit organization, and everyone must be welcome to participate with equal rights. Unless this happens, the effort will fall apart and lose its credibility. Non-profit structures exist because they force developments to be open and transparent [<a href="reference.html#ref202"><span class="blue">Mason 2015</span></a>].</p>
<h5 class="h5"><strong>Notable Open Standards Organizations</strong></h5>
<p class="noindent">The Khronos Group is a good working example of a non-profit standards organization, and their work is free of royalty fees and licensing fees. OpenGL, OpenCL, WebGL, and <a id="page_483"></a>more are all credited to the Khronos Group. To participate, members pay an annual fee, decisions are voted on, and the standards are implemented.</p>
<p class="indent">The Immersive Technology Alliance (ITA; <span class="weblink"><a href="http://www.ita3d.com"><span class="blue">http://www.ita3d.com</span></a></span>) is a formal non-profit corporation that was originally founded in 2009 under a different name. Its executive director is Neil Schneider, who also created Meant to be Seen (MTSB; <span class="weblink"><a href="http://mtbs3D.com"><span class="blue">http://mtbs3D.com</span></a></span>). MTBS is where the Oculus Rift was born and marks the spot where John Carmack and Palmer Luckey first met. The ITA exists to make immersive technology successful, and in addition to having its own working groups pertaining to standards and industry growth, it regularly collaborates with external organizations like SIGGRAPH, the Khronos Group, meetup organizations (e.g., SVVR), and more. They have also launched Immersed Access (<span class="weblink"><a href="http://www.immersedaccess.com"><span class="blue">http://www.immersedaccess.com</span></a></span>), an NDA-backed private community for professionals to share and learn from one another in a safe environment that is closed off from the press. Immersed Access features unofficial discussion areas for OSVR, Oculus, Valve, and other platforms.</p>
<h3 class="h3"><a id="lev35.5"></a><strong><span class="font">35.5</span> Hardware</strong></h3>
<p class="noindent">New VR hardware developments are now occurring on a regular basis largely due to the access of 3D printing. HMDs are becoming lighter and with wider fields of view. Hybrid tracking is improving precision and accuracy for both the head and the hands. Magic Leap claims to be solving the accommodation-vergence conflict. Numerous companies are improving upon full body tracking. Eventually, exoskeletons may be built to provide better haptics and to complement human abilities with superhuman powers.</p>
<p class="indent">The leading VR companies (Oculus, Valve, Sony, and Sixense) are all now creating tracked hand-held controller options at low price points (at least compared to older professional systems). Such controllers are currently the best way to interact with a majority of fully immersive VR experiences (although such applications are still relatively rare due to the lack of user ownership of such devices). This is significant as not having hands in VR is equivalent to being paralyzed in the real world. As these types of hand input devices become more available, then developers will create better and more innovative methods of interacting. At some point most all VR experiences, other than completely passive experiences, will enable users to interact with their hands.</p>
<p class="indent">Even with 6 DoF hand input devices, current hand input has been described as a limiting &#8220;boxing glove&#8221; style interface where fingers are rarely tracked, and if fingers are tracked, they are rarely tracked accurately and never with 100% reliability. Tyndall is working in collaboration with TSSG and NextGen Interactions on commercializing their extremely accurate glove technology, previously used for surgical training. The <a id="page_484"></a>goal is to provide a VR glove at a consumer price point that overcomes the significant challenges previous gloves have faced. Figure <a href="chapter35.html#fig35.3"><span class="blue">35.3</span></a> shows a prototype of the glove.</p>
<p class="image"><a id="fig35.3"></a><img src="../images/f0484-01.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 35.3</span> Early prototype of the Tyndall/TSSG VR glove.</strong> (Courtesy of Tyndall and TSSG)</p>
<h3 class="h3"><a id="lev35.6"></a><strong><span class="font">35.6</span> The Convergence of AR and VR</strong></h3>
<p class="noindent">Augmented reality and virtual reality have many differences, yet there are also many similarities and the two will likely converge. Although the experiences may still be very different (VR is transporting someone to a different world whereas augmented reality adds to the local world), the same hardware might be used for both. For example, cameras have been capturing the real world and bringing it into the non-see-through HMD VR experience since the 1990s (a form of augmented virtuality; see Section <a href="chapter03.html#lev3.1"><span class="blue">3.1</span></a> and Figure <a href="chapter27.html#fig27.6"><span class="blue">27.6</span></a>). So the convergence of AR and VR is not new from a research perspective, but would be new as far as catching mainstream attention. Conversely, future optical-see-through HMDs will be able to make individual pixels opaque so digital imagery can completely occlude all or part of the real world.</p>
<p class="footnote"><a id="pg474fn1"></a><a href="chapter35.html#rpg474fn1">1</a>. To find a local VR Meetup, go to <span class="blue"><span class="weblink"><a href="http://vr.meetup.com">http://vr.meetup.com</a></span></span>.</p>
</body>
</html>
