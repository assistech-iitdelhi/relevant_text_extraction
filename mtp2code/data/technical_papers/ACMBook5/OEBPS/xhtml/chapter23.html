<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >
<head>
<title>The VR Book</title>
<link rel="stylesheet" type="text/css" href="../styles/9781970001143.css"/>
</head>
<body>
<h2 class="h2"><a id="page_261"></a><a id="ch23"></a><span class="blue1">23</span></h2>
<h2 class="h2b"><span class="blue">Transitioning to VR Content Creation</span></h2>
<p class="chblock"><em>It is interesting to realize that while the VR industry is rushing to develop VR game systems, the real task will be to fill these systems with interesting and entertaining environments. This task is challenging because the medium is much richer and demanding than existing video games. While a conventional game requires the designer to create a two-dimensional video environment, the nature of VR requires that a completely interactive and rich environment be created</em>.</p>
<p class="chattribute">&#8212;Mark Bolas [<a href="reference.html#ref20"><span class="blue">1992</span></a>]</p>
<p class="noindent"><a id="pg261lev1"></a>VR development is very different than traditional product or software development. This chapter provides some of the most important points to consider when creating VR content.</p>
<h3 class="h3"><a id="lev23.1"></a><strong><span class="font">23.1</span> Paradigm Shifts from Traditional Development to VR Development</strong></h3>
<p class="noindent">VR is very different than any other form of media. In order to fully understand and take advantage of VR, it is very useful to approach it as a new artistic medium for expression [<a href="reference.html#ref20"><span class="blue">Bolas 1992</span></a>]. VR is extremely cross-disciplinary and thus it is useful to study and understand other disciplines. However, no single discipline is sufficient by itself. There will be things that work from other disciplines and some that won&#8217;t. Be prepared to give up on those things that don&#8217;t work. The following are some key points that should always be at the forefront of a VR content creator&#8217;s mind.</p>
<p class="hangt"><strong>Focus on the user experience.</strong> For VR, the user experience is more important than for any other medium. A bad website design is still usable. A bad VR design will make users sick. The experience must be extremely compelling and engaging to convince people to stick a piece of hardware on their face.</p>
<p class="hanga"><strong>Minimize sickness-inducing effects.</strong> Whereas real-world motion sickness is common (e.g., seasickness or from a carnival ride), sickness is almost never an issue <a id="page_262"></a>with other forms of digital media. More traditional digital media does occasionally cause sickness (e.g., IMAX and 3D film), but it is minor compared to what sickness can occur with VR if not designed properly (Part <a href="part03.html#part3"><span class="blue">III</span></a>).</p>
<p class="hanga"><strong>Make aesthetics secondary.</strong> Aesthetics are nice to have, but other challenges are more important to focus on at the beginning of a project. Start with basic content and incrementally build upon it while the essential requirements are maintained. For example, frame rate is absolutely essential in reducing latency, so geometry should be optimized as necessary. In fact, frame rate is so important that a core requirement of all VR systems should be to match or exceed the refresh rate of the HMD, and the scene should fade out when this requirement is not met (Section <a href="chapter31.html#lev31.15.3"><span class="blue">31.15.3</span></a>).</p>
<p class="hanga"><strong>Study human perception.</strong> Perceptions are very different in VR than they are on a regular display. Film and video games can be viewed from different angles with almost no impact on the experience. VR scenes are rendered from a very specific viewpoint of where the user is looking from. Depth cues are important for presence (Section <a href="chapter09.html#lev9.1.3"><span class="blue">9.1.3</span></a>), and inconsistent sensory cues can cause sickness (Section <a href="chapter12.html#lev12.3.1"><span class="blue">12.3.1</span></a>). Understanding how we perceive the real world is directly relevant to creating immersive content.</p>
<p class="hanga"><strong>Give up on having all the action in one part of the scene.</strong> No other form of media completely surrounds and encompasses the user. The user can look in any direction at any time. Many traditional first-person video games allow the user to look around with a controller, but there is still the option for the system to control the camera when necessary. Proper VR does not offer such luxury. Provide cues to direct users to important areas but do not depend upon them.</p>
<p class="hanga"><strong>Experiment excessively.</strong> VR best practices are not yet standardized (and they may never be) nor are they mature&#8212;there are a lot of unknowns so there must be room for experimentation. What works in one situation might not work in another situation. Test across a variety of people that fit within your target audience and make improvements based on their feedback. Then iterate. Iterate. Iterate&#160;.&#160;.&#160;.&#160;(Part <a href="part04.html#part4"><span class="blue">VI</span></a>).</p>
<h3 class="h3"><a id="lev23.2"></a><strong><span class="font">23.2</span> Reusing Existing Content</strong></h3>
<p class="noindent">Traditional digital media is very different from VR. With that being said, some content can be included or even ported to VR. 2D images or video is very straightforward to apply onto a texture map within a virtual environment. In fact, watching 2D movies within VR has proven to be surprisingly popular. Web content or any other content <a id="page_263"></a>can even be updated in real time and interacted with on a 2D surface such as that described in Section <a href="chapter28.html#lev28.4.1"><span class="blue">28.4.1</span></a>.</p>
<p class="indent">Although there are similarities, video game design is very different than VR design, primarily due to being designed for a 2D screen and not having head tracking. Concepts such as head tracking, hand tracking, and the accurate calibration required to match how we perceive the real world are core elements for VR experiences that the designer should consider from the start of the project. If any of these essential VR elements are not implemented well, then the mind will quickly reject any sense of presence and sickness may result. Because of these issues, porting existing games to VR without a redesign and rewrite of the game engine where appropriate is not recommended. Reusing assets and refactoring code where appropriate is the correct solution. With that being said, implementing the right solution requires resources and there will be those who port existing games with no or minimal modification of code. Thus, the following information is provided to help port games for those choosing this path.</p>
<h4 class="h4"><a id="lev23.2.1"></a><strong><span class="font1">23.2.1</span> Geometric Detail</strong></h4>
<p class="noindent">Games typically use texture excessively in place of 3D geometry. More depth cues, especially stereo cues, and motion parallax cues make textures obviously 2D. Whereas such flat cardboard-appearing worlds are not necessarily realistic, there is no concern for flat textures to cause sickness.</p>
<p class="indent">In addition, many standard video game techniques and geometric hacks simplify 3D calculations for better performance. Simplified geometry and lighting created with screen space techniques, normal maps, textures, billboard sprites, some shaders and shadows (depending on implementation), and other illusion of 3D in games are not actually 3D and often look flat or strange in VR. Many of these techniques fortunately often do work at further distances but should be avoided for close distances. For close objects to be most convincing, they should be modeled in detail. Such detailed objects can be swapped out with lower levels of detailed models and with geometric hacks when they become further from the viewpoint. Some code may need to be modified or rewritten to appear correct in VR, even for further objects.</p>
<h4 class="h4"><a id="lev23.2.2"></a><strong><span class="font1">23.2.2</span> Heads-Up Displays</strong></h4>
<p class="noindent"><strong>Heads-up displays</strong> (HUDs) provide visual information overlaid on the scene in the general forward direction. Traditional video-game implementations are especially problematic for VR. This is because most HUDs are implemented as a 2D overlay that is in screen space, not part of the scene. Because there is no depth, most ports simply place the same HUD image to the left and right eyes, resulting in binocular <a id="page_264"></a>cues being at an infinite depth. Unfortunately, this results in a binocular-occlusion conflict (Section <a href="chapter13.html#lev13.2"><span class="blue">13.2</span></a>), which is a major problem. When the two eyes see the same image of the HUD, the HUD appears at an infinite distance so the entire scene should occlude the HUD, but it does not. Some solutions for this are described below.</p>
<p class="indentnumbert">1. The easiest solution is to turn off all HUD elements. Some game engines enable the user to do this without modifying source code. However, some of the HUD information is important for status and game play, so this solution can leave players quite confused.</p>
<p class="indentnumber">2. Draw or render the HUD information to a texture and place onto a transparent quad at some depth in front of the user (and possibly angled and below eye level so the information is accessed by looking down) so that it becomes occluded when other geometry passes in front of it. Factors such as readability, occlusion of the scene, and accommodation-vergence conflict can occur, but these are relatively minor compared to binocular-occlusion conflict and adjustments can be made until reasonably comfortable values are found. This solution works reasonably well, except that the HUD information becomes occluded when other geometry passes in front of it.</p>
<p class="indentnumber">3. Separate out the different HUD elements and place them on the user&#8217;s body and/or in different areas relative to the user&#8217;s body (e.g., an information belt or at the user&#8217;s feet). This is the ideal solution but can take substantial work depending on the game and game engine.</p>
<h4 class="h4"><a id="lev23.2.3"></a><strong><span class="font1">23.2.3</span> Targeting Reticle</strong></h4>
<p class="noindent">A targeting <strong>reticle</strong> is a visual cue used for aiming or selecting objects and is typically implemented as part of the HUD. However, the solutions for a VR reticle may be different.</p>
<p class="indentnumbert">1. The reticle can be implemented in the same way as option &#35;2 for HUDs as described above. This results in the reticle behaving as a helmet with the reticle on the front of the helmet in front of the eyes. Like a HUD, a challenge with this solution is the reticle is seen as a double image when looking at the target in the distance. This is due to the eyes not being converged on the reticle and is congruent with how one sights a weapon in the real world. This is a more realistic solution as the real world requires one to close one eye to properly aim a weapon. One eye (ideally the system should enable the user to configure the reticle for his dominant eye) must be set to be the sighting eye so that the reticle crosshairs directly overlap the target. In order to know what the user is targeting, <a id="page_265"></a>the system must know what eye is being used in order to cast a ray from the eye through the reticle.</p>
<p class="indentnumber">2. Another option is to project the reticle onto (or just in front of) whatever is being aimed at. Although not as realistic and the reticle jumps large distance in depth, this is preferred by some users as being more comfortable and is less confusing when one doesn&#8217;t understand the need to close one eye to aim.</p>
<h4 class="h4"><a id="lev23.2.4"></a><strong><span class="font1">23.2.4</span> Hand/Weapon Models</strong></h4>
<p class="noindent">Similar to HUDs, the hands and/or weapons in desktop games are placed directly in front of the user, either as 2D textures or full 3D objects. The obvious problem is that 2D textures representing the hands/weapons will appear flat and not work well with VR.</p>
<p class="indent">Although not realistic and perhaps a bit disturbing at first, replacing 2D hands and arms with 3D hands without arms that are directly controlled with a tracked hand-held controller can work quite well in VR. However, hands with arms are more of a problem. In most first-person desktop video games there is no need to have a full body, so when the user looks down in a game ported to VR there is no body, or at best only some portion of the body. If the game includes hands, then the arms will likely be hanging in space. Rotating a tracked hand-held controller cannot be directly mapped to an entire static hand/arm model because the point of rotation should be about the hand, and rotation of the hand results in the entire arm rotating. In addition, many game engines have a completely different implementation for the hands and weapons than the rest of the world, so generalizing the hands and weapons to behave as other 3D objects may not be possible without re-architecting or refactoring the code. If arms are required, then some form of inverse kinematics will be required.</p>
<h4 class="h4"><a id="lev23.2.5"></a><strong><span class="font1">23.2.5</span> Zoom Mode</strong></h4>
<p class="noindent">Some games have a zoom mode with a tool or weapon such as a sniper rifle. A zoom lens that moves with the head causes a difference between the physical field of view and the rendered field of view, which results in an unstable virtual world and sickness when the head moves (a similar result can occur with real-world magnifying glasses; Section <a href="chapter10.html#lev10.1.3"><span class="blue">10.1.3</span></a>). Because of this, the zoom should be independent of head pose or only a small portion of the screen should be zoomed in (i.e., a small part of the screen where the scope is located). If the zoom is affected by head motion and it is not possible to prevent a large part of the scene from zooming in, then zooming should be disabled.</p>
</body>
</html>
