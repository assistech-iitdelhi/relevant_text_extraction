<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >
<head>
<title>The VR Book</title>
<link rel="stylesheet" type="text/css" href="../styles/9781970001143.css"/>
</head>
<body>
<h2 class="h2"><a id="page_251"></a><a id="ch22"></a><span class="blue1">22</span></h2>
<h2 class="h2b"><span class="blue">Affecting Behavior</span></h2>
<p class="noindent">VR users who feel fully present inside the creator&#8217;s world can be affected by content more than in any other medium. This chapter discusses several ways that the designer can influence and affect users through mechanisms linked to content, as well as how the designer should consider hardware and networking when creating content.</p>
<h3 class="h3"><a id="lev22.1"></a><strong><span class="font">22.1</span> Personal Wayfinding Aids</strong></h3>
<h4 class="h4a"><a id="lev22.1.1"></a><strong><span class="font1">22.1.1</span> Maps</strong></h4>
<p class="noindent">A <strong>map</strong> is a symbolic representation of a space, where relationships between objects, areas, and themes are conveyed. The purpose of a map is not necessarily to provide a direct mapping to some other space. Abstract representations can often be more effective in portraying understanding. Consider, for example, subway maps that only show relevant information and where scale might not be consistent.</p>
<p class="indent">Maps can be static or dynamic and looked at before navigation or concurrently while navigating. Maps that are used concurrently involve placement of oneself on the map (mentally or through technology) and help to answer the questions &#8220;Where am I?&#8221; and &#8220;What direction am I facing?&#8221;</p>
<p class="indent">Dynamic &#8220;you-are-here&#8221; markers on a map are extremely helpful for users to understand where they are in the world. Showing the user&#8217;s direction is also important. This can be done with an arrow or the user&#8217;s field of view on the map.</p>
<p class="indent">For large environments, it can be difficult to see details if the map represents the entire environment. The scale of the map can be modified, such as by a pinch gesture or 3D Multi-Touch Pattern (Section <a href="chapter28.html#lev28.3.3"><span class="blue">28.3.3</span></a>). To prevent the map from getting in the way/being annoying when it is not of use, consider putting the map on the non-dominant hand and give the option to turn it on/off.</p>
<p class="indent">Maps can also be used to more efficiently navigate to a location by entering the map through the World-In-Miniature Pattern (Section <a href="chapter28.html#lev28.5.2"><span class="blue">28.5.2</span></a>)&#8212;point on the map where to go and then &#8220;enter into&#8221; the map with the map becoming the surrounding world.</p>
<p class="indent"><a id="page_252"></a>How a map is oriented can have a big impact on spatial understanding. Map use during navigation is different from map use for spatial knowledge extraction. While driving or walking, people in an unfamiliar area generally turn maps in different directions, and misaligned maps cause problems for some people in judgments of direction. However, when looking over a map to plan a trip, the map is normally not turned. Depending on the task, maps are best used with either a forward-up orientation or a north-up orientation.</p>
<p class="indent"><strong>Forward-up maps</strong> align the information on the map to match the direction the user is facing or traveling. For example, if the user is traveling southeast, then the top center of the map corresponds to that southeast direction. This method is best used when concurrently navigating and/or searching in an egocentric manner [<a href="reference.html#ref64"><span class="blue">Darken and Cevik 1999</span></a>], as it automatically lines up the map with the direction of travel and enables easy matching between points on the map and corresponding landmarks in the environment. When the system does not automatically align the map (i.e., the users have to manually align the map), many users will stop using the map.</p>
<p class="indent"><strong>North-up maps</strong> are independent of the user&#8217;s orientation; no matter how the user turns or travels, the information on the map does not rotate. For example, if the user holds the map in the southeast direction, then the top center of the map still represents <a id="pg252lev1"></a>north. North-up maps are good for exocentric tasks. Example exocentric uses of north-up maps are (1) familiarizing oneself with the entire layout of the environment independent of where one is located, and (2) route planning before navigating. For egocentric tasks, a mental transformation is required from the egocentric perspective to the exocentric perspective.</p>
<h4 class="h4"><a id="lev22.1.2"></a><strong><span class="font1">22.1.2</span> Compasses</strong></h4>
<p class="noindent">A <strong>compass</strong> is an aid that helps give a user a sense of exocentric direction. In the real world, many people have an intuitive feel of which way is north after only being in a new location for a short period of time. If virtual turns are employed in VR, then keeping track of which way is which is much more difficult due to the lack of physical turning cues. By having easy access to a virtual compass, users can easily redirect themselves after performing a virtual turn and return to the intended direction of travel. Compasses are similar to forward-up maps except compasses only consist of direction, not location.</p>
<p class="indent">A virtual compass can be held in the hand as in the real world. Holding the compass in the hand enables one to precisely determine the heading of a landmark by holding the compass up to directly line up ticks on the compass onto landmarks in the environment. In contrast to the real world, a virtual compass can hang in space relative to the body (Section <a href="chapter26.html#lev26.3.3"><span class="blue">26.3.3</span></a>) so there is no need to hold it with the hand, although <a id="page_253"></a>this comes at the disadvantage of not being able to easily line up the compass with landmarks. The hand, however, can easily grab and release the compass as needed. Figure <a href="chapter22.html#fig22.1"><span class="blue">22.1</span></a> (left) shows a standard compass showing the cardinal directions over a terrain.</p>
<p class="image"><a id="fig22.1"></a><img src="../images/f0253-01.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 22.1</span> A traditional cardinal compass (left) and a medical compass with a human CT dataset (right). The letter <em>A</em> on the medical compass represents the anterior (front) side of the body, and the letter <em>R</em> represents the right lateral side of the body.</strong> (Courtesy of Digital ArtForms)</p>
<p class="indent"><a id="pg253lev1"></a>A compass does not necessarily provide cardinal directional information. Dataset visualization sometimes uses a cubic compass that represents direction relative to the dataset. For example, medical visualization sometimes uses a cube with the first letter of the directions on each face of the cube to help users understand how the close-up anatomy relates to the context of the entire body. Figure <a href="chapter22.html#fig22.1"><span class="blue">22.1</span></a> (right) shows such a compass.</p>
<p class="indent">If the compass is placed at eye level surrounding the user, then the user can overlay the compass ticks on landmarks by simply rotating the head (in yaw and pitch). Alternatively, the compass can be placed at the user&#8217;s feet as shown in Figure <a href="chapter22.html#fig22.2"><span class="blue">22.2</span></a>. In this case the user simply looks down to determine the way he is facing. This has the advantage of not being distracting as the compass is only seen when looking in the downward direction.</p>
<h4 class="h4"><a id="lev22.1.3"></a><strong><span class="font1">22.1.3</span> Multiple Wayfinding Aids</strong></h4>
<p class="noindent">Individual wayfinding aids by themselves are not particularly useful. Combining multiple aids together can significantly help. Effectiveness of wayfinding depends on the number and quality of wayfinding cues or aids provided to users [<a href="reference.html#ref24"><span class="blue">Bowman et al. 2004</span></a>]. However, too many wayfinding aids can be overwhelming; choose what is most appropriate for the goals of the project.</p>
<p class="image"><a id="page_254"></a><a id="fig22.2"></a><img src="../images/f0254-01.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 22.2</span> A compass surrounding the user&#8217;s feet.</strong> (Courtesy of NextGen Interactions)</p>
<p class="image"><a id="pg254lev1"></a><a id="fig22.3"></a><img src="../images/f0254-02.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 22.3</span> Visionary VR splits the scene into different action zones.</strong> (Courtesy of Visionary VR)</p>
<h3 class="h3"><a id="lev22.2"></a><strong><span class="font">22.2</span> Center of Action</strong></h3>
<p class="noindent">Not being able to control what direction users are looking is a new challenge for filmmakers as well as other content makers. Visionary VR, a start-up based in Los Angeles, splits the world around the user into different zones such as primary and secondary viewing directions (Figure <a href="chapter22.html#fig22.3"><span class="blue">22.3</span></a>) [<a href="reference.html#ref172"><span class="blue">Lang 2015</span></a>]. The most important action occurs in the primary direction. As a user starts looking toward another zone, cues are provided to inform the user that she is starting to look at a different part of the scene and the action and/or content is about to change if they keep looking in that direction. For example, glowing boundaries between zones can be drawn, the lights might dim for a zone as the user starts to look toward a different zone, or time might slow down to a halt as users look toward a different zone. Zones are also aware if the user is looking in their direction so actions within that zone can react when being <a id="page_255"></a>looked at. These techniques can be used to enable users to experience all parts of the scene independent of the order in which they view the different zones.</p>
<h3 class="h3"><a id="lev22.3"></a><strong><span class="font">22.3</span> Field of View</strong></h3>
<p class="noindent">There are a number of techniques designers can use to take advantage of the power of field of view (Mark Bolas, personal communication, June 13, 2015). One is to artificially constrain the field of view for certain parts of a VR experience, and then allow it to go wide for others. This is similar to how cinematographers use light or color in a movie; they control the perceptual arc to correlate with moments in the story being experienced. Another is to shape the frame around the field of view&#8212;rounded, asymmetric shapes feel better than rectilinear ones. You want the periphery to feel natural, even including the occlusion due to the nose. The qualitative result is the ability to author content with greater range and emotional depth. Its power turns up in unexpected ways. For example, anecdotal evidence suggests virtual characters cause a greater sense of presence when looking at them with a wide field of view compared to a narrow field of view. When there is a wide field of view, there is more of an obligation to obey social norms&#8212;for example, not staring at characters for too long and keeping an appropriate distance.</p>
<h3 class="h3"><a id="lev22.4"></a><strong><span class="font">22.4</span> Casual vs. High-End VR</strong></h3>
<p class="noindent">Different types of systems each have their own advantages and disadvantages. The experiences will be very different depending on the system type, and the experience should be targeted and designed for the primary type (although multiple types might be supported, the experience should be most optimized for one). This section focuses on wired vs. wireless and mobile vs. location-based systems. Chapter <a href="chapter27.html#ch27"><span class="blue">27</span></a> discusses system details specific to user input.</p>
<h4 class="h4"><a id="lev22.4.1"></a><strong><span class="font1">22.4.1</span> Wired vs. Wireless VR</strong></h4>
<p class="noindent">Wired and wireless systems result in different experiences whether the designer considers the trade-offs or not. For example, users will feel the tug of wires on the HMD resulting in a break-in-presence if they attempt to physically turn too far with a wired system. To optimize the user experience, design should take into account whether the targeted system is wired or wireless.</p>
<p class="indent"><strong>Wired seated systems</strong> should place content in front of the user and/or use an interface that enables virtual turning so that wires do not become tangled. An advantage of not enabling virtual turning (in addition to minimizing motion sickness) is that the designer can assume the user is facing in a general forward direction. Many seated <a id="page_256"></a>experiences can be designed so that non-tracked hand controllers can be assumed to be held in the lap, such that some visual representation of the controller and user&#8217;s hands can be drawn at the approximate location of the physical hands (Section <a href="chapter27.html#lev27.2.2"><span class="blue">27.2.2</span></a>). If virtual turning is used, the visual hands/controller should turn with the virtual turn (e.g., draw some form of chair-like device with the controller and body attached to the chair).</p>
<p class="indent"><strong>Freely turnable systems</strong> are wireless systems that allow users to easily look in any direction just as they would in the real world without concern of which direction is forward in the real world. Real turning has the advantages that it does not cause motion sickness and does not cause disorientation. A system that includes a swivel chair or omnidirectional treadmill should use a wireless system as cables will otherwise quickly become tangled after more than a 180&#176; turn.</p>
<p class="indent"><strong>Fully walkable systems</strong> enable users to stand up and physically walk around. Fully walkable untethered systems are known as <strong>nomadic VR</strong> (Denise Quesnel, personal communication, June 8, 2015). Whereas fully walkable systems can work extremely well, a non-immersed spotter should follow behind the user to prevent injury, and in the case of wired systems to prevent entanglement, tugging of the cables on the user&#8217;s head, and breaks-in-presence by the wires touching any part of the user&#8217;s body. Even <a id="pg256lev1"></a>with a wireless system or wires attached to a rail system, such as that at UNC-Chapel Hill, a spotter should still be used.</p>
<h4 class="h4"><a id="lev22.4.2"></a><strong><span class="font1">22.4.2</span> Mobile vs. Location-Based VR</strong></h4>
<p class="noindent">Mobile VR vs. location-based VR is the equivalent of mobile apps/games vs. more detailed and higher-powered desktop software. Although there is overlap, each should be designed to be optimized to take advantage of its specific characteristics (similar to input devices).</p>
<p class="indent"><strong>Mobile VR</strong> is defined by being able to place all equipment in a small bag and being able to immerse oneself almost instantaneously at about any time and any location when engagement with the real world is not required. Cell phones that snap into a head-mounted device are currently the standard for mobile VR. Mobile VR is also much more social and casual as VR experiences can be shared on a plane, at a party, or in a meeting.</p>
<p class="indent"><strong>Location-based VR</strong> requires a suitcase or more, takes time to set up, and ranges from one&#8217;s living room or office to out-of-home experiences [<a href="reference.html#ref335"><span class="blue">Williams and Mascioni 2014</span></a>] such as VR arcades or theme parks. Location-based VR has the potential to be higher quality and the most immersive as it can include high-end equipment and tracking technologies.</p>
<p class="image"><a id="page_257"></a><a id="fig22.4"></a><img src="../images/f0257-01.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 22.4</span> A user drives a virtual car in a CAVE while speaking with an avatar controlled by a remote user.</strong> (From <a href="reference.html#ref59"><span class="blue">Daily et al.</span></a> [<a href="reference.html#ref59"><span class="blue">2000</span></a>])</p>
<h3 class="h3"><a id="pg257lev1"></a><a id="lev22.5"></a><strong><span class="font">22.5</span> Characters, Avatars, and Social Networking</strong></h3>
<p class="noindent">A character can be either a computer-controlled character (an agent) or an avatar. An <strong>avatar</strong> is a character that is a virtual representation of a real user. This section discusses characters and how they influence behavior. Section <a href="chapter32.html#lev32.3"><span class="blue">32.3</span></a> discusses technical implementation of social networking. Figure <a href="chapter22.html#fig22.4"><span class="blue">22.4</span></a> shows an example of a user and a remote user rendered locally as an avatar.</p>
<p class="indent">As mentioned in Section <a href="chapter04.html#lev4.3"><span class="blue">4.3</span></a>, how we perceive ourselves can be quite distorted. In VR, we can explicitly define and design ourselves from a third-person perspective to look any way we wish. In addition, audio filters and prerecorded audio can be used to modify the sound of our voice. Providing the capability for users to personalize their own avatar has been proven to be very popular in both 2D virtual worlds (e.g., Second Life) as well as more fully immersive worlds. The Xbox Avatar store alone has 20,000 items for free or purchase.<a id="rpg257fn1"></a><sup><a href="chapter22.html#pg257fn1">1</a></sup> <strong>Caricature</strong> is a representation of a person or thing in which certain striking characteristics are exaggerated and less important features are omitted or simplified in order to create a comic or grotesque effect. Cartoonlike rendering with caricature can be enjoyable, effective, compelling, and presence inducing. Caricature can be especially effective for avatars because it can avoid the Uncanny Valley (Section <a href="chapter04.html#lev4.4.1"><span class="blue">4.4.1</span></a>).</p>
<p class="image"><a id="fig22.5"></a><a id="page_258"></a><img src="../images/f0258-01.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 22.5</span> Robotic characters without legs prevent breaks-in-presence that often occur when <a id="pg258lev1"></a>characters walk or run due to the difficulty of animating walking/running in a way that humans perceive as real.</strong> (Courtesy of NextGen Interactions)</p>
<p class="indent">As discussed in Section <a href="chapter09.html#lev9.3.9"><span class="blue">9.3.9</span></a>, the human ability to perceive the motion of others is extremely good. Although motion capture can result in character animation that is extremely compelling, this is difficult to do when mixing motion capture data with characters that are able to arbitrarily move and turn at different speeds. A simple solution is to use characters without legs, such as legless robotic characters, so that no breaks-in-presence occur due to walking and animations not always looking correct. Figure <a href="chapter22.html#fig22.5"><span class="blue">22.5</span></a> shows an example of an enemy robot that floats above the ground and only tilts when moving. Although not as impressive as a human-like character with legs, simple is better in this case to prevent breaks-in-presence resulting from awkward-looking leg movement.</p>
<p class="indent">Character head motion is extremely important for maintaining a sense of social presence [<a href="reference.html#ref237"><span class="blue">Pausch et al. 1996</span></a>]. Fortunately, since the use of HMDs requires head tracking, this information can be directly mapped to one&#8217;s avatar as seen by others (assuming quality bandwidth). Eye animations can add effect but are not necessary as any three-year-old child can attest to after watching <em>Sesame Street</em>. Moving an avatar&#8217;s eyes that does not result from eye tracking also risks the false impression that the character is not paying attention.</p>
<p class="image"><a id="page_259"></a><a id="fig22.6"></a><img src="../images/f0259-01.jpg" alt="image"/></p>
<p class="caption"><strong><span class="blue">Figure 22.6</span> An example of a fully immersive VR social experience.</strong> (Courtesy of VRChat)</p>
<p class="indent">To naturally convey attention, computer-controlled characters should first turn their heads before turning their bodies. Rotating the eyes before head turning can also add effect. However, if a computer-controlled character has eye motion and a user-controlled avatar does not, then that can provide a cue to users of which other characters are user controlled and which are not. Characters can also be used to encourage users to look in certain directions by pointing or lining themselves up between the user and the object to be looked at.</p>
<p class="indent">Social networking across distances through technology is not new. Like online 2D virtual worlds, people now spend hours at a time in fully immersive social VR such as VRChat (Figure <a href="chapter22.html#fig22.6"><span class="blue">22.6</span></a>). Jesse Joudrey (personal communication, April 20, 2015), CEO of VRChat, claims the urge to communicate with others in VR to be much stronger than in other digital mediums. For example, there is an urge to back up in VR if someone gets in one&#8217;s personal space. Although he believes face-to-face interaction is the best way of communicating, VR is the second-best way to interact with real people. Interestingly, even though users can visually define themselves differently than what they look like in real life, behavior is more difficult to change. Involuntary body language is difficult to hide even with only basic motion. People who are fidgety in real life also fidget in VR.<a id="page_260"></a></p>
<p class="footnote"><a id="pg257fn1"></a><a href="chapter22.html#rpg257fn1">1</a>. <span class="weblink"><a href="http://marketplace.xbox.com/en-US/AvatarMarketplace"><span class="blue">http://marketplace.xbox.com/en-US/AvatarMarketplace</span></a></span>; accessed June 16, 2015.</p>
</body>
</html>
